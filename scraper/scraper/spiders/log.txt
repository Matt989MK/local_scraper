INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 296d303f903195fa
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2898865726912 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2898865726912 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2898865726912 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2898865726912 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 22340
DEBUG: POST http://localhost:51635/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:51635
DEBUG: http://localhost:51635 "POST /session HTTP/1.1" 200 791
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.73","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir22340_1552261349"},"goog:chromeOptions":{"debuggerAddress":"localhost:51638"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"bf11cd543f059a6fa717ab4c1e834c5b"}} | headers=HTTPHeaderDict({'Content-Length': '791', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:51635/session/bf11cd543f059a6fa717ab4c1e834c5b/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:51635 "POST /session/bf11cd543f059a6fa717ab4c1e834c5b/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:51635/session/bf11cd543f059a6fa717ab4c1e834c5b/timeouts {"implicit": 10000}
DEBUG: http://localhost:51635 "POST /session/bf11cd543f059a6fa717ab4c1e834c5b/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Scraped from <200 http://smithgill.com/>
{'facebook': 'https://www.facebook.com/smithgillarch'}
DEBUG: DELETE http://localhost:51635/session/bf11cd543f059a6fa717ab4c1e834c5b {}
DEBUG: http://localhost:51635 "DELETE /session/bf11cd543f059a6fa717ab4c1e834c5b HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 18.209871,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 5, 23, 55, 13, 986742),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'item_scraped_count': 1,
 'log_count/DEBUG': 84,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 5, 23, 54, 55, 776871)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: f74f7239a1d268d1
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2215736630752 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2215736630752 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2215736630752 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2215736630752 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 15088
DEBUG: POST http://localhost:49199/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:49199
DEBUG: http://localhost:49199 "POST /session HTTP/1.1" 200 791
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.73","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir15088_1423117287"},"goog:chromeOptions":{"debuggerAddress":"localhost:49202"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"8104acd0b3740afb0111ae884d988a25"}} | headers=HTTPHeaderDict({'Content-Length': '791', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:49199/session/8104acd0b3740afb0111ae884d988a25/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:49199 "POST /session/8104acd0b3740afb0111ae884d988a25/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:49199/session/8104acd0b3740afb0111ae884d988a25/timeouts {"implicit": 10000}
DEBUG: http://localhost:49199 "POST /session/8104acd0b3740afb0111ae884d988a25/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Scraped from <200 http://smithgill.com/>
{'facebook': 'https://www.facebook.com/smithgillarch'}
DEBUG: DELETE http://localhost:49199/session/8104acd0b3740afb0111ae884d988a25 {}
DEBUG: http://localhost:49199 "DELETE /session/8104acd0b3740afb0111ae884d988a25 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 18.327564,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 5, 23, 59, 32, 128719),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'item_scraped_count': 1,
 'log_count/DEBUG': 84,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 5, 23, 59, 13, 801155)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 37f0ff2012db75e8
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1502844935504 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1502844935504 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1502844935504 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1502844935504 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 27404
DEBUG: POST http://localhost:49266/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:49266
DEBUG: http://localhost:49266 "POST /session HTTP/1.1" 200 791
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.73","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir27404_1278179160"},"goog:chromeOptions":{"debuggerAddress":"localhost:49269"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"1285595ee63e95d3abc3724ba2fadb70"}} | headers=HTTPHeaderDict({'Content-Length': '791', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:49266/session/1285595ee63e95d3abc3724ba2fadb70/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:49266 "POST /session/1285595ee63e95d3abc3724ba2fadb70/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:49266/session/1285595ee63e95d3abc3724ba2fadb70/timeouts {"implicit": 10000}
DEBUG: http://localhost:49266 "POST /session/1285595ee63e95d3abc3724ba2fadb70/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Scraped from <200 http://smithgill.com/>
{'facebook': 'https://www.facebook.com/smithgillarch'}
DEBUG: DELETE http://localhost:49266/session/1285595ee63e95d3abc3724ba2fadb70 {}
DEBUG: http://localhost:49266 "DELETE /session/1285595ee63e95d3abc3724ba2fadb70 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 18.828954,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 6, 0, 0, 38, 296836),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'item_scraped_count': 1,
 'log_count/DEBUG': 84,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 6, 0, 0, 19, 467882)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: c048dd801886f7e2
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2216693160288 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2216693160288 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2216693160288 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2216693160288 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 20180
DEBUG: POST http://localhost:49334/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:49334
DEBUG: http://localhost:49334 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.73","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir20180_515118047"},"goog:chromeOptions":{"debuggerAddress":"localhost:49337"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"239f2ac481164180e2bf7d45a31c2cfc"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:49334/session/239f2ac481164180e2bf7d45a31c2cfc/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:49334 "POST /session/239f2ac481164180e2bf7d45a31c2cfc/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:49334/session/239f2ac481164180e2bf7d45a31c2cfc/timeouts {"implicit": 10000}
DEBUG: http://localhost:49334 "POST /session/239f2ac481164180e2bf7d45a31c2cfc/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Scraped from <200 http://smithgill.com/>
{'facebook': 'https://www.facebook.com/smithgillarch'}
DEBUG: DELETE http://localhost:49334/session/239f2ac481164180e2bf7d45a31c2cfc {}
DEBUG: http://localhost:49334 "DELETE /session/239f2ac481164180e2bf7d45a31c2cfc HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 2,
 'elapsed_time_seconds': 20.906456,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 6, 0, 1, 7, 243798),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'item_scraped_count': 1,
 'log_count/DEBUG': 84,
 'log_count/INFO': 11,
 'request_depth_max': 2,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 6, 0, 0, 46, 337342)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 0491f4165f4044de
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1736992283936 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1736992283936 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1736992283936 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1736992283936 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 26932
DEBUG: POST http://localhost:49405/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:49405
DEBUG: http://localhost:49405 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.73","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir26932_346921101"},"goog:chromeOptions":{"debuggerAddress":"localhost:49409"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"8d92a46e2b752e1f3cea941f212e23d1"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:49405/session/8d92a46e2b752e1f3cea941f212e23d1/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:49405 "POST /session/8d92a46e2b752e1f3cea941f212e23d1/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:49405/session/8d92a46e2b752e1f3cea941f212e23d1/timeouts {"implicit": 10000}
DEBUG: http://localhost:49405 "POST /session/8d92a46e2b752e1f3cea941f212e23d1/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Scraped from <200 http://smithgill.com/>
{'facebook': 'https://www.facebook.com/smithgillarch'}
DEBUG: DELETE http://localhost:49405/session/8d92a46e2b752e1f3cea941f212e23d1 {}
DEBUG: http://localhost:49405 "DELETE /session/8d92a46e2b752e1f3cea941f212e23d1 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 2,
 'elapsed_time_seconds': 19.6648,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 6, 0, 2, 22, 805851),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'item_scraped_count': 1,
 'log_count/DEBUG': 84,
 'log_count/INFO': 11,
 'request_depth_max': 2,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 6, 0, 2, 3, 141051)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: ef8661ccd5b45378
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1375770288496 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1375770288496 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1375770288496 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1375770288496 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 20428
DEBUG: POST http://localhost:52074/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:52074
DEBUG: http://localhost:52074 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.73","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir20428_444834778"},"goog:chromeOptions":{"debuggerAddress":"localhost:52077"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"458b276eb34697e0d41d1d0345d04fc1"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:52074/session/458b276eb34697e0d41d1d0345d04fc1/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:52074 "POST /session/458b276eb34697e0d41d1d0345d04fc1/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:52074/session/458b276eb34697e0d41d1d0345d04fc1/timeouts {"implicit": 10000}
DEBUG: http://localhost:52074 "POST /session/458b276eb34697e0d41d1d0345d04fc1/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Scraped from <200 http://smithgill.com/>
{'facebook': 'https://www.facebook.com/smithgillarch'}
DEBUG: DELETE http://localhost:52074/session/458b276eb34697e0d41d1d0345d04fc1 {}
DEBUG: http://localhost:52074 "DELETE /session/458b276eb34697e0d41d1d0345d04fc1 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 2,
 'elapsed_time_seconds': 17.379686,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 6, 9, 28, 56, 34259),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'item_scraped_count': 1,
 'log_count/DEBUG': 84,
 'log_count/INFO': 11,
 'request_depth_max': 2,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 6, 9, 28, 38, 654573)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 283762aecb5a140d
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2717806405008 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2717806405008 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2717806405008 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2717806405008 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 14128
DEBUG: POST http://localhost:52149/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:52149
DEBUG: http://localhost:52149 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.73","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir14128_447787574"},"goog:chromeOptions":{"debuggerAddress":"localhost:52152"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"8c68d953356ec0a27582a6fd6f727023"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:52149/session/8c68d953356ec0a27582a6fd6f727023/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:52149 "POST /session/8c68d953356ec0a27582a6fd6f727023/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:52149/session/8c68d953356ec0a27582a6fd6f727023/timeouts {"implicit": 10000}
DEBUG: http://localhost:52149 "POST /session/8c68d953356ec0a27582a6fd6f727023/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Scraped from <200 http://smithgill.com/>
{'facebook': 'https://www.facebook.com/smithgillarch'}
DEBUG: DELETE http://localhost:52149/session/8c68d953356ec0a27582a6fd6f727023 {}
DEBUG: http://localhost:52149 "DELETE /session/8c68d953356ec0a27582a6fd6f727023 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 16.656587,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 6, 9, 30, 7, 270818),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'item_scraped_count': 1,
 'log_count/DEBUG': 84,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 6, 9, 29, 50, 614231)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: affc52e95524307e
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2350901470368 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2350901470368 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2350901470368 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2350901470368 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 25104
DEBUG: POST http://localhost:52217/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:52217
DEBUG: http://localhost:52217 "POST /session HTTP/1.1" 200 791
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.73","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir25104_1910651868"},"goog:chromeOptions":{"debuggerAddress":"localhost:52220"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"fcaa33da4510af84b4fe84ed93dd7630"}} | headers=HTTPHeaderDict({'Content-Length': '791', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:52217/session/fcaa33da4510af84b4fe84ed93dd7630/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:52217 "POST /session/fcaa33da4510af84b4fe84ed93dd7630/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:52217/session/fcaa33da4510af84b4fe84ed93dd7630/timeouts {"implicit": 10000}
DEBUG: http://localhost:52217 "POST /session/fcaa33da4510af84b4fe84ed93dd7630/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Scraped from <200 http://smithgill.com/>
{'facebook': 'https://www.facebook.com/smithgillarch'}
DEBUG: DELETE http://localhost:52217/session/fcaa33da4510af84b4fe84ed93dd7630 {}
DEBUG: http://localhost:52217 "DELETE /session/fcaa33da4510af84b4fe84ed93dd7630 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 12533,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 15.835927,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 6, 9, 30, 43, 405514),
 'httpcompression/response_bytes': 59820,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 81,
 'log_count/INFO': 11,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 12, 6, 9, 30, 27, 569587)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 5b20fedc61d40384
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2433226155408 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2433226155408 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2433226155408 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2433226155408 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 3816
DEBUG: POST http://localhost:52282/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:52282
DEBUG: http://localhost:52282 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.73","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir3816_1587810755"},"goog:chromeOptions":{"debuggerAddress":"localhost:52285"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"6174ffa3da4c5914c9d832214c1526ff"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:52282/session/6174ffa3da4c5914c9d832214c1526ff/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:52282 "POST /session/6174ffa3da4c5914c9d832214c1526ff/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:52282/session/6174ffa3da4c5914c9d832214c1526ff/timeouts {"implicit": 10000}
DEBUG: http://localhost:52282 "POST /session/6174ffa3da4c5914c9d832214c1526ff/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Scraped from <200 http://smithgill.com/>
{'facebook': 'https://www.facebook.com/smithgillarch'}
DEBUG: DELETE http://localhost:52282/session/6174ffa3da4c5914c9d832214c1526ff {}
DEBUG: http://localhost:52282 "DELETE /session/6174ffa3da4c5914c9d832214c1526ff HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 2,
 'elapsed_time_seconds': 17.05021,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 6, 9, 31, 29, 714641),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'item_scraped_count': 1,
 'log_count/DEBUG': 84,
 'log_count/INFO': 11,
 'request_depth_max': 2,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 6, 9, 31, 12, 664431)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 0d813e74b4642481
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1687325826768 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1687325826768 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1687325826768 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1687325826768 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 9700
DEBUG: POST http://localhost:50911/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:50911
DEBUG: http://localhost:50911 "POST /session HTTP/1.1" 200 789
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir9700_903949772"},"goog:chromeOptions":{"debuggerAddress":"localhost:50915"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"87c684a523448f90c5150c44ef55740e"}} | headers=HTTPHeaderDict({'Content-Length': '789', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:50911/session/87c684a523448f90c5150c44ef55740e/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:50911 "POST /session/87c684a523448f90c5150c44ef55740e/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:50911/session/87c684a523448f90c5150c44ef55740e/timeouts {"implicit": 10000}
DEBUG: http://localhost:50911 "POST /session/87c684a523448f90c5150c44ef55740e/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Scraped from <200 http://smithgill.com/>
{'facebook': 'https://www.facebook.com/smithgillarch'}
DEBUG: DELETE http://localhost:50911/session/87c684a523448f90c5150c44ef55740e {}
DEBUG: http://localhost:50911 "DELETE /session/87c684a523448f90c5150c44ef55740e HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 2,
 'elapsed_time_seconds': 18.03273,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 19, 32, 29, 194945),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'item_scraped_count': 1,
 'log_count/DEBUG': 84,
 'log_count/INFO': 11,
 'request_depth_max': 2,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 8, 19, 32, 11, 162215)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: c9746dcc08e7cdfa
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2261708677392 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2261708677392 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2261708677392 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2261708677392 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 36268
DEBUG: POST http://localhost:50980/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:50980
DEBUG: http://localhost:50980 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir36268_752997432"},"goog:chromeOptions":{"debuggerAddress":"localhost:50983"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"5a5aba8db20ba9fb97469b9cf619cd04"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:50980/session/5a5aba8db20ba9fb97469b9cf619cd04/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:50980 "POST /session/5a5aba8db20ba9fb97469b9cf619cd04/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:50980/session/5a5aba8db20ba9fb97469b9cf619cd04/timeouts {"implicit": 10000}
DEBUG: http://localhost:50980 "POST /session/5a5aba8db20ba9fb97469b9cf619cd04/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Scraped from <200 http://smithgill.com/>
{'facebook': 'https://www.facebook.com/smithgillarch'}
DEBUG: DELETE http://localhost:50980/session/5a5aba8db20ba9fb97469b9cf619cd04 {}
DEBUG: http://localhost:50980 "DELETE /session/5a5aba8db20ba9fb97469b9cf619cd04 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 2,
 'elapsed_time_seconds': 18.006735,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 19, 33, 43, 228139),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'item_scraped_count': 1,
 'log_count/DEBUG': 84,
 'log_count/INFO': 11,
 'request_depth_max': 2,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 8, 19, 33, 25, 221404)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: b135c9e51a268f2c
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2109861568976 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2109861568976 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2109861568976 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2109861568976 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 33712
DEBUG: POST http://localhost:60095/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:60095
DEBUG: http://localhost:60095 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir33712_835472672"},"goog:chromeOptions":{"debuggerAddress":"localhost:60098"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"d508a53b3d90f437cd7d922c52eaaa68"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60095/session/d508a53b3d90f437cd7d922c52eaaa68/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:60095 "POST /session/d508a53b3d90f437cd7d922c52eaaa68/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60095/session/d508a53b3d90f437cd7d922c52eaaa68/timeouts {"implicit": 10000}
DEBUG: http://localhost:60095 "POST /session/d508a53b3d90f437cd7d922c52eaaa68/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Scraped from <200 http://smithgill.com/>
{'facebook': 'https://www.facebook.com/smithgillarch'}
DEBUG: DELETE http://localhost:60095/session/d508a53b3d90f437cd7d922c52eaaa68 {}
DEBUG: http://localhost:60095 "DELETE /session/d508a53b3d90f437cd7d922c52eaaa68 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 2,
 'elapsed_time_seconds': 18.189901,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 19, 41, 45, 25030),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'item_scraped_count': 1,
 'log_count/DEBUG': 84,
 'log_count/INFO': 11,
 'request_depth_max': 2,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 8, 19, 41, 26, 835129)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 9c2b773f8c27b9bf
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1833405621312 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1833405621312 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1833405621312 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1833405621312 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 21548
DEBUG: POST http://localhost:60178/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:60178
DEBUG: http://localhost:60178 "POST /session HTTP/1.1" 200 791
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir21548_1158249242"},"goog:chromeOptions":{"debuggerAddress":"localhost:60181"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"0821091a9ee2810323285944c797f066"}} | headers=HTTPHeaderDict({'Content-Length': '791', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60178/session/0821091a9ee2810323285944c797f066/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:60178 "POST /session/0821091a9ee2810323285944c797f066/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60178/session/0821091a9ee2810323285944c797f066/timeouts {"implicit": 10000}
DEBUG: http://localhost:60178 "POST /session/0821091a9ee2810323285944c797f066/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Scraped from <200 http://smithgill.com/>
{'facebook': 'https://www.facebook.com/smithgillarch'}
DEBUG: DELETE http://localhost:60178/session/0821091a9ee2810323285944c797f066 {}
DEBUG: http://localhost:60178 "DELETE /session/0821091a9ee2810323285944c797f066 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
ERROR: Spider must return request, item, or None, got 'list' in <GET http://smithgill.com/contact/>
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 18.137216,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 19, 47, 43, 104396),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'item_scraped_count': 1,
 'log_count/DEBUG': 84,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 8, 19, 47, 24, 967180)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: b105392a9c7c798f
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2384008486032 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2384008486032 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2384008486032 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2384008486032 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 18596
DEBUG: POST http://localhost:60259/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:60259
DEBUG: http://localhost:60259 "POST /session HTTP/1.1" 200 791
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir18596_1343328411"},"goog:chromeOptions":{"debuggerAddress":"localhost:60262"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"64c27804eadde3d7f15b09c30d2c4576"}} | headers=HTTPHeaderDict({'Content-Length': '791', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60259/session/64c27804eadde3d7f15b09c30d2c4576/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:60259 "POST /session/64c27804eadde3d7f15b09c30d2c4576/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60259/session/64c27804eadde3d7f15b09c30d2c4576/timeouts {"implicit": 10000}
DEBUG: http://localhost:60259 "POST /session/64c27804eadde3d7f15b09c30d2c4576/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
ERROR: Spider error processing <GET http://smithgill.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 79, in parse_website
    meta_contact = {'facebook': facebook_link, 'instagram': instagram_link, 'twitter': twitter_link, 'linkedin': linkedin_link,'emails': emails}
UnboundLocalError: local variable 'instagram_link' referenced before assignment
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 12533,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 10.407969,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 19, 51, 3, 742978),
 'httpcompression/response_bytes': 59820,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 76,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/UnboundLocalError': 1,
 'start_time': datetime.datetime(2022, 12, 8, 19, 50, 53, 335009)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 470da2703463bbd4
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2951221714304 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2951221714304 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2951221714304 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2951221714304 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 5700
DEBUG: POST http://localhost:60321/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:60321
DEBUG: http://localhost:60321 "POST /session HTTP/1.1" 200 789
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir5700_747423759"},"goog:chromeOptions":{"debuggerAddress":"localhost:60324"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"46f1b43febea027e9019398212a9526c"}} | headers=HTTPHeaderDict({'Content-Length': '789', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60321/session/46f1b43febea027e9019398212a9526c/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:60321 "POST /session/46f1b43febea027e9019398212a9526c/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60321/session/46f1b43febea027e9019398212a9526c/timeouts {"implicit": 10000}
DEBUG: http://localhost:60321 "POST /session/46f1b43febea027e9019398212a9526c/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
ERROR: Spider error processing <GET http://smithgill.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 79, in parse_website
    meta_contact = {'facebook': facebook_link, 'instagram': instagram_link, 'twitter': twitter_link, 'linkedin': linkedin_link}
UnboundLocalError: local variable 'instagram_link' referenced before assignment
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 12533,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 11.168823,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 19, 51, 52, 710287),
 'httpcompression/response_bytes': 59820,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 76,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/UnboundLocalError': 1,
 'start_time': datetime.datetime(2022, 12, 8, 19, 51, 41, 541464)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 4169149c0fc5ab55
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2090484080144 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2090484080144 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2090484080144 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2090484080144 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 36436
DEBUG: POST http://localhost:60387/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:60387
DEBUG: http://localhost:60387 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir36436_456798415"},"goog:chromeOptions":{"debuggerAddress":"localhost:60390"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"18ac2ec394b0b92c370712d6ab6d70c0"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60387/session/18ac2ec394b0b92c370712d6ab6d70c0/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:60387 "POST /session/18ac2ec394b0b92c370712d6ab6d70c0/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60387/session/18ac2ec394b0b92c370712d6ab6d70c0/timeouts {"implicit": 10000}
DEBUG: http://localhost:60387 "POST /session/18ac2ec394b0b92c370712d6ab6d70c0/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
ERROR: Spider error processing <GET http://smithgill.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 79, in parse_website
    meta_contact = {'facebook': facebook_link, 'instagram': instagram_link, 'twitter': twitter_link, 'linkedin': linkedin_link}
UnboundLocalError: local variable 'instagram_link' referenced before assignment
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 12533,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 10.795219,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 19, 54, 5, 82162),
 'httpcompression/response_bytes': 59820,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 76,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/UnboundLocalError': 1,
 'start_time': datetime.datetime(2022, 12, 8, 19, 53, 54, 286943)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 605c37237f448985
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2206733542752 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2206733542752 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2206733542752 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2206733542752 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 33420
DEBUG: POST http://localhost:60449/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:60449
DEBUG: http://localhost:60449 "POST /session HTTP/1.1" 200 791
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir33420_1556172617"},"goog:chromeOptions":{"debuggerAddress":"localhost:60452"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"1fe041a32f9fde7b3e387f2a40f956cd"}} | headers=HTTPHeaderDict({'Content-Length': '791', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60449/session/1fe041a32f9fde7b3e387f2a40f956cd/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:60449 "POST /session/1fe041a32f9fde7b3e387f2a40f956cd/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60449/session/1fe041a32f9fde7b3e387f2a40f956cd/timeouts {"implicit": 10000}
DEBUG: http://localhost:60449 "POST /session/1fe041a32f9fde7b3e387f2a40f956cd/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: DELETE http://localhost:60449/session/1fe041a32f9fde7b3e387f2a40f956cd {}
DEBUG: http://localhost:60449 "DELETE /session/1fe041a32f9fde7b3e387f2a40f956cd HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
ERROR: Spider must return request, item, or None, got 'list' in <GET http://smithgill.com/contact/>
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 17.589261,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 19, 55, 32, 383342),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'log_count/DEBUG': 83,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 8, 19, 55, 14, 794081)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 78b1db63d0a90f33
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2975018754128 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2975018754128 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2975018754128 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2975018754128 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 13968
DEBUG: POST http://localhost:60523/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:60523
DEBUG: http://localhost:60523 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir13968_592609336"},"goog:chromeOptions":{"debuggerAddress":"localhost:60526"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"b28fb3b3e60a51b349ee81a6bf0d9d48"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60523/session/b28fb3b3e60a51b349ee81a6bf0d9d48/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:60523 "POST /session/b28fb3b3e60a51b349ee81a6bf0d9d48/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60523/session/b28fb3b3e60a51b349ee81a6bf0d9d48/timeouts {"implicit": 10000}
DEBUG: http://localhost:60523 "POST /session/b28fb3b3e60a51b349ee81a6bf0d9d48/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: DELETE http://localhost:60523/session/b28fb3b3e60a51b349ee81a6bf0d9d48 {}
DEBUG: http://localhost:60523 "DELETE /session/b28fb3b3e60a51b349ee81a6bf0d9d48 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
ERROR: Spider error processing <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 117, in parse_contact
    print("meta test", response.meta['meta'])
KeyError: 'meta'
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 18.29174,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 19, 58, 12, 153012),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'log_count/DEBUG': 83,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2022, 12, 8, 19, 57, 53, 861272)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 0aa98f3bc481fedf
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1734779183808 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1734779183808 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1734779183808 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1734779183808 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 39452
DEBUG: POST http://localhost:60589/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:60589
DEBUG: http://localhost:60589 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir39452_528592525"},"goog:chromeOptions":{"debuggerAddress":"localhost:60592"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"8f2f7d2856d1a43e16e785f1f6c356ad"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60589/session/8f2f7d2856d1a43e16e785f1f6c356ad/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:60589 "POST /session/8f2f7d2856d1a43e16e785f1f6c356ad/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60589/session/8f2f7d2856d1a43e16e785f1f6c356ad/timeouts {"implicit": 10000}
DEBUG: http://localhost:60589 "POST /session/8f2f7d2856d1a43e16e785f1f6c356ad/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: DELETE http://localhost:60589/session/8f2f7d2856d1a43e16e785f1f6c356ad {}
DEBUG: http://localhost:60589 "DELETE /session/8f2f7d2856d1a43e16e785f1f6c356ad HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
ERROR: Spider error processing <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 117, in parse_contact
    print("meta test", response.meta['meta'])
KeyError: 'meta'
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 21.320392,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 19, 58, 41, 372768),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'log_count/DEBUG': 83,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2022, 12, 8, 19, 58, 20, 52376)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: ee4301448b1a7310
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2048533634960 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2048533634960 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2048533634960 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2048533634960 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 30816
DEBUG: POST http://localhost:60655/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:60655
DEBUG: http://localhost:60655 "POST /session HTTP/1.1" 200 791
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir30816_1729229009"},"goog:chromeOptions":{"debuggerAddress":"localhost:60658"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"b87ce40caeb4fab7a8188e7df25a4ea0"}} | headers=HTTPHeaderDict({'Content-Length': '791', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60655/session/b87ce40caeb4fab7a8188e7df25a4ea0/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:60655 "POST /session/b87ce40caeb4fab7a8188e7df25a4ea0/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60655/session/b87ce40caeb4fab7a8188e7df25a4ea0/timeouts {"implicit": 10000}
DEBUG: http://localhost:60655 "POST /session/b87ce40caeb4fab7a8188e7df25a4ea0/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: DELETE http://localhost:60655/session/b87ce40caeb4fab7a8188e7df25a4ea0 {}
DEBUG: http://localhost:60655 "DELETE /session/b87ce40caeb4fab7a8188e7df25a4ea0 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 19.654422,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 19, 59, 19, 591426),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'log_count/DEBUG': 83,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 8, 19, 58, 59, 937004)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 8fa33a6686e9fb96
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2192890830304 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2192890830304 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2192890830304 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2192890830304 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 16228
DEBUG: POST http://localhost:60721/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:60721
DEBUG: http://localhost:60721 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir16228_651677254"},"goog:chromeOptions":{"debuggerAddress":"localhost:60724"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"f6814cce0c5b1223fd3adc3b313bfbb2"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60721/session/f6814cce0c5b1223fd3adc3b313bfbb2/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:60721 "POST /session/f6814cce0c5b1223fd3adc3b313bfbb2/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60721/session/f6814cce0c5b1223fd3adc3b313bfbb2/timeouts {"implicit": 10000}
DEBUG: http://localhost:60721 "POST /session/f6814cce0c5b1223fd3adc3b313bfbb2/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: DELETE http://localhost:60721/session/f6814cce0c5b1223fd3adc3b313bfbb2 {}
DEBUG: http://localhost:60721 "DELETE /session/f6814cce0c5b1223fd3adc3b313bfbb2 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
DEBUG: Scraped from <200 http://smithgill.com/contact/>
{'emails': ['resumes@smithgill.com',
            'weiweiluo@smithgill.com',
            'info@smithgill.com',
            'press@smithgill.com'],
 'facebook': 'https://www.facebook.com/smithgillarch',
 'instagram': '',
 'linkedin': '',
 'twitter': 'https://www.twitter.com/smithgillarch'}
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 19.020343,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 20, 0, 1, 946477),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'item_scraped_count': 1,
 'log_count/DEBUG': 84,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 8, 19, 59, 42, 926134)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: e3fa88ea69b7af65
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 3033818702144 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 3033818702144 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 3033818702144 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 3033818702144 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://smithgill.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 228 without any user agent to enforce it on.
DEBUG: Rule at line 229 without any user agent to enforce it on.
DEBUG: Rule at line 230 without any user agent to enforce it on.
DEBUG: Rule at line 238 without any user agent to enforce it on.
DEBUG: Rule at line 239 without any user agent to enforce it on.
DEBUG: Rule at line 240 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 243 without any user agent to enforce it on.
DEBUG: Rule at line 244 without any user agent to enforce it on.
DEBUG: Rule at line 245 without any user agent to enforce it on.
DEBUG: Rule at line 246 without any user agent to enforce it on.
DEBUG: Rule at line 247 without any user agent to enforce it on.
DEBUG: Rule at line 248 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 250 without any user agent to enforce it on.
DEBUG: Rule at line 251 without any user agent to enforce it on.
DEBUG: Rule at line 285 without any user agent to enforce it on.
DEBUG: Rule at line 291 without any user agent to enforce it on.
DEBUG: Rule at line 297 without any user agent to enforce it on.
DEBUG: Rule at line 303 without any user agent to enforce it on.
DEBUG: Rule at line 309 without any user agent to enforce it on.
DEBUG: Rule at line 315 without any user agent to enforce it on.
DEBUG: Rule at line 321 without any user agent to enforce it on.
DEBUG: Rule at line 327 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 359 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 383 without any user agent to enforce it on.
DEBUG: Rule at line 389 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 440 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 442 without any user agent to enforce it on.
DEBUG: Rule at line 443 without any user agent to enforce it on.
DEBUG: Rule at line 449 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 454 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 481 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://smithgill.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 39560
DEBUG: POST http://localhost:60789/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:60789
DEBUG: http://localhost:60789 "POST /session HTTP/1.1" 200 791
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir39560_1953390729"},"goog:chromeOptions":{"debuggerAddress":"localhost:60792"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"0884e43fee273ef7c087ed5ba511c321"}} | headers=HTTPHeaderDict({'Content-Length': '791', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60789/session/0884e43fee273ef7c087ed5ba511c321/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:60789 "POST /session/0884e43fee273ef7c087ed5ba511c321/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:60789/session/0884e43fee273ef7c087ed5ba511c321/timeouts {"implicit": 10000}
DEBUG: http://localhost:60789 "POST /session/0884e43fee273ef7c087ed5ba511c321/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Filtered duplicate request: <GET http://smithgill.com/contact> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: DELETE http://localhost:60789/session/0884e43fee273ef7c087ed5ba511c321 {}
DEBUG: http://localhost:60789 "DELETE /session/0884e43fee273ef7c087ed5ba511c321 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET http://smithgill.com/contact/> from <GET http://smithgill.com/contact>
DEBUG: Crawled (200) <GET http://smithgill.com/contact/> (referer: http://smithgill.com/)
DEBUG: Scraped from <200 http://smithgill.com/contact/>
{'emails': ['info@smithgill.com',
            'resumes@smithgill.com',
            'weiweiluo@smithgill.com',
            'press@smithgill.com'],
 'facebook': 'https://www.facebook.com/smithgillarch',
 'instagram': '',
 'linkedin': '',
 'twitter': 'https://www.twitter.com/smithgillarch'}
INFO: Closing spider (finished)
INFO: Stored json feed (1 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1252,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 18931,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 17.509849,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 20, 0, 49, 572385),
 'httpcompression/response_bytes': 85365,
 'httpcompression/response_count': 3,
 'item_scraped_count': 1,
 'log_count/DEBUG': 84,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 12, 8, 20, 0, 32, 62536)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 3056dc336498360e
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 28, in start_requests
    with open("data.csv") as csvfile:
FileNotFoundError: [Errno 2] No such file or directory: 'data.csv'
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.004001,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 20, 23, 7, 208396),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'start_time': datetime.datetime(2022, 12, 8, 20, 23, 7, 204395)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: b901e17bf20db432
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website())
TypeError: WebsiteSpider.parse_website() missing 1 required positional argument: 'response'
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.004001,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 20, 23, 46, 916757),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'start_time': datetime.datetime(2022, 12, 8, 20, 23, 46, 912756)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 44eb6e611193f36b
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website())
TypeError: WebsiteSpider.parse_website() missing 1 required positional argument: 'response'
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.004001,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 20, 23, 52, 355286),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'start_time': datetime.datetime(2022, 12, 8, 20, 23, 52, 351285)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 5ce4de5a332d6eb1
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: address
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.015004,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 20, 24, 1, 587172),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'start_time': datetime.datetime(2022, 12, 8, 20, 24, 1, 572168)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 06bc2e8d0110886c
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 38, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: address
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.005003,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 20, 24, 27, 988975),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'start_time': datetime.datetime(2022, 12, 8, 20, 24, 27, 983972)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: c1c35e26042cf710
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 38, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: address
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.004,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 20, 25, 4, 207008),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'start_time': datetime.datetime(2022, 12, 8, 20, 25, 4, 203008)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 93a76448dbbbd902
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 38, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: adres:%206336%20OH-605%20S,%20Westerville,%20OH%2043082,%20Stany%20Zjednoczone
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.005,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 20, 26, 23, 848242),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'start_time': datetime.datetime(2022, 12, 8, 20, 26, 23, 843242)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: a067d5f9820db64b
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 38, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: adres:%206336%20OH-605%20S,%20Westerville,%20OH%2043082,%20Stany%20Zjednoczone
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.005001,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 20, 27, 12, 817514),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'start_time': datetime.datetime(2022, 12, 8, 20, 27, 12, 812513)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 21cc6c1bbc7a8b92
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/robots.txt> from <GET http://www.fandftrees.com/robots.txt>
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/robots.txt> (referer: None)
DEBUG: Attempting to acquire lock 2107676850880 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2107676850880 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2107676850880 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2107676850880 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://trapperstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://www.midohiotree.org/robots.txt> (referer: None)
DEBUG: Filtered duplicate request: <GET http://hardwicktreecare.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 22680
DEBUG: POST http://localhost:65267/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:65267
DEBUG: http://localhost:65267 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir22680_661478169"},"goog:chromeOptions":{"debuggerAddress":"localhost:65270"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"10a1d99cef3f71a34f18369a7748bff2"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:65267/session/10a1d99cef3f71a34f18369a7748bff2/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:65267 "POST /session/10a1d99cef3f71a34f18369a7748bff2/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:65267/session/10a1d99cef3f71a34f18369a7748bff2/timeouts {"implicit": 10000}
DEBUG: http://localhost:65267 "POST /session/10a1d99cef3f71a34f18369a7748bff2/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: DELETE http://localhost:65267/session/10a1d99cef3f71a34f18369a7748bff2 {}
DEBUG: http://localhost:65267 "DELETE /session/10a1d99cef3f71a34f18369a7748bff2 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Crawled (403) <GET https://www.midohiotree.org/> (referer: None)
DEBUG: Crawled (200) <GET http://hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET http://ohiotreeandexcavating.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/robots.txt> from <GET http://starwoodtree.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.treetechohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/> from <GET http://www.fandftrees.com/>
DEBUG: Redirecting (301) to <GET https://www.hardwicktreecare.com/> from <GET http://hardwicktreecare.com/>
INFO: Ignoring response <403 https://www.midohiotree.org/>: HTTP status code is not handled or not allowed
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 39048
DEBUG: POST http://localhost:65328/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:65328
DEBUG: http://localhost:65328 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir39048_105985459"},"goog:chromeOptions":{"debuggerAddress":"localhost:65331"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"4cd165bb2334557510d367a7080b7d3d"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:65328/session/4cd165bb2334557510d367a7080b7d3d/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:65328 "POST /session/4cd165bb2334557510d367a7080b7d3d/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:65328/session/4cd165bb2334557510d367a7080b7d3d/timeouts {"implicit": 10000}
DEBUG: http://localhost:65328 "POST /session/4cd165bb2334557510d367a7080b7d3d/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.net/>
DEBUG: DELETE http://localhost:65328/session/4cd165bb2334557510d367a7080b7d3d {}
DEBUG: http://localhost:65328 "DELETE /session/4cd165bb2334557510d367a7080b7d3d HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Crawled (200) <GET http://herculestree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/robots.txt> from <GET http://ohiotreeandexcavating.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET http://ohiotreecare.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 4228
DEBUG: POST http://localhost:65366/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:65366
DEBUG: http://localhost:65366 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir4228_1410459277"},"goog:chromeOptions":{"debuggerAddress":"localhost:65369"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"ff332d6ae864940a17154f0d198cf441"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:65366/session/ff332d6ae864940a17154f0d198cf441/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:65366 "POST /session/ff332d6ae864940a17154f0d198cf441/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:65366/session/ff332d6ae864940a17154f0d198cf441/timeouts {"implicit": 10000}
DEBUG: http://localhost:65366 "POST /session/ff332d6ae864940a17154f0d198cf441/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: DELETE http://localhost:65366/session/ff332d6ae864940a17154f0d198cf441 {}
DEBUG: http://localhost:65366 "DELETE /session/ff332d6ae864940a17154f0d198cf441 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: Redirecting (301) to <GET https://herculestree.com/> from <GET http://herculestree.com/>
DEBUG: Redirecting (301) to <GET https://www.treesaremybusiness.com/> from <GET http://www.treesaremybusiness.com/>
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/> (referer: None)
DEBUG: Crawled (200) <GET http://ohiotreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/contact> (referer: https://www.treetechohio.com/)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.com/>
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/robots.txt> (referer: None)
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 6068
DEBUG: POST http://localhost:65394/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:65394
DEBUG: http://localhost:65394 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir6068_1461231678"},"goog:chromeOptions":{"debuggerAddress":"localhost:65397"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"e69791393866c89d4b40204f35d020a4"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:65394/session/e69791393866c89d4b40204f35d020a4/url {"url": "http://smithgill.com/"}
ERROR: Spider error processing <GET https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1368, in getresponse
    response.begin()
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 317, in begin
    version, status, reason = self._read_status()
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 278, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 52, in parse_website
    driver.get("http://smithgill.com/")
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 455, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 442, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 294, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 316, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1368, in getresponse
    response.begin()
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 317, in begin
    version, status, reason = self._read_status()
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 278, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 6656
DEBUG: POST http://localhost:65407/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:65407
DEBUG: http://localhost:65407 "POST /session HTTP/1.1" 200 789
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir6656_976337431"},"goog:chromeOptions":{"debuggerAddress":"localhost:65410"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"8ea4366a8214d6c4e96db61aa217f070"}} | headers=HTTPHeaderDict({'Content-Length': '789', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:65407/session/8ea4366a8214d6c4e96db61aa217f070/url {"url": "http://smithgill.com/"}
DEBUG: http://localhost:65407 "POST /session/8ea4366a8214d6c4e96db61aa217f070/url HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:65407/session/8ea4366a8214d6c4e96db61aa217f070/timeouts {"implicit": 10000}
DEBUG: http://localhost:65407 "POST /session/8ea4366a8214d6c4e96db61aa217f070/timeouts HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: DELETE http://localhost:65407/session/8ea4366a8214d6c4e96db61aa217f070 {}
DEBUG: http://localhost:65407 "DELETE /session/8ea4366a8214d6c4e96db61aa217f070 HTTP/1.1" 200 14
DEBUG: Remote response: status=200 | data={"value":null} | headers=HTTPHeaderDict({'Content-Length': '14', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
DEBUG: Using driver at: C:\Users\moffi\.cache\selenium\chromedriver\win32\108.0.5359.71\chromedriver.exe
DEBUG: Started executable: `chromedriver` in a child process with pid: 10520
DEBUG: POST http://localhost:65437/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": []}}}}
DEBUG: Starting new HTTP connection (1): localhost:65437
DEBUG: http://localhost:65437 "POST /session HTTP/1.1" 200 790
DEBUG: Remote response: status=200 | data={"value":{"capabilities":{"acceptInsecureCerts":false,"browserName":"chrome","browserVersion":"108.0.5359.98","chrome":{"chromedriverVersion":"108.0.5359.71 (1e0e3868ee06e91ad636a874420e3ca3ae3756ac-refs/branch-heads/5359@{#1016})","userDataDir":"C:\\Users\\moffi\\AppData\\Local\\Temp\\scoped_dir10520_673439773"},"goog:chromeOptions":{"debuggerAddress":"localhost:65440"},"networkConnectionEnabled":false,"pageLoadStrategy":"normal","platformName":"windows","proxy":{},"setWindowRect":true,"strictFileInteractability":false,"timeouts":{"implicit":0,"pageLoad":300000,"script":30000},"unhandledPromptBehavior":"dismiss and notify","webauthn:extension:credBlob":true,"webauthn:extension:largeBlob":true,"webauthn:virtualAuthenticators":true},"sessionId":"50cbad26a13fd6b61f7f7ff5be5b98ea"}} | headers=HTTPHeaderDict({'Content-Length': '790', 'Content-Type': 'application/json; charset=utf-8', 'cache-control': 'no-cache'})
DEBUG: Finished Request
DEBUG: POST http://localhost:65437/session/50cbad26a13fd6b61f7f7ff5be5b98ea/url {"url": "http://smithgill.com/"}
INFO: Received SIGINT, shutting down gracefully. Send again to force 
ERROR: Spider error processing <GET http://ohiotreecare.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1368, in getresponse
    response.begin()
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 317, in begin
    version, status, reason = self._read_status()
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 278, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 52, in parse_website
    driver.get("http://smithgill.com/")
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 455, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 442, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 294, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 316, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1368, in getresponse
    response.begin()
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 317, in begin
    version, status, reason = self._read_status()
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 278, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
DEBUG: Crawled (200) <GET https://starwoodtree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/> (referer: None)
INFO: Closing spider (shutdown)
DEBUG: Scraped from <200 https://www.treetechohio.com/contact>
{'emails': ['8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            'info@mysite.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'http://www.facebook.com/wix',
 'instagram': '',
 'linkedin': '',
 'twitter': 'http://www.twitter.com/wix'}
DEBUG: driver not found in PATH, trying Selenium Manager
DEBUG: Executing: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome
INFO: Received SIGINT twice, forcing unclean shutdown
DEBUG: Unable to obtain driver using Selenium Manager: Selenium manager failed for: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome. 
ERROR: Spider error processing <GET https://www.hardwicktreecare.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\service.py", line 97, in start
    path = SeleniumManager().driver_location(browser)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\selenium_manager.py", line 74, in driver_location
    result = self.run((binary, flag, browser))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\selenium_manager.py", line 93, in run
    raise SeleniumManagerException(f"Selenium manager failed for: {command}. {stderr}")
selenium.common.exceptions.SeleniumManagerException: Message: Selenium manager failed for: C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe --browser chrome. 


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 49, in parse_website
    driver = webdriver.Chrome(desired_capabilities=desired_capabilities)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 81, in __init__
    super().__init__(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\chromium\webdriver.py", line 103, in __init__
    self.service.start()
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\service.py", line 100, in start
    raise err
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\service.py", line 90, in start
    self._start_process(self.path)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\selenium\webdriver\common\service.py", line 213, in _start_process
    raise WebDriverException(
selenium.common.exceptions.WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home

DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://www.hackettstreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 https://www.tackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Retrying <GET https://herculestree.com/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
DEBUG: Retrying <GET https://www.treesaremybusiness.com/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
DEBUG: Retrying <GET https://specialtytreeohio.com/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 25ca2007c0ebc7ae
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1390804873184 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1390804873184 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1390804873184 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1390804873184 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/robots.txt> from <GET http://www.fandftrees.com/robots.txt>
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Crawled (403) <GET https://www.midohiotree.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/robots.txt> (referer: None)
DEBUG: Filtered duplicate request: <GET http://hardwicktreecare.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (404) <GET http://ohiotreeandexcavating.net/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/> from <GET http://www.fandftrees.com/>
DEBUG: Crawled (403) <GET https://www.midohiotree.org/> (referer: None)
INFO: Ignoring response <403 https://trapperstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hardwicktreecare.com/> from <GET http://hardwicktreecare.com/>
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/robots.txt> from <GET http://starwoodtree.com/robots.txt>
INFO: Ignoring response <403 https://www.midohiotree.org/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.net/>
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/robots.txt> from <GET http://ohiotreeandexcavating.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.com/>
DEBUG: Crawled (200) <GET https://www.treetechohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET http://ohiotreecare.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown> (referer: None)
DEBUG: Crawled (200) <GET http://herculestree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treesaremybusiness.com/> from <GET http://www.treesaremybusiness.com/>
INFO: Ignoring response <403 https://www.tackettstreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.hackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://deeprootedtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/contact> (referer: https://www.treetechohio.com/)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://herculestree.com/> from <GET http://herculestree.com/>
DEBUG: Scraped from <200 https://www.treetechohio.com/contact>
{'emails': ['8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'info@mysite.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'http://www.facebook.com/wix',
 'instagram': '',
 'linkedin': '',
 'twitter': 'http://www.twitter.com/wix'}
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://treesaremybusiness.com/> from <GET https://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET https://www.whymonster.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.monstertreeservice.com/akron/contact-us/> from <GET https://www.whymonster.com/akron/contact-us/>
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/> from <GET http://starwoodtree.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/contact-us/> (referer: https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/akron/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsterTreeServiceofAkron/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://herculestree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://ohiotreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://herculestree.com/contact/> from <GET https://herculestree.com/contact>
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/contact-us/> (referer: https://treesaremybusiness.com/)
DEBUG: Scraped from <200 https://treesaremybusiness.com/contact-us/>
{'emails': ['millcraft@treesaremybusiness.com',
            'office@treesaremybusiness.com'],
 'facebook': 'https://www.facebook.com/treesaremybusinessohio/',
 'instagram': 'https://www.instagram.com/trees_are_my_business/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/contact-hardwick-tree-care> (referer: https://www.hardwicktreecare.com/)
DEBUG: Scraped from <200 https://www.hardwicktreecare.com/contact-hardwick-tree-care>
{'emails': ['8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'info@HardwickTreeCare.com',
            'f1ffc0b5efe04e9eb9762cd808722520@sentry.wixpress.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'https://www.facebook.com/hardwicktreecarellc',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://herculestree.com/contact/request-quote/> from <GET https://herculestree.com/contact/request-quote>
DEBUG: Crawled (200) <GET https://starwoodtree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/> (referer: https://herculestree.com/)
DEBUG: Scraped from <200 https://herculestree.com/contact/>
{'emails': ['Herculestree@gmail.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote/> (referer: https://herculestree.com/)
DEBUG: Scraped from <200 https://herculestree.com/contact/request-quote/>
{'emails': ['info@herculesTrees.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://starwoodtree.com/contact-us/> (referer: https://starwoodtree.com/)
DEBUG: Scraped from <200 https://starwoodtree.com/contact-us/>
{'emails': ['support@starwoodtree.com'],
 'facebook': 'https://www.facebook.com/Starwoodtreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
INFO: Closing spider (finished)
INFO: Stored json feed (7 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 14771,
 'downloader/request_count': 59,
 'downloader/request_method_count/GET': 59,
 'downloader/response_bytes': 850618,
 'downloader/response_count': 59,
 'downloader/response_status_count/200': 33,
 'downloader/response_status_count/301': 14,
 'downloader/response_status_count/403': 10,
 'downloader/response_status_count/404': 2,
 'dupefilter/filtered': 13,
 'elapsed_time_seconds': 5.776223,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 20, 29, 7, 336495),
 'httpcompression/response_bytes': 3778716,
 'httpcompression/response_count': 41,
 'httperror/response_ignored_count': 5,
 'httperror/response_ignored_status_count/403': 5,
 'item_scraped_count': 7,
 'log_count/DEBUG': 92,
 'log_count/INFO': 16,
 'request_depth_max': 1,
 'response_received_count': 45,
 'robotstxt/request_count': 21,
 'robotstxt/response_count': 21,
 'robotstxt/response_status_count/200': 14,
 'robotstxt/response_status_count/403': 5,
 'robotstxt/response_status_count/404': 2,
 'scheduler/dequeued': 35,
 'scheduler/dequeued/memory': 35,
 'scheduler/enqueued': 35,
 'scheduler/enqueued/memory': 35,
 'start_time': datetime.datetime(2022, 12, 8, 20, 29, 1, 560272)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: ff2174d84724c45c
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 3180317303680 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 3180317303680 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 3180317303680 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 3180317303680 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/robots.txt> from <GET http://www.fandftrees.com/robots.txt>
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Crawled (403) <GET https://www.midohiotree.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/robots.txt> (referer: None)
DEBUG: Filtered duplicate request: <GET http://hardwicktreecare.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/> (referer: None)
INFO: Ignoring response <403 https://trapperstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/> from <GET http://www.fandftrees.com/>
DEBUG: Crawled (200) <GET http://hardwicktreecare.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://www.midohiotree.org/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.fandftrees.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hardwicktreecare.com/> from <GET http://hardwicktreecare.com/>
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/robots.txt> from <GET http://starwoodtree.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.treetechohio.com/contact> (referer: https://www.treetechohio.com/)
DEBUG: Crawled (404) <GET http://ohiotreeandexcavating.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.treetechohio.com/contact>
{'emails': ['605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'info@mysite.com'],
 'facebook': 'http://www.facebook.com/wix',
 'instagram': '',
 'linkedin': '',
 'twitter': 'http://www.twitter.com/wix'}
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.net/>
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/robots.txt> from <GET http://ohiotreeandexcavating.com/robots.txt>
DEBUG: Crawled (200) <GET http://herculestree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/> (referer: None)
DEBUG: Crawled (404) <GET http://ohiotreecare.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://www.tackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.com/>
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://www.hackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://herculestree.com/> from <GET http://herculestree.com/>
INFO: Ignoring response <403 http://deeprootedtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treesaremybusiness.com/> from <GET http://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/> (referer: None)
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.whymonster.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.monstertreeservice.com/akron/contact-us/> from <GET https://www.whymonster.com/akron/contact-us/>
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/> from <GET http://starwoodtree.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/contact-us/> (referer: https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/akron/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsterTreeServiceofAkron/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET http://ohiotreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://treesaremybusiness.com/> from <GET https://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET https://herculestree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/contact-hardwick-tree-care> (referer: https://www.hardwicktreecare.com/)
DEBUG: Scraped from <200 https://www.hardwicktreecare.com/contact-hardwick-tree-care>
{'emails': ['605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'info@HardwickTreeCare.com',
            'f1ffc0b5efe04e9eb9762cd808722520@sentry.wixpress.com'],
 'facebook': 'https://www.facebook.com/hardwicktreecarellc',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://herculestree.com/contact/> (referer: https://herculestree.com/)
DEBUG: Scraped from <200 https://herculestree.com/contact/>
{'emails': ['Herculestree@gmail.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/> (referer: None)
DEBUG: Scraped from <200 https://herculestree.com/contact>
{'emails': ['Herculestree@gmail.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://herculestree.com/contact/request-quote>
{'emails': ['info@herculesTrees.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://herculestree.com/contact/request-quote/>
{'emails': ['info@herculesTrees.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://starwoodtree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/contact-us/> (referer: https://treesaremybusiness.com/)
DEBUG: Scraped from <200 https://treesaremybusiness.com/contact-us/>
{'emails': ['office@treesaremybusiness.com',
            'millcraft@treesaremybusiness.com'],
 'facebook': 'https://www.facebook.com/treesaremybusinessohio/',
 'instagram': 'https://www.instagram.com/trees_are_my_business/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://starwoodtree.com/contact-us/> (referer: https://starwoodtree.com/)
DEBUG: Scraped from <200 https://starwoodtree.com/contact-us/>
{'emails': ['support@starwoodtree.com'],
 'facebook': 'https://www.facebook.com/Starwoodtreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
INFO: Closing spider (finished)
INFO: Stored json feed (9 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 14769,
 'downloader/request_count': 59,
 'downloader/request_method_count/GET': 59,
 'downloader/response_bytes': 870249,
 'downloader/response_count': 59,
 'downloader/response_status_count/200': 35,
 'downloader/response_status_count/301': 12,
 'downloader/response_status_count/403': 10,
 'downloader/response_status_count/404': 2,
 'dupefilter/filtered': 11,
 'elapsed_time_seconds': 5.78635,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 20, 31, 54, 760248),
 'httpcompression/response_bytes': 3895744,
 'httpcompression/response_count': 43,
 'httperror/response_ignored_count': 5,
 'httperror/response_ignored_status_count/403': 5,
 'item_scraped_count': 9,
 'log_count/DEBUG': 94,
 'log_count/INFO': 16,
 'request_depth_max': 1,
 'response_received_count': 47,
 'robotstxt/request_count': 21,
 'robotstxt/response_count': 21,
 'robotstxt/response_status_count/200': 14,
 'robotstxt/response_status_count/403': 5,
 'robotstxt/response_status_count/404': 2,
 'scheduler/dequeued': 35,
 'scheduler/dequeued/memory': 35,
 'scheduler/enqueued': 35,
 'scheduler/enqueued/memory': 35,
 'start_time': datetime.datetime(2022, 12, 8, 20, 31, 48, 973898)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: ee3c99733abc97ee
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1823293691728 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1823293691728 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1823293691728 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1823293691728 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/robots.txt> (referer: None)
DEBUG: Filtered duplicate request: <GET http://hardwicktreecare.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/robots.txt> from <GET http://www.fandftrees.com/robots.txt>
DEBUG: Crawled (403) <GET https://www.midohiotree.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://hardwicktreecare.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://trapperstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/> from <GET http://www.fandftrees.com/>
INFO: Ignoring response <403 https://www.midohiotree.org/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.hardwicktreecare.com/> from <GET http://hardwicktreecare.com/>
DEBUG: Crawled (200) <GET https://www.fandftrees.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/robots.txt> from <GET http://starwoodtree.com/robots.txt>
DEBUG: Crawled (404) <GET http://ohiotreeandexcavating.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/contact> (referer: https://www.treetechohio.com/)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.treetechohio.com/contact>
{'emails': ['605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            'info@mysite.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            '8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com'],
 'facebook': 'http://www.facebook.com/wix',
 'instagram': '',
 'linkedin': '',
 'twitter': 'http://www.twitter.com/wix'}
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.net/>
DEBUG: Crawled (200) <GET http://www.treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/robots.txt> from <GET http://ohiotreeandexcavating.com/robots.txt>
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://www.hackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treesaremybusiness.com/> from <GET http://www.treesaremybusiness.com/>
DEBUG: Crawled (404) <GET http://ohiotreecare.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.com/>
INFO: Ignoring response <403 https://www.tackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://deeprootedtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/contact-hardwick-tree-care> (referer: https://www.hardwicktreecare.com/)
DEBUG: Scraped from <200 https://www.hardwicktreecare.com/contact-hardwick-tree-care>
{'emails': ['605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'f1ffc0b5efe04e9eb9762cd808722520@sentry.wixpress.com',
            'info@HardwickTreeCare.com',
            '8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com'],
 'facebook': 'https://www.facebook.com/hardwicktreecarellc',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://treesaremybusiness.com/> from <GET https://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET https://www.whymonster.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/> (referer: None)
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET http://herculestree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.monstertreeservice.com/akron/contact-us/> from <GET https://www.whymonster.com/akron/contact-us/>
DEBUG: Crawled (200) <GET https://starwoodtree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/contact-us/> (referer: https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown)
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/> from <GET http://starwoodtree.com/>
DEBUG: Scraped from <200 https://www.monstertreeservice.com/akron/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsterTreeServiceofAkron/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://herculestree.com/> from <GET http://herculestree.com/>
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://ohiotreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/contact-us/> (referer: https://treesaremybusiness.com/)
DEBUG: Scraped from <200 https://treesaremybusiness.com/contact-us/>
{'emails': ['millcraft@treesaremybusiness.com',
            'office@treesaremybusiness.com'],
 'facebook': 'https://www.facebook.com/treesaremybusinessohio/',
 'instagram': 'https://www.instagram.com/trees_are_my_business/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://herculestree.com/contact> (referer: https://herculestree.com/)
DEBUG: Scraped from <200 https://herculestree.com/contact>
{'emails': ['Herculestree@gmail.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://starwoodtree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/> (referer: https://herculestree.com/)
DEBUG: Scraped from <200 https://herculestree.com/contact/request-quote/>
{'emails': ['info@herculesTrees.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote> (referer: https://herculestree.com/)
DEBUG: Scraped from <200 https://herculestree.com/contact/>
{'emails': ['Herculestree@gmail.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://herculestree.com/contact/request-quote>
{'emails': ['info@herculesTrees.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://starwoodtree.com/contact-us/> (referer: https://starwoodtree.com/)
DEBUG: Scraped from <200 https://starwoodtree.com/contact-us/>
{'emails': ['support@starwoodtree.com'],
 'facebook': 'https://www.facebook.com/Starwoodtreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
INFO: Closing spider (finished)
INFO: Stored json feed (9 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 14767,
 'downloader/request_count': 59,
 'downloader/request_method_count/GET': 59,
 'downloader/response_bytes': 869431,
 'downloader/response_count': 59,
 'downloader/response_status_count/200': 35,
 'downloader/response_status_count/301': 12,
 'downloader/response_status_count/403': 10,
 'downloader/response_status_count/404': 2,
 'dupefilter/filtered': 11,
 'elapsed_time_seconds': 6.197123,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 20, 39, 3, 545492),
 'httpcompression/response_bytes': 3894458,
 'httpcompression/response_count': 43,
 'httperror/response_ignored_count': 5,
 'httperror/response_ignored_status_count/403': 5,
 'item_scraped_count': 9,
 'log_count/DEBUG': 94,
 'log_count/INFO': 16,
 'request_depth_max': 1,
 'response_received_count': 47,
 'robotstxt/request_count': 21,
 'robotstxt/response_count': 21,
 'robotstxt/response_status_count/200': 14,
 'robotstxt/response_status_count/403': 5,
 'robotstxt/response_status_count/404': 2,
 'scheduler/dequeued': 35,
 'scheduler/dequeued/memory': 35,
 'scheduler/enqueued': 35,
 'scheduler/enqueued/memory': 35,
 'start_time': datetime.datetime(2022, 12, 8, 20, 38, 57, 348369)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 6705490c6e050424
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/robots.txt> from <GET http://www.fandftrees.com/robots.txt>
DEBUG: Attempting to acquire lock 2808013923872 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2808013923872 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2808013923872 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2808013923872 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.treetechohio.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/> from <GET http://www.fandftrees.com/>
DEBUG: Crawled (403) <GET https://www.midohiotree.org/robots.txt> (referer: None)
DEBUG: Filtered duplicate request: <GET http://hardwicktreecare.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.charteroakscompany.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://trapperstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://www.midohiotree.org/> (referer: None)
DEBUG: Crawled (200) <GET http://hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/robots.txt> from <GET http://starwoodtree.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.treetechohio.com/contact> (referer: https://www.treetechohio.com/)
INFO: Ignoring response <403 https://www.midohiotree.org/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.hardwicktreecare.com/> from <GET http://hardwicktreecare.com/>
DEBUG: Crawled (404) <GET http://ohiotreeandexcavating.net/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.treetechohio.com/contact>
{'emails': ['info@mysite.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com'],
 'facebook': 'http://www.facebook.com/wix',
 'instagram': '',
 'linkedin': '',
 'twitter': 'http://www.twitter.com/wix'}
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.net/>
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/robots.txt> from <GET http://ohiotreeandexcavating.com/robots.txt>
DEBUG: Crawled (200) <GET http://www.treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.com/>
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/contact-hardwick-tree-care> (referer: https://www.hardwicktreecare.com/)
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://www.tackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.charteroakscompany.com/> from <GET http://www.charteroakscompany.com/>
DEBUG: Scraped from <200 https://www.hardwicktreecare.com/contact-hardwick-tree-care>
{'emails': ['f1ffc0b5efe04e9eb9762cd808722520@sentry.wixpress.com',
            'info@HardwickTreeCare.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com'],
 'facebook': 'https://www.facebook.com/hardwicktreecarellc',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown> (referer: None)
DEBUG: Crawled (404) <GET http://ohiotreecare.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://www.treesaremybusiness.com/> from <GET http://www.treesaremybusiness.com/>
INFO: Ignoring response <403 http://www.hackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://deeprootedtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/robots.txt> from <GET http://timberlandtreeohio.com/robots.txt>
DEBUG: Crawled (200) <GET https://starwoodtree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/> (referer: None)
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET http://herculestree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.charteroakscompany.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/> from <GET http://starwoodtree.com/>
DEBUG: Crawled (200) <GET https://www.independenttree.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://cottstrees.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://treesaremybusiness.com/> from <GET https://www.treesaremybusiness.com/>
DEBUG: Crawled (403) <GET http://cottstrees.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://herculestree.com/> from <GET http://herculestree.com/>
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/robots.txt> from <GET http://www.jstreeservicesllc.com/robots.txt>
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://cottstrees.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.whymonster.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.monstertreeservice.com/akron/contact-us/> from <GET https://www.whymonster.com/akron/contact-us/>
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/> from <GET http://timberlandtreeohio.com/>
DEBUG: Crawled (200) <GET https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website> (referer: None)
DEBUG: Redirecting (301) to <GET https://roquetree.com/robots.txt> from <GET http://roquetree.com/robots.txt>
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://ohiotreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/contact-us/> (referer: https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown)
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/robots.txt> from <GET http://www.basictreecare.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.independenttree.com/contact-us/> (referer: https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/akron/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsterTreeServiceofAkron/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://www.independenttree.com/contact-us/>
{'emails': ['info@independenttree.com'],
 'facebook': 'https://www.facebook.com/IndependentTreeOH/',
 'instagram': 'https://www.instagram.com/independenttreeservice/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://herculestree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.kiddertreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/contact-us/> (referer: https://www.ewsmithtree.com/)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/cleveland/?utm_source=GMB&utm_medium=organic&utm_campaign=AvonLake> (referer: None)
DEBUG: Redirecting (301) to <GET https://jstreeservicesllc.com/> from <GET http://www.jstreeservicesllc.com/>
DEBUG: Redirecting (301) to <GET https://www.kiddertreemov.com/> from <GET http://www.kiddertreeservice.com/>
DEBUG: Scraped from <200 https://www.ewsmithtree.com/contact-us/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://roquetree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/robots.txt> from <GET http://www.haneytreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.basictreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://roquetree.com/> from <GET http://roquetree.com/>
DEBUG: Crawled (200) <GET https://starwoodtree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/> from <GET http://www.basictreecare.com/>
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/robots.txt> from <GET http://www.jttreeservicellc.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.roquetree.com/> from <GET https://roquetree.com/>
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/contact-us/> (referer: https://treesaremybusiness.com/)
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/> (referer: None)
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://treesaremybusiness.com/contact-us/>
{'emails': ['office@treesaremybusiness.com',
            'millcraft@treesaremybusiness.com'],
 'facebook': 'https://www.facebook.com/treesaremybusinessohio/',
 'instagram': 'https://www.instagram.com/trees_are_my_business/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.basictreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/> from <GET http://www.haneytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://herculestree.com/contact/> from <GET https://herculestree.com/contact>
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/index.html> from <GET http://haneytreeservice.com/>
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.roquetree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://www.kandatreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/robots.txt> from <GET http://www.ripleytreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.roquetree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus> (referer: None)
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/> from <GET http://www.jttreeservicellc.com/>
DEBUG: Crawled (200) <GET http://haneytreeservice.com/index.html> (referer: None)
INFO: Ignoring response <403 http://www.jjsfamilytreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://parkstree.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/cincinnati-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Cincinnati> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/contact-us/> (referer: https://starwoodtree.com/)
DEBUG: Crawled (200) <GET https://parkstree.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://starwoodtree.com/contact-us/>
{'emails': ['support@starwoodtree.com'],
 'facebook': 'https://www.facebook.com/Starwoodtreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/> from <GET http://www.ripleytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://rawtreeserv.com/> from <GET https://www.rawtreeserv.com/>
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/robots.txt> from <GET https://www.extremetreeservicestoledo.com/robots.txt>
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/contact-us/> from <GET http://www.jstreeservicesllc.com/contact-us>
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/contact-us/> (referer: https://jstreeservicesllc.com/)
DEBUG: Scraped from <200 https://jstreeservicesllc.com/contact-us/>
{'emails': ['j_s.tree@yahoo.com'],
 'facebook': 'http://www.facebook.com/jandstreeservices',
 'instagram': 'http://www.instagram.com/jandstreeservices',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonresidential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=nonresidential>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Retrying <GET https://challengerstreeservice.com/robots.txt> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
DEBUG: Crawled (200) <GET https://parkstree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/contact-us/> (referer: None)
DEBUG: Crawled (200) <GET https://rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 http://jstreeservicesllc.com/contact-us/>
{'emails': ['j_s.tree@yahoo.com'],
 'facebook': 'http://www.facebook.com/jandstreeservices',
 'instagram': 'http://www.instagram.com/jandstreeservices',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://parkstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.savatree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://rawtreeserv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://blackstreemov.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.blackstreemov.com/> from <GET http://blackstreemov.com/>
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonservicerequest> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
INFO: Ignoring response <403 http://www.haymakertreeandlawn.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/northeast-cleveland-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Northeast%20Cleveland> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=nonservicerequest>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=residential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/> from <GET https://www.extremetreeservicestoledo.com/>
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=residential>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://www.cstreemulch.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/> (referer: None)
INFO: Ignoring response <403 http://www.ashtreeservicepro.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.savatree.com/dayton-ohio-tree-service-lawn-care?utm_source=GMB&utm_medium=organic&utm_campaign=dayton> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/robots.txt> from <GET http://toddstreeservice.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/robots.txt> from <GET http://www.roguetreesolutions.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/robots.txt> from <GET http://hoffmantreeservice.com/robots.txt>
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://www.roguetreesolutions.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 52 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 59 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 109 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 111 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 119 without any user agent to enforce it on.
DEBUG: Rule at line 120 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 128 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 155 without any user agent to enforce it on.
DEBUG: Rule at line 165 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/> from <GET http://toddstreeservice.com/>
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/> from <GET http://www.roguetreesolutions.com/>
DEBUG: Crawled (200) <GET https://www.roguetreesolutions.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/> from <GET http://hoffmantreeservice.com/>
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/> (referer: None)
DEBUG: Crawled (200) <GET http://urbanloggersohio.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://herculestree.com/contact/request-quote/> from <GET https://herculestree.com/contact/request-quote>
DEBUG: Redirecting (301) to <GET https://urbanloggersohio.com/> from <GET http://urbanloggersohio.com/>
INFO: Ignoring response <403 http://www.toddstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://extremetreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 5 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 19 without any user agent to enforce it on.
DEBUG: Rule at line 21 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 34 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 60 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 68 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 73 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Rule at line 75 without any user agent to enforce it on.
DEBUG: Rule at line 76 without any user agent to enforce it on.
DEBUG: Rule at line 77 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 83 without any user agent to enforce it on.
DEBUG: Rule at line 85 without any user agent to enforce it on.
DEBUG: Rule at line 86 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 89 without any user agent to enforce it on.
DEBUG: Rule at line 90 without any user agent to enforce it on.
DEBUG: Rule at line 91 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 93 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 95 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 99 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 102 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 113 without any user agent to enforce it on.
DEBUG: Rule at line 114 without any user agent to enforce it on.
DEBUG: Rule at line 115 without any user agent to enforce it on.
DEBUG: Rule at line 116 without any user agent to enforce it on.
DEBUG: Rule at line 117 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Crawled (404) <GET http://www.boonestreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Retrying <GET https://challengerstreeservice.com/robots.txt> (failed 2 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET http://www.boonestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/contact> (referer: https://www.blackstreemov.com/)
DEBUG: Scraped from <200 https://www.blackstreemov.com/contact>
{'emails': ['blackstreeservice140@gmail.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            'BlacksTreeService140@gmail.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com'],
 'facebook': 'https://www.facebook.com/pages/Blacks-Tree-Service/205784306214398',
 'instagram': 'http://instagram.com/wix',
 'linkedin': '',
 'twitter': 'https://twitter.com/BlacksTreeMOV'}
DEBUG: Redirecting (301) to <GET https://barbertontree.com/robots.txt> from <GET https://www.barbertontree.com/robots.txt>
DEBUG: Redirecting (302) to <GET https://www.greatdanetreeexperts.com/404.html> from <GET https://www.greatdanetreeexperts.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/robots.txt> from <GET http://tree-works-ohio.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/404.html> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 136 without any user agent to enforce it on.
DEBUG: Rule at line 141 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 147 without any user agent to enforce it on.
DEBUG: Rule at line 156 without any user agent to enforce it on.
DEBUG: Rule at line 157 without any user agent to enforce it on.
DEBUG: Rule at line 191 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://premiertreesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/contact/> (referer: https://extremetreeservicestoledo.com/)
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/> (referer: None)
DEBUG: Retrying <GET https://premiertreesllc.com/> (failed 1 times): 429 Unknown Status
DEBUG: Scraped from <200 https://extremetreeservicestoledo.com/contact/>
{'emails': ['extremetreeswanton@gmail.com'],
 'facebook': 'https://www.facebook.com/ToledosExtremeTree/',
 'instagram': '',
 'linkedin': '',
 'twitter': 'https://twitter.com/SuperClimber101'}
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/> (referer: None)
DEBUG: Retrying <GET https://premiertreesllc.com/> (failed 2 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/robots.txt> from <GET http://www.treeservicenow.net/robots.txt>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/akron-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Akron> (referer: None)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://brushbandittree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://barbertontree.com/> from <GET https://www.barbertontree.com/>
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/> (referer: None)
DEBUG: Retrying <GET https://barbertontree.com/robots.txt> (failed 1 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/robots.txt> from <GET http://www.lamannatreeservice.com/robots.txt>
DEBUG: Retrying <GET https://barbertontree.com/robots.txt> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://herculestree.com/contact/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/contact-urban-loggers/> (referer: https://urbanloggersohio.com/)
DEBUG: Crawled (200) <GET https://premiertreesllc.com/> (referer: None)
DEBUG: Scraped from <200 https://herculestree.com/contact/>
{'emails': ['Herculestree@gmail.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://urbanloggersohio.com/contact-urban-loggers/>
{'emails': ['Info@urbanloggersohio.com'],
 'facebook': '',
 'instagram': 'https://www.instagram.com/urbanloggersllc/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://brushbandittree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/contact-us/> (referer: http://www.treeservicedelawareoh.com/)
DEBUG: Retrying <GET https://barbertontree.com/> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote/> (referer: https://herculestree.com/)
DEBUG: Scraped from <200 http://www.treeservicedelawareoh.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/biz/43015/James-Tree-Service/194987980849287/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/robots.txt> from <GET https://www.treeservicenow.net/robots.txt>
DEBUG: Crawled (200) <GET https://larochetree.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 1 times): 429 Unknown Status
DEBUG: Scraped from <200 https://herculestree.com/contact/request-quote/>
{'emails': ['info@herculesTrees.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Retrying <GET https://barbertontree.com/> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/?utm_source=googlelocal&utm_medium=organic> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.larochetree.com/> from <GET https://larochetree.com/>
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 2 times): 429 Unknown Status
ERROR: Gave up retrying <GET https://barbertontree.com/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://barbertontree.com/> (referer: None)
DEBUG: Crawled (403) <GET http://tomcotreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/robots.txt> (referer: None)
INFO: Ignoring response <429 https://barbertontree.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
ERROR: Gave up retrying <GET https://premiertreesllc.com/contact-us/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://premiertreesllc.com/contact-us/> (referer: https://premiertreesllc.com/)
DEBUG: Crawled (403) <GET http://tomcotreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.larochetree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://brushbandittree.com/contact-us/> (referer: https://brushbandittree.com/)
INFO: Ignoring response <429 https://premiertreesllc.com/contact-us/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://tomcotreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/robots.txt> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 38, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://brushbandittree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/brushbandittree/',
 'instagram': 'https://www.instagram.com/brushband1t/',
 'linkedin': '',
 'twitter': 'https://twitter.com/brushband1t%20'}
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
INFO: Ignoring response <403 http://www.dolcestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/> from <GET http://www.treeservicenow.net/>
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/> from <GET http://www.lamannatreeservice.com/>
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/> from <GET https://www.treeservicenow.net/>
ERROR: Gave up retrying <GET https://challengerstreeservice.com/robots.txt> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
ERROR: Error downloading <GET https://challengerstreeservice.com/robots.txt>: Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
DEBUG: Crawled (404) <GET https://www.napierandson.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.napierandson.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.larochetree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.larochetree.com/contact> (referer: https://www.larochetree.com/)
DEBUG: Scraped from <200 https://www.larochetree.com/contact>
{'emails': ['ContactUs@larochetree.com',
            'contactus@larochetree.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'dd0a55ccb8124b9c9d938e3acf41f8aa@sentry.wixpress.com'],
 'facebook': 'https://www.facebook.com/LaRocheTree',
 'instagram': 'https://www.instagram.com/LaRochetree/',
 'linkedin': 'https://www.linkedin.com/company/laroche-tree-service-inc',
 'twitter': 'https://twitter.com/larochetree'}
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/contact/> (referer: https://lamannatreeservice.com/)
DEBUG: Scraped from <200 https://lamannatreeservice.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/lamannatreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://treeservicenow.net/> (referer: None)
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/> from <GET http://tree-works-ohio.com/>
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/contact-us/> (referer: https://treeservicecolumbusohio.net/)
DEBUG: Retrying <GET https://challengerstreeservice.com/> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
DEBUG: Scraped from <200 https://treeservicecolumbusohio.net/contact-us/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/contact-tree-works-for-all-your-emergency-services-tree-removal-stump-grinding-etc/> (referer: https://tree-works-ohio.com/)
DEBUG: Crawled (200) <GET https://treeservicenow.net/contact_us_1> (referer: https://treeservicenow.net/)
DEBUG: Scraped from <200 https://tree-works-ohio.com/contact-tree-works-for-all-your-emergency-services-tree-removal-stump-grinding-etc/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Scraped from <200 https://treeservicenow.net/contact_us_1>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Retrying <GET https://challengerstreeservice.com/> (failed 2 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
ERROR: Gave up retrying <GET https://challengerstreeservice.com/> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
ERROR: Error downloading <GET https://challengerstreeservice.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
INFO: Closing spider (finished)
INFO: Stored json feed (24 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 6,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 6,
 'downloader/request_bytes': 66794,
 'downloader/request_count': 250,
 'downloader/request_method_count/GET': 250,
 'downloader/response_bytes': 3462199,
 'downloader/response_count': 244,
 'downloader/response_status_count/200': 142,
 'downloader/response_status_count/301': 57,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/403': 29,
 'downloader/response_status_count/404': 5,
 'downloader/response_status_count/429': 10,
 'dupefilter/filtered': 61,
 'elapsed_time_seconds': 22.584587,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 8, 22, 24, 33, 573578),
 'httpcompression/response_bytes': 14647156,
 'httpcompression/response_count': 153,
 'httperror/response_ignored_count': 16,
 'httperror/response_ignored_status_count/403': 14,
 'httperror/response_ignored_status_count/429': 2,
 'item_scraped_count': 24,
 'log_count/DEBUG': 477,
 'log_count/ERROR': 7,
 'log_count/INFO': 27,
 'request_depth_max': 1,
 'response_received_count': 178,
 'retry/count': 12,
 'retry/max_reached': 4,
 'retry/reason_count/429 Unknown Status': 8,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 4,
 "robotstxt/exception_count/<class 'twisted.internet.error.ConnectionRefusedError'>": 1,
 'robotstxt/request_count': 84,
 'robotstxt/response_count': 83,
 'robotstxt/response_status_count/200': 63,
 'robotstxt/response_status_count/403': 15,
 'robotstxt/response_status_count/404': 5,
 'scheduler/dequeued': 140,
 'scheduler/dequeued/memory': 140,
 'scheduler/enqueued': 140,
 'scheduler/enqueued/memory': 140,
 'start_time': datetime.datetime(2022, 12, 8, 22, 24, 10, 988991)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: f072a400819b4b92
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/robots.txt> from <GET http://www.fandftrees.com/robots.txt>
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Attempting to acquire lock 1681995291408 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1681995291408 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1681995291408 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1681995291408 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://trapperstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.charteroakscompany.com/robots.txt> (referer: None)
DEBUG: Filtered duplicate request: <GET http://hardwicktreecare.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/> (referer: None)
INFO: Ignoring response <403 https://www.midohiotree.org/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/robots.txt> from <GET http://starwoodtree.com/robots.txt>
DEBUG: Crawled (200) <GET http://hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hardwicktreecare.com/> from <GET http://hardwicktreecare.com/>
DEBUG: Crawled (404) <GET http://ohiotreeandexcavating.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/> from <GET http://www.fandftrees.com/>
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.net/>
DEBUG: Crawled (200) <GET https://www.treetechohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/robots.txt> from <GET http://ohiotreeandexcavating.com/robots.txt>
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.charteroakscompany.com/> from <GET http://www.charteroakscompany.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown> (referer: None)
DEBUG: Crawled (200) <GET http://www.treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET http://ohiotreecare.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/> (referer: None)
INFO: Ignoring response <403 https://www.tackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.treesaremybusiness.com/> from <GET http://www.treesaremybusiness.com/>
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/> (referer: None)
INFO: Ignoring response <403 http://www.hackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://starwoodtree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/contact> (referer: https://www.treetechohio.com/)
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.charteroakscompany.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://herculestree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.com/>
DEBUG: Scraped from <200 https://www.treetechohio.com/contact>
{'emails': ['8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            'info@mysite.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com'],
 'facebook': 'http://www.facebook.com/wix',
 'instagram': '',
 'linkedin': '',
 'twitter': 'http://www.twitter.com/wix'}
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/> from <GET http://starwoodtree.com/>
INFO: Ignoring response <403 http://deeprootedtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://treesaremybusiness.com/> from <GET https://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET https://www.whymonster.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.monstertreeservice.com/akron/contact-us/> from <GET https://www.whymonster.com/akron/contact-us/>
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/robots.txt> from <GET http://timberlandtreeohio.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://herculestree.com/> from <GET http://herculestree.com/>
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/contact-hardwick-tree-care> (referer: https://www.hardwicktreecare.com/)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/contact-us/> (referer: https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown)
DEBUG: Crawled (200) <GET https://www.independenttree.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.hardwicktreecare.com/contact-hardwick-tree-care>
{'emails': ['8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            'f1ffc0b5efe04e9eb9762cd808722520@sentry.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'info@HardwickTreeCare.com'],
 'facebook': 'https://www.facebook.com/hardwicktreecarellc',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/akron/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsterTreeServiceofAkron/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://cottstrees.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://cottstrees.com/> (referer: None)
INFO: Ignoring response <403 http://cottstrees.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/> from <GET http://timberlandtreeohio.com/>
DEBUG: Redirecting (301) to <GET https://roquetree.com/robots.txt> from <GET http://roquetree.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/robots.txt> from <GET http://www.basictreecare.com/robots.txt>
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/robots.txt> from <GET http://www.haneytreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/contact-us/> (referer: https://treesaremybusiness.com/)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/cleveland/?utm_source=GMB&utm_medium=organic&utm_campaign=AvonLake> (referer: None)
DEBUG: Scraped from <200 https://treesaremybusiness.com/contact-us/>
{'emails': ['millcraft@treesaremybusiness.com',
            'office@treesaremybusiness.com'],
 'facebook': 'https://www.facebook.com/treesaremybusinessohio/',
 'instagram': 'https://www.instagram.com/trees_are_my_business/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://roquetree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.basictreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://ohiotreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://roquetree.com/> from <GET http://roquetree.com/>
DEBUG: Crawled (200) <GET http://www.kiddertreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/contact-us/> (referer: https://www.ewsmithtree.com/)
DEBUG: Redirecting (301) to <GET https://www.kiddertreemov.com/> from <GET http://www.kiddertreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/> from <GET http://www.basictreecare.com/>
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.ewsmithtree.com/contact-us/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://www.roquetree.com/> from <GET https://roquetree.com/>
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/> from <GET http://www.haneytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.basictreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.independenttree.com/contact-us/> (referer: https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/robots.txt> from <GET http://www.jttreeservicellc.com/robots.txt>
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.independenttree.com/contact-us/>
{'emails': ['info@independenttree.com'],
 'facebook': 'https://www.facebook.com/IndependentTreeOH/',
 'instagram': 'https://www.instagram.com/independenttreeservice/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/index.html> from <GET http://haneytreeservice.com/>
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/robots.txt> from <GET http://www.jstreeservicesllc.com/robots.txt>
INFO: Ignoring response <403 https://www.kandatreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/robots.txt> from <GET http://www.ripleytreeservice.com/robots.txt>
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.roquetree.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://www.jjsfamilytreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://haneytreeservice.com/index.html> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/contact-us/> (referer: https://starwoodtree.com/)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.roquetree.com/> (referer: None)
DEBUG: Scraped from <200 https://starwoodtree.com/contact-us/>
{'emails': ['support@starwoodtree.com'],
 'facebook': 'https://www.facebook.com/Starwoodtreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://parkstree.net/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/> from <GET http://www.jttreeservicellc.com/>
DEBUG: Crawled (200) <GET https://parkstree.net/> (referer: None)
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/> from <GET http://www.ripleytreeservice.com/>
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Redirecting (301) to <GET https://rawtreeserv.com/> from <GET https://www.rawtreeserv.com/>
DEBUG: Crawled (200) <GET https://parkstree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/cincinnati-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Cincinnati> (referer: None)
DEBUG: Redirecting (301) to <GET https://jstreeservicesllc.com/> from <GET http://www.jstreeservicesllc.com/>
DEBUG: Crawled (200) <GET https://rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/robots.txt> from <GET https://www.extremetreeservicestoledo.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.savatree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://rawtreeserv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=residential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/?utm_source=googlelocal&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET http://blackstreemov.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=residential>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (301) to <GET https://www.blackstreemov.com/> from <GET http://blackstreemov.com/>
INFO: Ignoring response <403 http://www.haymakertreeandlawn.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/> (referer: None)
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/northeast-cleveland-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Northeast%20Cleveland> (referer: None)
INFO: Ignoring response <403 http://www.cstreemulch.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
INFO: Ignoring response <403 http://www.ashtreeservicepro.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/robots.txt> from <GET http://toddstreeservice.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/robots.txt> from <GET http://www.roguetreesolutions.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/robots.txt> from <GET http://hoffmantreeservice.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/> from <GET https://www.extremetreeservicestoledo.com/>
DEBUG: Crawled (404) <GET https://www.roguetreesolutions.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 52 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 59 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 109 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 111 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 119 without any user agent to enforce it on.
DEBUG: Rule at line 120 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 128 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 155 without any user agent to enforce it on.
DEBUG: Rule at line 165 without any user agent to enforce it on.
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.savatree.com/dayton-ohio-tree-service-lawn-care?utm_source=GMB&utm_medium=organic&utm_campaign=dayton> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/> from <GET http://www.roguetreesolutions.com/>
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://urbanloggersohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.roguetreesolutions.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/> from <GET http://toddstreeservice.com/>
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://urbanloggersohio.com/> from <GET http://urbanloggersohio.com/>
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/> from <GET http://hoffmantreeservice.com/>
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/> (referer: None)
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeohio.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.toddstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (404) <GET http://www.boonestreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 5 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 19 without any user agent to enforce it on.
DEBUG: Rule at line 21 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 34 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 60 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 68 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 73 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Rule at line 75 without any user agent to enforce it on.
DEBUG: Rule at line 76 without any user agent to enforce it on.
DEBUG: Rule at line 77 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 83 without any user agent to enforce it on.
DEBUG: Rule at line 85 without any user agent to enforce it on.
DEBUG: Rule at line 86 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 89 without any user agent to enforce it on.
DEBUG: Rule at line 90 without any user agent to enforce it on.
DEBUG: Rule at line 91 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 93 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 95 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 99 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 102 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 113 without any user agent to enforce it on.
DEBUG: Rule at line 114 without any user agent to enforce it on.
DEBUG: Rule at line 115 without any user agent to enforce it on.
DEBUG: Rule at line 116 without any user agent to enforce it on.
DEBUG: Rule at line 117 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonservicerequest> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET http://www.boonestreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=nonservicerequest>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/contact-us/> from <GET http://www.jstreeservicesllc.com/contact-us>
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/contact/> (referer: https://extremetreeservicestoledo.com/)
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Scraped from <200 https://extremetreeservicestoledo.com/contact/>
{'emails': ['extremetreeswanton@gmail.com'],
 'facebook': 'https://www.facebook.com/ToledosExtremeTree/',
 'instagram': '',
 'linkedin': '',
 'twitter': 'https://twitter.com/SuperClimber101'}
DEBUG: Redirecting (302) to <GET https://www.greatdanetreeexperts.com/404.html> from <GET https://www.greatdanetreeexperts.com/robots.txt>
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/contact-us/> (referer: https://jstreeservicesllc.com/)
DEBUG: Redirecting (301) to <GET https://barbertontree.com/robots.txt> from <GET https://www.barbertontree.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/robots.txt> from <GET http://tree-works-ohio.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/404.html> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 136 without any user agent to enforce it on.
DEBUG: Rule at line 141 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 147 without any user agent to enforce it on.
DEBUG: Rule at line 156 without any user agent to enforce it on.
DEBUG: Rule at line 157 without any user agent to enforce it on.
DEBUG: Rule at line 191 without any user agent to enforce it on.
DEBUG: Scraped from <200 https://jstreeservicesllc.com/contact-us/>
{'emails': ['j_s.tree@yahoo.com'],
 'facebook': 'http://www.facebook.com/jandstreeservices',
 'instagram': 'http://www.instagram.com/jandstreeservices',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://premiertreesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonresidential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/> (referer: None)
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/contact-us/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=nonresidential>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/robots.txt> from <GET http://www.treeservicenow.net/robots.txt>
DEBUG: Retrying <GET https://premiertreesllc.com/> (failed 1 times): 429 Unknown Status
DEBUG: Scraped from <200 http://jstreeservicesllc.com/contact-us/>
{'emails': ['j_s.tree@yahoo.com'],
 'facebook': 'http://www.facebook.com/jandstreeservices',
 'instagram': 'http://www.instagram.com/jandstreeservices',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/akron-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Akron> (referer: None)
DEBUG: Retrying <GET https://premiertreesllc.com/> (failed 2 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/robots.txt> from <GET http://www.lamannatreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://brushbandittree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://larochetree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.larochetree.com/> from <GET https://larochetree.com/>
DEBUG: Crawled (200) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/> from <GET http://tree-works-ohio.com/>
DEBUG: Redirecting (301) to <GET https://barbertontree.com/> from <GET https://www.barbertontree.com/>
DEBUG: Retrying <GET https://barbertontree.com/robots.txt> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://premiertreesllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.larochetree.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://barbertontree.com/robots.txt> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (403) <GET http://tomcotreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/contact-urban-loggers/> (referer: https://urbanloggersohio.com/)
DEBUG: Crawled (403) <GET http://tomcotreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
DEBUG: Scraped from <200 https://urbanloggersohio.com/contact-urban-loggers/>
{'emails': ['Info@urbanloggersohio.com'],
 'facebook': '',
 'instagram': 'https://www.instagram.com/urbanloggersllc/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.larochetree.com/> (referer: None)
INFO: Ignoring response <403 http://tomcotreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
DEBUG: Retrying <GET https://barbertontree.com/> (failed 1 times): 429 Unknown Status
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/> (referer: None)
DEBUG: Retrying <GET https://barbertontree.com/> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/> (referer: None)
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 2 times): 429 Unknown Status
INFO: Ignoring response <403 http://www.dolcestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://brushbandittree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 38, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
ERROR: Gave up retrying <GET https://barbertontree.com/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://barbertontree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/contact> (referer: https://www.blackstreemov.com/)
ERROR: Gave up retrying <GET https://premiertreesllc.com/contact-us/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://premiertreesllc.com/contact-us/> (referer: https://premiertreesllc.com/)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/> from <GET http://www.lamannatreeservice.com/>
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
INFO: Ignoring response <429 https://barbertontree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
DEBUG: Crawled (200) <GET https://www.larochetree.com/contact> (referer: https://www.larochetree.com/)
DEBUG: Scraped from <200 https://www.blackstreemov.com/contact>
{'emails': ['605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            'BlacksTreeService140@gmail.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'blackstreeservice140@gmail.com'],
 'facebook': 'https://www.facebook.com/pages/Blacks-Tree-Service/205784306214398',
 'instagram': 'http://instagram.com/wix',
 'linkedin': '',
 'twitter': 'https://twitter.com/BlacksTreeMOV'}
INFO: Ignoring response <429 https://premiertreesllc.com/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.larochetree.com/contact>
{'emails': ['ContactUs@larochetree.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'contactus@larochetree.com',
            'dd0a55ccb8124b9c9d938e3acf41f8aa@sentry.wixpress.com'],
 'facebook': 'https://www.facebook.com/LaRocheTree',
 'instagram': 'https://www.instagram.com/LaRochetree/',
 'linkedin': 'https://www.linkedin.com/company/laroche-tree-service-inc',
 'twitter': 'https://twitter.com/larochetree'}
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://brushbandittree.com/contact-us/> (referer: https://brushbandittree.com/)
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/contact-tree-works-for-all-your-emergency-services-tree-removal-stump-grinding-etc/> (referer: https://tree-works-ohio.com/)
DEBUG: Scraped from <200 https://brushbandittree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/brushbandittree/',
 'instagram': 'https://www.instagram.com/brushband1t/',
 'linkedin': '',
 'twitter': 'https://twitter.com/brushband1t%20'}
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/> (referer: None)
DEBUG: Crawled (404) <GET https://www.napierandson.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://tree-works-ohio.com/contact-tree-works-for-all-your-emergency-services-tree-removal-stump-grinding-etc/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/> (referer: None)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.napierandson.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/robots.txt> from <GET https://www.treeservicenow.net/robots.txt>
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/contact-us/> (referer: http://www.treeservicedelawareoh.com/)
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/contact/> (referer: https://lamannatreeservice.com/)
DEBUG: Scraped from <200 http://www.treeservicedelawareoh.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/biz/43015/James-Tree-Service/194987980849287/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://herculestree.com/> (referer: None)
DEBUG: Scraped from <200 https://lamannatreeservice.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/lamannatreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/> from <GET http://www.treeservicenow.net/>
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/> from <GET https://www.treeservicenow.net/>
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://herculestree.com/contact> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://treeservicenow.net/> (referer: None)
DEBUG: Scraped from <200 https://herculestree.com/contact/>
{'emails': ['Herculestree@gmail.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://herculestree.com/contact>
{'emails': ['Herculestree@gmail.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://herculestree.com/contact/request-quote/> from <GET https://herculestree.com/contact/request-quote>
DEBUG: Crawled (200) <GET https://treeservicenow.net/contact_us_1> (referer: https://treeservicenow.net/)
DEBUG: Scraped from <200 https://treeservicenow.net/contact_us_1>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/contact-us/> (referer: https://treeservicecolumbusohio.net/)
DEBUG: Scraped from <200 https://herculestree.com/contact/request-quote/>
{'emails': ['info@herculesTrees.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://treeservicecolumbusohio.net/contact-us/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
INFO: Closing spider (finished)
INFO: Stored json feed (25 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 64905,
 'downloader/request_count': 246,
 'downloader/request_method_count/GET': 246,
 'downloader/response_bytes': 3495263,
 'downloader/response_count': 246,
 'downloader/response_status_count/200': 145,
 'downloader/response_status_count/301': 56,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/403': 29,
 'downloader/response_status_count/404': 5,
 'downloader/response_status_count/429': 10,
 'dupefilter/filtered': 60,
 'elapsed_time_seconds': 14.443245,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 10, 30, 45, 864570),
 'httpcompression/response_bytes': 14816381,
 'httpcompression/response_count': 156,
 'httperror/response_ignored_count': 16,
 'httperror/response_ignored_status_count/403': 14,
 'httperror/response_ignored_status_count/429': 2,
 'item_scraped_count': 25,
 'log_count/DEBUG': 476,
 'log_count/ERROR': 3,
 'log_count/INFO': 27,
 'request_depth_max': 1,
 'response_received_count': 181,
 'retry/count': 8,
 'retry/max_reached': 2,
 'retry/reason_count/429 Unknown Status': 8,
 'robotstxt/request_count': 84,
 'robotstxt/response_count': 84,
 'robotstxt/response_status_count/200': 64,
 'robotstxt/response_status_count/403': 15,
 'robotstxt/response_status_count/404': 5,
 'scheduler/dequeued': 138,
 'scheduler/dequeued/memory': 138,
 'scheduler/enqueued': 138,
 'scheduler/enqueued/memory': 138,
 'start_time': datetime.datetime(2022, 12, 9, 10, 30, 31, 421325)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 13cb8b81a9ecd7cd
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/robots.txt> from <GET http://www.fandftrees.com/robots.txt>
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Attempting to acquire lock 2251446444736 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2251446444736 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2251446444736 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2251446444736 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/> from <GET http://www.fandftrees.com/>
INFO: Ignoring response <403 https://trapperstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.charteroakscompany.com/robots.txt> (referer: None)
DEBUG: Filtered duplicate request: <GET http://hardwicktreecare.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/> (referer: None)
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/robots.txt> from <GET http://starwoodtree.com/robots.txt>
INFO: Ignoring response <403 https://www.midohiotree.org/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hardwicktreecare.com/> from <GET http://hardwicktreecare.com/>
DEBUG: Crawled (404) <GET http://ohiotreeandexcavating.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/contact> (referer: https://www.treetechohio.com/)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.net/>
DEBUG: Crawled (200) <GET http://www.treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/robots.txt> from <GET http://ohiotreeandexcavating.com/robots.txt>
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treesaremybusiness.com/> from <GET http://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.com/>
DEBUG: Crawled (404) <GET http://ohiotreecare.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/contact-hardwick-tree-care> (referer: https://www.hardwicktreecare.com/)
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.charteroakscompany.com/> from <GET http://www.charteroakscompany.com/>
INFO: Ignoring response <403 https://www.tackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://www.hackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/robots.txt> from <GET http://timberlandtreeohio.com/robots.txt>
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://deeprootedtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://treesaremybusiness.com/> from <GET https://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.charteroakscompany.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/> from <GET http://starwoodtree.com/>
DEBUG: Crawled (200) <GET https://www.independenttree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.whymonster.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/> from <GET http://timberlandtreeohio.com/>
DEBUG: Redirecting (301) to <GET https://www.monstertreeservice.com/akron/contact-us/> from <GET https://www.whymonster.com/akron/contact-us/>
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/robots.txt> from <GET http://www.jstreeservicesllc.com/robots.txt>
DEBUG: Crawled (403) <GET http://cottstrees.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://cottstrees.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://cottstrees.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/contact-us/> (referer: https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown)
DEBUG: Crawled (200) <GET https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website> (referer: None)
DEBUG: Crawled (200) <GET http://ohiotreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://roquetree.com/robots.txt> from <GET http://roquetree.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/robots.txt> from <GET http://www.basictreecare.com/robots.txt>
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.kiddertreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/robots.txt> from <GET http://www.haneytreeservice.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.kiddertreemov.com/> from <GET http://www.kiddertreeservice.com/>
DEBUG: Crawled (200) <GET https://www.independenttree.com/contact-us/> (referer: https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/cleveland/?utm_source=GMB&utm_medium=organic&utm_campaign=AvonLake> (referer: None)
DEBUG: Redirecting (301) to <GET https://jstreeservicesllc.com/> from <GET http://www.jstreeservicesllc.com/>
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.basictreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/contact-us/> (referer: https://treesaremybusiness.com/)
DEBUG: Crawled (200) <GET https://roquetree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/> from <GET http://www.basictreecare.com/>
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://roquetree.com/> from <GET http://roquetree.com/>
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/> from <GET http://www.haneytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/contact-us/> (referer: https://www.ewsmithtree.com/)
DEBUG: Redirecting (301) to <GET https://www.roquetree.com/> from <GET https://roquetree.com/>
DEBUG: Crawled (200) <GET https://www.basictreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/robots.txt> from <GET http://www.jttreeservicellc.com/robots.txt>
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://www.kandatreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/index.html> from <GET http://haneytreeservice.com/>
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/robots.txt> from <GET http://www.ripleytreeservice.com/robots.txt>
INFO: Ignoring response <403 http://www.jjsfamilytreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://haneytreeservice.com/index.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/robots.txt> from <GET https://www.extremetreeservicestoledo.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.roquetree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.roquetree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/> from <GET http://www.jttreeservicellc.com/>
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/> from <GET http://www.ripleytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus> (referer: None)
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/> from <GET https://www.extremetreeservicestoledo.com/>
DEBUG: Crawled (200) <GET https://www.savatree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.net/> (referer: None)
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://rawtreeserv.com/> from <GET https://www.rawtreeserv.com/>
DEBUG: Crawled (200) <GET https://parkstree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/> (referer: None)
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/cincinnati-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Cincinnati> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/contact-us/> (referer: https://starwoodtree.com/)
DEBUG: Crawled (200) <GET https://www.savatree.com/dayton-ohio-tree-service-lawn-care?utm_source=GMB&utm_medium=organic&utm_campaign=dayton> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/contact/> (referer: https://extremetreeservicestoledo.com/)
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/contact-us/> from <GET http://www.jstreeservicesllc.com/contact-us>
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/contact-us/> (referer: https://jstreeservicesllc.com/)
DEBUG: Crawled (200) <GET http://blackstreemov.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.blackstreemov.com/> from <GET http://blackstreemov.com/>
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/northeast-cleveland-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Northeast%20Cleveland> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://www.haymakertreeandlawn.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/> (referer: None)
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/contact-us/> (referer: None)
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/> (referer: None)
DEBUG: Crawled (200) <GET https://rawtreeserv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/?utm_source=googlelocal&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/> (referer: None)
INFO: Ignoring response <403 http://www.cstreemulch.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/contact> (referer: https://www.blackstreemov.com/)
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/robots.txt> from <GET http://www.roguetreesolutions.com/robots.txt>
INFO: Ignoring response <403 http://www.ashtreeservicepro.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/robots.txt> from <GET http://toddstreeservice.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/robots.txt> from <GET http://hoffmantreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://extremetreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonservicerequest> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET http://urbanloggersohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://urbanloggersohio.com/> from <GET http://urbanloggersohio.com/>
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://www.roguetreesolutions.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 52 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 59 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 109 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 111 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 119 without any user agent to enforce it on.
DEBUG: Rule at line 120 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 128 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 155 without any user agent to enforce it on.
DEBUG: Rule at line 165 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://herculestree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/> from <GET http://hoffmantreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/> from <GET http://www.roguetreesolutions.com/>
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 5 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 19 without any user agent to enforce it on.
DEBUG: Rule at line 21 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 34 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 60 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 68 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 73 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Rule at line 75 without any user agent to enforce it on.
DEBUG: Rule at line 76 without any user agent to enforce it on.
DEBUG: Rule at line 77 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 83 without any user agent to enforce it on.
DEBUG: Rule at line 85 without any user agent to enforce it on.
DEBUG: Rule at line 86 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 89 without any user agent to enforce it on.
DEBUG: Rule at line 90 without any user agent to enforce it on.
DEBUG: Rule at line 91 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 93 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 95 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 99 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 102 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 113 without any user agent to enforce it on.
DEBUG: Rule at line 114 without any user agent to enforce it on.
DEBUG: Rule at line 115 without any user agent to enforce it on.
DEBUG: Rule at line 116 without any user agent to enforce it on.
DEBUG: Rule at line 117 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/> from <GET http://toddstreeservice.com/>
DEBUG: Crawled (200) <GET https://www.roguetreesolutions.com/> (referer: None)
DEBUG: Crawled (404) <GET http://www.boonestreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET http://www.boonestreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.toddstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://herculestree.com/> from <GET http://herculestree.com/>
DEBUG: Redirecting (302) to <GET https://www.greatdanetreeexperts.com/404.html> from <GET https://www.greatdanetreeexperts.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/robots.txt> from <GET http://www.treeservicenow.net/robots.txt>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=residential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/robots.txt> from <GET http://tree-works-ohio.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/404.html> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 136 without any user agent to enforce it on.
DEBUG: Rule at line 141 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 147 without any user agent to enforce it on.
DEBUG: Rule at line 156 without any user agent to enforce it on.
DEBUG: Rule at line 157 without any user agent to enforce it on.
DEBUG: Rule at line 191 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonresidential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET https://premiertreesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://barbertontree.com/robots.txt> from <GET https://www.barbertontree.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/akron-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Akron> (referer: None)
DEBUG: Crawled (200) <GET https://brushbandittree.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://premiertreesllc.com/> (failed 1 times): 429 Unknown Status
DEBUG: Retrying <GET https://premiertreesllc.com/> (failed 2 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/robots.txt> from <GET http://www.lamannatreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://larochetree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/contact-urban-loggers/> (referer: https://urbanloggersohio.com/)
DEBUG: Redirecting (301) to <GET https://www.larochetree.com/> from <GET https://larochetree.com/>
DEBUG: Crawled (200) <GET https://herculestree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://premiertreesllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.larochetree.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://tomcotreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://tomcotreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/> from <GET http://tree-works-ohio.com/>
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
INFO: Ignoring response <403 http://tomcotreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://barbertontree.com/> from <GET https://www.barbertontree.com/>
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://brushbandittree.com/> (referer: None)
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.larochetree.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://herculestree.com/contact/> from <GET https://herculestree.com/contact>
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/> (referer: None)
DEBUG: Retrying <GET https://barbertontree.com/robots.txt> (failed 1 times): 429 Unknown Status
ERROR: Gave up retrying <GET https://premiertreesllc.com/contact-us/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://premiertreesllc.com/contact-us/> (referer: https://premiertreesllc.com/)
INFO: Ignoring response <403 http://www.dolcestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
DEBUG: Crawled (200) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
INFO: Ignoring response <429 https://premiertreesllc.com/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/> from <GET http://www.lamannatreeservice.com/>
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.larochetree.com/contact> (referer: https://www.larochetree.com/)
DEBUG: Retrying <GET https://barbertontree.com/> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 40, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (404) <GET https://www.napierandson.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://barbertontree.com/> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://brushbandittree.com/contact-us/> (referer: https://brushbandittree.com/)
ERROR: Gave up retrying <GET https://barbertontree.com/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://barbertontree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.napierandson.com/> (referer: None)
INFO: Ignoring response <429 https://barbertontree.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://herculestree.com/contact/request-quote/> from <GET https://herculestree.com/contact/request-quote>
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/robots.txt> from <GET https://www.treeservicenow.net/robots.txt>
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/> (referer: None)
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/contact-tree-works-for-all-your-emergency-services-tree-removal-stump-grinding-etc/> (referer: https://tree-works-ohio.com/)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/contact-us/> (referer: https://treeservicecolumbusohio.net/)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/contact/> (referer: https://lamannatreeservice.com/)
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/> from <GET http://www.treeservicenow.net/>
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/contact-us/> (referer: http://www.treeservicedelawareoh.com/)
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/> from <GET https://www.treeservicenow.net/>
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/contact_us_1> (referer: https://treeservicenow.net/)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote/> (referer: https://herculestree.com/)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 64674,
 'downloader/request_count': 245,
 'downloader/request_method_count/GET': 245,
 'downloader/response_bytes': 3481509,
 'downloader/response_count': 245,
 'downloader/response_status_count/200': 144,
 'downloader/response_status_count/301': 57,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/403': 29,
 'downloader/response_status_count/404': 5,
 'downloader/response_status_count/429': 9,
 'dupefilter/filtered': 61,
 'elapsed_time_seconds': 17.912499,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 12, 23, 35, 562524),
 'httpcompression/response_bytes': 14785681,
 'httpcompression/response_count': 155,
 'httperror/response_ignored_count': 16,
 'httperror/response_ignored_status_count/403': 14,
 'httperror/response_ignored_status_count/429': 2,
 'log_count/DEBUG': 450,
 'log_count/ERROR': 3,
 'log_count/INFO': 26,
 'request_depth_max': 1,
 'response_received_count': 180,
 'retry/count': 7,
 'retry/max_reached': 2,
 'retry/reason_count/429 Unknown Status': 7,
 'robotstxt/request_count': 84,
 'robotstxt/response_count': 84,
 'robotstxt/response_status_count/200': 64,
 'robotstxt/response_status_count/403': 15,
 'robotstxt/response_status_count/404': 5,
 'scheduler/dequeued': 138,
 'scheduler/dequeued/memory': 138,
 'scheduler/enqueued': 138,
 'scheduler/enqueued/memory': 138,
 'start_time': datetime.datetime(2022, 12, 9, 12, 23, 17, 650025)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 181c3c7ded670f7f
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2731534273888 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2731534273888 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2731534273888 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2731534273888 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/robots.txt> from <GET http://www.fandftrees.com/robots.txt>
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.treetechohio.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/> (referer: None)
DEBUG: Crawled (404) <GET http://ohiotreeandexcavating.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/robots.txt> (referer: None)
DEBUG: Filtered duplicate request: <GET http://hardwicktreecare.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.charteroakscompany.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/> (referer: None)
INFO: Ignoring response <403 https://trapperstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/> from <GET http://www.fandftrees.com/>
DEBUG: Crawled (200) <GET http://hardwicktreecare.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://www.midohiotree.org/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.fandftrees.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hardwicktreecare.com/> from <GET http://hardwicktreecare.com/>
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/robots.txt> from <GET http://starwoodtree.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.treetechohio.com/contact> (referer: https://www.treetechohio.com/)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.net/>
DEBUG: Scraped from <200 https://www.treetechohio.com/contact>
{'emails': ['831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            'info@mysite.com'],
 'facebook': 'http://www.facebook.com/wix',
 'instagram': '',
 'linkedin': '',
 'twitter': 'http://www.twitter.com/wix'}
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/robots.txt> from <GET http://ohiotreeandexcavating.com/robots.txt>
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/contact-hardwick-tree-care> (referer: https://www.hardwicktreecare.com/)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treesaremybusiness.com/> from <GET http://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET http://herculestree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.com/>
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/> (referer: None)
DEBUG: Crawled (404) <GET http://ohiotreecare.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.hardwicktreecare.com/contact-hardwick-tree-care>
{'emails': ['831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'info@HardwickTreeCare.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            'f1ffc0b5efe04e9eb9762cd808722520@sentry.wixpress.com'],
 'facebook': 'https://www.facebook.com/hardwicktreecarellc',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown> (referer: None)
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.tackettstreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.hackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.independenttree.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/robots.txt> from <GET http://timberlandtreeohio.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://herculestree.com/> from <GET http://herculestree.com/>
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.charteroakscompany.com/> from <GET http://www.charteroakscompany.com/>
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://deeprootedtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://treesaremybusiness.com/> from <GET https://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/robots.txt> from <GET http://www.jstreeservicesllc.com/robots.txt>
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website> (referer: None)
DEBUG: Crawled (200) <GET https://www.whymonster.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/> from <GET http://timberlandtreeohio.com/>
DEBUG: Crawled (200) <GET https://starwoodtree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.monstertreeservice.com/akron/contact-us/> from <GET https://www.whymonster.com/akron/contact-us/>
DEBUG: Crawled (200) <GET https://www.charteroakscompany.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://cottstrees.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/> from <GET http://starwoodtree.com/>
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/contact-us/> (referer: https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown)
DEBUG: Crawled (403) <GET http://cottstrees.com/> (referer: None)
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/akron/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsterTreeServiceofAkron/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': '',
 'twitter': ''}
INFO: Ignoring response <403 http://cottstrees.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.independenttree.com/contact-us/> (referer: https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/cleveland/?utm_source=GMB&utm_medium=organic&utm_campaign=AvonLake> (referer: None)
DEBUG: Redirecting (301) to <GET https://roquetree.com/robots.txt> from <GET http://roquetree.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/robots.txt> from <GET http://www.basictreecare.com/robots.txt>
DEBUG: Scraped from <200 https://www.independenttree.com/contact-us/>
{'emails': ['info@independenttree.com'],
 'facebook': 'https://www.facebook.com/IndependentTreeOH/',
 'instagram': 'https://www.instagram.com/independenttreeservice/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/robots.txt> from <GET http://www.haneytreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://herculestree.com/contact> (referer: https://herculestree.com/)
DEBUG: Redirecting (301) to <GET https://jstreeservicesllc.com/> from <GET http://www.jstreeservicesllc.com/>
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/> (referer: None)
DEBUG: Crawled (200) <GET http://ohiotreecare.com/> (referer: None)
DEBUG: Scraped from <200 https://herculestree.com/contact>
{'emails': ['Herculestree@gmail.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.basictreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET http://www.kiddertreeservice.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://herculestree.com/contact/>
{'emails': ['Herculestree@gmail.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://www.kiddertreemov.com/> from <GET http://www.kiddertreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/> from <GET http://www.basictreecare.com/>
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/contact-us/> (referer: https://www.ewsmithtree.com/)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/> from <GET http://www.haneytreeservice.com/>
DEBUG: Crawled (200) <GET https://roquetree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/contact-us/> (referer: https://treesaremybusiness.com/)
DEBUG: Scraped from <200 https://www.ewsmithtree.com/contact-us/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Scraped from <200 https://treesaremybusiness.com/contact-us/>
{'emails': ['millcraft@treesaremybusiness.com',
            'office@treesaremybusiness.com'],
 'facebook': 'https://www.facebook.com/treesaremybusinessohio/',
 'instagram': 'https://www.instagram.com/trees_are_my_business/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote> (referer: https://herculestree.com/)
DEBUG: Redirecting (301) to <GET https://roquetree.com/> from <GET http://roquetree.com/>
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.basictreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote/> (referer: https://herculestree.com/)
DEBUG: Scraped from <200 https://herculestree.com/contact/request-quote>
{'emails': ['info@herculesTrees.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/robots.txt> from <GET http://www.jttreeservicellc.com/robots.txt>
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/index.html> from <GET http://haneytreeservice.com/>
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.roquetree.com/> from <GET https://roquetree.com/>
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://herculestree.com/contact/request-quote/>
{'emails': ['info@herculesTrees.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.kandatreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/robots.txt> from <GET http://www.ripleytreeservice.com/robots.txt>
INFO: Ignoring response <403 http://www.jjsfamilytreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://haneytreeservice.com/index.html> (referer: None)
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/robots.txt> from <GET https://www.extremetreeservicestoledo.com/robots.txt>
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.roquetree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.savatree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/> from <GET http://www.ripleytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/> from <GET http://www.jttreeservicellc.com/>
DEBUG: Redirecting (301) to <GET https://rawtreeserv.com/> from <GET https://www.rawtreeserv.com/>
DEBUG: Crawled (200) <GET https://www.roquetree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/> from <GET https://www.extremetreeservicestoledo.com/>
DEBUG: Crawled (200) <GET https://parkstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET https://www.savatree.com/dayton-ohio-tree-service-lawn-care?utm_source=GMB&utm_medium=organic&utm_campaign=dayton> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/> (referer: None)
DEBUG: Crawled (200) <GET https://rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://blackstreemov.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/contact-us/> from <GET http://www.jstreeservicesllc.com/contact-us>
INFO: Ignoring response <403 http://www.haymakertreeandlawn.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.blackstreemov.com/> from <GET http://blackstreemov.com/>
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/contact-us/> (referer: https://jstreeservicesllc.com/)
DEBUG: Crawled (200) <GET https://rawtreeserv.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/cincinnati-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Cincinnati> (referer: None)
DEBUG: Scraped from <200 https://jstreeservicesllc.com/contact-us/>
{'emails': ['j_s.tree@yahoo.com'],
 'facebook': 'http://www.facebook.com/jandstreeservices',
 'instagram': 'http://www.instagram.com/jandstreeservices',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/contact/> (referer: https://extremetreeservicestoledo.com/)
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/> (referer: None)
INFO: Ignoring response <403 http://www.cstreemulch.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://extremetreeservicestoledo.com/contact/>
{'emails': ['extremetreeswanton@gmail.com'],
 'facebook': 'https://www.facebook.com/ToledosExtremeTree/',
 'instagram': '',
 'linkedin': '',
 'twitter': 'https://twitter.com/SuperClimber101'}
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/robots.txt> from <GET http://www.roguetreesolutions.com/robots.txt>
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/contact-us/> (referer: None)
INFO: Ignoring response <403 http://www.ashtreeservicepro.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/contact> (referer: https://www.blackstreemov.com/)
DEBUG: Scraped from <200 http://jstreeservicesllc.com/contact-us/>
{'emails': ['j_s.tree@yahoo.com'],
 'facebook': 'http://www.facebook.com/jandstreeservices',
 'instagram': 'http://www.instagram.com/jandstreeservices',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/robots.txt> from <GET http://toddstreeservice.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/robots.txt> from <GET http://hoffmantreeservice.com/robots.txt>
DEBUG: Scraped from <200 https://www.blackstreemov.com/contact>
{'emails': ['BlacksTreeService140@gmail.com',
            'blackstreeservice140@gmail.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'https://www.facebook.com/pages/Blacks-Tree-Service/205784306214398',
 'instagram': 'http://instagram.com/wix',
 'linkedin': '',
 'twitter': 'https://twitter.com/BlacksTreeMOV'}
DEBUG: Crawled (200) <GET https://starwoodtree.com/contact-us/> (referer: https://starwoodtree.com/)
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/?utm_source=googlelocal&utm_medium=organic> (referer: None)
DEBUG: Scraped from <200 https://starwoodtree.com/contact-us/>
{'emails': ['support@starwoodtree.com'],
 'facebook': 'https://www.facebook.com/Starwoodtreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://extremetreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/northeast-cleveland-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Northeast%20Cleveland> (referer: None)
DEBUG: Crawled (200) <GET http://urbanloggersohio.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://www.roguetreesolutions.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 52 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 59 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 109 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 111 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 119 without any user agent to enforce it on.
DEBUG: Rule at line 120 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 128 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 155 without any user agent to enforce it on.
DEBUG: Rule at line 165 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/> from <GET http://www.roguetreesolutions.com/>
DEBUG: Crawled (200) <GET https://extremetreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.roguetreesolutions.com/> (referer: None)
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://urbanloggersohio.com/> from <GET http://urbanloggersohio.com/>
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/> from <GET http://hoffmantreeservice.com/>
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/> from <GET http://toddstreeservice.com/>
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 5 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 19 without any user agent to enforce it on.
DEBUG: Rule at line 21 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 34 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 60 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 68 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 73 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Rule at line 75 without any user agent to enforce it on.
DEBUG: Rule at line 76 without any user agent to enforce it on.
DEBUG: Rule at line 77 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 83 without any user agent to enforce it on.
DEBUG: Rule at line 85 without any user agent to enforce it on.
DEBUG: Rule at line 86 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 89 without any user agent to enforce it on.
DEBUG: Rule at line 90 without any user agent to enforce it on.
DEBUG: Rule at line 91 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 93 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 95 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 99 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 102 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 113 without any user agent to enforce it on.
DEBUG: Rule at line 114 without any user agent to enforce it on.
DEBUG: Rule at line 115 without any user agent to enforce it on.
DEBUG: Rule at line 116 without any user agent to enforce it on.
DEBUG: Rule at line 117 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Crawled (404) <GET http://www.boonestreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=residential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Redirecting (302) to <GET https://www.greatdanetreeexperts.com/404.html> from <GET https://www.greatdanetreeexperts.com/robots.txt>
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=residential>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://barbertontree.com/robots.txt> from <GET https://www.barbertontree.com/robots.txt>
DEBUG: Crawled (200) <GET http://www.boonestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/404.html> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 136 without any user agent to enforce it on.
DEBUG: Rule at line 141 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 147 without any user agent to enforce it on.
DEBUG: Rule at line 156 without any user agent to enforce it on.
DEBUG: Rule at line 157 without any user agent to enforce it on.
DEBUG: Rule at line 191 without any user agent to enforce it on.
INFO: Ignoring response <403 http://www.toddstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://brushbandittree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/robots.txt> from <GET http://www.treeservicenow.net/robots.txt>
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/robots.txt> from <GET http://www.lamannatreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/> (referer: None)
DEBUG: Crawled (200) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://barbertontree.com/> from <GET https://www.barbertontree.com/>
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/> from <GET http://www.lamannatreeservice.com/>
DEBUG: Crawled (200) <GET https://premiertreesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/contact-us/> (referer: http://www.treeservicedelawareoh.com/)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
DEBUG: Retrying <GET https://barbertontree.com/robots.txt> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/robots.txt> from <GET https://www.treeservicenow.net/robots.txt>
DEBUG: Crawled (200) <GET https://larochetree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/robots.txt> from <GET http://tree-works-ohio.com/robots.txt>
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/> (referer: None)
DEBUG: Scraped from <200 http://www.treeservicedelawareoh.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/biz/43015/James-Tree-Service/194987980849287/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Retrying <GET https://premiertreesllc.com/> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonresidential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Redirecting (301) to <GET https://www.larochetree.com/> from <GET https://larochetree.com/>
DEBUG: Retrying <GET https://barbertontree.com/robots.txt> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://brushbandittree.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=nonresidential>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (403) <GET http://tomcotreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/contact/> (referer: https://lamannatreeservice.com/)
ERROR: Gave up retrying <GET https://barbertontree.com/robots.txt> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 21 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 34 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/akron-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Akron> (referer: None)
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/contact-urban-loggers/> (referer: https://urbanloggersohio.com/)
DEBUG: Crawled (200) <GET https://premiertreesllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.larochetree.com/robots.txt> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 40, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://lamannatreeservice.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/lamannatreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://tomcotreecare.com/> (referer: None)
DEBUG: Scraped from <200 https://urbanloggersohio.com/contact-urban-loggers/>
{'emails': ['Info@urbanloggersohio.com'],
 'facebook': '',
 'instagram': 'https://www.instagram.com/urbanloggersllc/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/> (referer: None)
DEBUG: Retrying <GET https://barbertontree.com/> (failed 1 times): 429 Unknown Status
INFO: Ignoring response <403 http://tomcotreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/> from <GET http://www.treeservicenow.net/>
INFO: Ignoring response <403 http://www.dolcestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Retrying <GET https://barbertontree.com/> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.larochetree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonservicerequest> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (404) <GET https://www.napierandson.com/robots.txt> (referer: None)
ERROR: Gave up retrying <GET https://barbertontree.com/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://barbertontree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://brushbandittree.com/contact-us/> (referer: https://brushbandittree.com/)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=nonservicerequest>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 2 times): 429 Unknown Status
INFO: Ignoring response <429 https://barbertontree.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://brushbandittree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/brushbandittree/',
 'instagram': 'https://www.instagram.com/brushband1t/',
 'linkedin': '',
 'twitter': 'https://twitter.com/brushband1t%20'}
DEBUG: Crawled (200) <GET https://www.larochetree.com/contact> (referer: https://www.larochetree.com/)
DEBUG: Crawled (200) <GET https://www.napierandson.com/> (referer: None)
ERROR: Gave up retrying <GET https://premiertreesllc.com/contact-us/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://premiertreesllc.com/contact-us/> (referer: https://premiertreesllc.com/)
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/> from <GET https://www.treeservicenow.net/>
DEBUG: Scraped from <200 https://www.larochetree.com/contact>
{'emails': ['831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'ContactUs@larochetree.com',
            'dd0a55ccb8124b9c9d938e3acf41f8aa@sentry.wixpress.com',
            'contactus@larochetree.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'https://www.facebook.com/LaRocheTree',
 'instagram': 'https://www.instagram.com/LaRochetree/',
 'linkedin': 'https://www.linkedin.com/company/laroche-tree-service-inc',
 'twitter': 'https://twitter.com/larochetree'}
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/> from <GET http://tree-works-ohio.com/>
INFO: Ignoring response <429 https://premiertreesllc.com/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/contact_us_1> (referer: https://treeservicenow.net/)
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/contact-us/> (referer: https://treeservicecolumbusohio.net/)
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/> (referer: None)
DEBUG: Scraped from <200 https://treeservicenow.net/contact_us_1>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Scraped from <200 https://treeservicecolumbusohio.net/contact-us/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/contact-tree-works-for-all-your-emergency-services-tree-removal-stump-grinding-etc/> (referer: https://tree-works-ohio.com/)
DEBUG: Scraped from <200 https://tree-works-ohio.com/contact-tree-works-for-all-your-emergency-services-tree-removal-stump-grinding-etc/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
INFO: Closing spider (finished)
INFO: Stored json feed (26 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 64229,
 'downloader/request_count': 245,
 'downloader/request_method_count/GET': 245,
 'downloader/response_bytes': 3504822,
 'downloader/response_count': 245,
 'downloader/response_status_count/200': 145,
 'downloader/response_status_count/301': 55,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/403': 29,
 'downloader/response_status_count/404': 5,
 'downloader/response_status_count/429': 10,
 'dupefilter/filtered': 59,
 'elapsed_time_seconds': 9.725817,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 12, 24, 1, 917649),
 'httpcompression/response_bytes': 14897610,
 'httpcompression/response_count': 156,
 'httperror/response_ignored_count': 16,
 'httperror/response_ignored_status_count/403': 14,
 'httperror/response_ignored_status_count/429': 2,
 'item_scraped_count': 26,
 'log_count/DEBUG': 491,
 'log_count/ERROR': 4,
 'log_count/INFO': 27,
 'request_depth_max': 1,
 'response_received_count': 182,
 'retry/count': 7,
 'retry/max_reached': 3,
 'retry/reason_count/429 Unknown Status': 7,
 'robotstxt/request_count': 84,
 'robotstxt/response_count': 84,
 'robotstxt/response_status_count/200': 63,
 'robotstxt/response_status_count/403': 15,
 'robotstxt/response_status_count/404': 5,
 'robotstxt/response_status_count/429': 1,
 'scheduler/dequeued': 137,
 'scheduler/dequeued/memory': 137,
 'scheduler/enqueued': 137,
 'scheduler/enqueued/memory': 137,
 'start_time': datetime.datetime(2022, 12, 9, 12, 23, 52, 191832)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 2a2ffdff3734a16c
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/robots.txt> from <GET http://www.fandftrees.com/robots.txt>
DEBUG: Attempting to acquire lock 3223339012672 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 3223339012672 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 3223339012672 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 3223339012672 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.treetechohio.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/robots.txt> (referer: None)
DEBUG: Filtered duplicate request: <GET http://hardwicktreecare.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/> from <GET http://www.fandftrees.com/>
DEBUG: Crawled (403) <GET https://www.midohiotree.org/> (referer: None)
DEBUG: Crawled (200) <GET http://www.charteroakscompany.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://trapperstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.fandftrees.com/> (referer: None)
DEBUG: Crawled (200) <GET http://hardwicktreecare.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://www.midohiotree.org/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/robots.txt> from <GET http://starwoodtree.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.hardwicktreecare.com/> from <GET http://hardwicktreecare.com/>
DEBUG: Crawled (404) <GET http://ohiotreeandexcavating.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/contact> (referer: https://www.treetechohio.com/)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.treetechohio.com/contact>
{'emails': ['605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            'info@mysite.com',
            '8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com'],
 'facebook': 'http://www.facebook.com/wix',
 'instagram': '',
 'linkedin': '',
 'twitter': 'http://www.twitter.com/wix'}
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.net/>
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treesaremybusiness.com/> from <GET http://www.treesaremybusiness.com/>
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/robots.txt> from <GET http://ohiotreeandexcavating.com/robots.txt>
INFO: Ignoring response <403 https://www.tackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/contact-hardwick-tree-care> (referer: https://www.hardwicktreecare.com/)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://www.hackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/> (referer: None)
DEBUG: Crawled (404) <GET http://ohiotreecare.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.com/>
DEBUG: Scraped from <200 https://www.hardwicktreecare.com/contact-hardwick-tree-care>
{'emails': ['605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            'f1ffc0b5efe04e9eb9762cd808722520@sentry.wixpress.com',
            'info@HardwickTreeCare.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com'],
 'facebook': 'https://www.facebook.com/hardwicktreecarellc',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://www.charteroakscompany.com/> from <GET http://www.charteroakscompany.com/>
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/robots.txt> from <GET http://timberlandtreeohio.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.independenttree.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://deeprootedtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://treesaremybusiness.com/> from <GET https://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://herculestree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.whymonster.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.charteroakscompany.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/> from <GET http://timberlandtreeohio.com/>
DEBUG: Redirecting (301) to <GET https://www.monstertreeservice.com/akron/contact-us/> from <GET https://www.whymonster.com/akron/contact-us/>
DEBUG: Crawled (200) <GET https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/robots.txt> from <GET http://www.jstreeservicesllc.com/robots.txt>
DEBUG: Crawled (403) <GET http://cottstrees.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/contact-us/> (referer: https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown)
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/> from <GET http://starwoodtree.com/>
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://cottstrees.com/> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/akron/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsterTreeServiceofAkron/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://cottstrees.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://roquetree.com/robots.txt> from <GET http://roquetree.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.independenttree.com/contact-us/> (referer: https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website)
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/robots.txt> from <GET http://www.basictreecare.com/robots.txt>
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.independenttree.com/contact-us/>
{'emails': ['info@independenttree.com'],
 'facebook': 'https://www.facebook.com/IndependentTreeOH/',
 'instagram': 'https://www.instagram.com/independenttreeservice/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.kiddertreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/robots.txt> from <GET http://www.haneytreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.kiddertreemov.com/> from <GET http://www.kiddertreeservice.com/>
DEBUG: Crawled (200) <GET http://ohiotreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/cleveland/?utm_source=GMB&utm_medium=organic&utm_campaign=AvonLake> (referer: None)
DEBUG: Crawled (200) <GET https://www.basictreecare.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://jstreeservicesllc.com/> from <GET http://www.jstreeservicesllc.com/>
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/contact-us/> (referer: https://treesaremybusiness.com/)
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/> from <GET http://www.basictreecare.com/>
DEBUG: Scraped from <200 https://treesaremybusiness.com/contact-us/>
{'emails': ['millcraft@treesaremybusiness.com',
            'office@treesaremybusiness.com'],
 'facebook': 'https://www.facebook.com/treesaremybusinessohio/',
 'instagram': 'https://www.instagram.com/trees_are_my_business/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://roquetree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/> from <GET http://www.haneytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/contact-us/> (referer: https://www.ewsmithtree.com/)
DEBUG: Redirecting (301) to <GET https://roquetree.com/> from <GET http://roquetree.com/>
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.basictreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/> (referer: None)
DEBUG: Scraped from <200 https://www.ewsmithtree.com/contact-us/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/robots.txt> from <GET http://www.jttreeservicellc.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.roquetree.com/> from <GET https://roquetree.com/>
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/index.html> from <GET http://haneytreeservice.com/>
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/robots.txt> from <GET http://www.ripleytreeservice.com/robots.txt>
INFO: Ignoring response <403 https://www.kandatreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://www.jjsfamilytreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://haneytreeservice.com/index.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.roquetree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/robots.txt> from <GET https://www.extremetreeservicestoledo.com/robots.txt>
DEBUG: Crawled (200) <GET https://parkstree.net/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://herculestree.com/> from <GET http://herculestree.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/> from <GET http://www.jttreeservicellc.com/>
DEBUG: Crawled (200) <GET https://www.roquetree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.savatree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/> from <GET http://www.ripleytreeservice.com/>
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://rawtreeserv.com/> from <GET https://www.rawtreeserv.com/>
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.savatree.com/dayton-ohio-tree-service-lawn-care?utm_source=GMB&utm_medium=organic&utm_campaign=dayton> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/> from <GET https://www.extremetreeservicestoledo.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/cincinnati-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Cincinnati> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/> (referer: None)
DEBUG: Crawled (200) <GET https://rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://blackstreemov.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/contact-us/> from <GET http://www.jstreeservicesllc.com/contact-us>
DEBUG: Redirecting (301) to <GET https://www.blackstreemov.com/> from <GET http://blackstreemov.com/>
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/?utm_source=googlelocal&utm_medium=organic> (referer: None)
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/contact-us/> (referer: https://jstreeservicesllc.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonservicerequest> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET https://rawtreeserv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://www.haymakertreeandlawn.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://jstreeservicesllc.com/contact-us/>
{'emails': ['j_s.tree@yahoo.com'],
 'facebook': 'http://www.facebook.com/jandstreeservices',
 'instagram': 'http://www.instagram.com/jandstreeservices',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=nonservicerequest>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://herculestree.com/contact> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/contact/> (referer: https://extremetreeservicestoledo.com/)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/> (referer: None)
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/contact-us/> (referer: None)
DEBUG: Scraped from <200 https://herculestree.com/contact>
{'emails': ['Herculestree@gmail.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://extremetreeservicestoledo.com/contact/>
{'emails': ['extremetreeswanton@gmail.com'],
 'facebook': 'https://www.facebook.com/ToledosExtremeTree/',
 'instagram': '',
 'linkedin': '',
 'twitter': 'https://twitter.com/SuperClimber101'}
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/contact-us/> (referer: https://starwoodtree.com/)
DEBUG: Scraped from <200 http://jstreeservicesllc.com/contact-us/>
{'emails': ['j_s.tree@yahoo.com'],
 'facebook': 'http://www.facebook.com/jandstreeservices',
 'instagram': 'http://www.instagram.com/jandstreeservices',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/contact> (referer: https://www.blackstreemov.com/)
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://starwoodtree.com/contact-us/>
{'emails': ['support@starwoodtree.com'],
 'facebook': 'https://www.facebook.com/Starwoodtreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/> (referer: None)
DEBUG: Scraped from <200 https://www.blackstreemov.com/contact>
{'emails': ['605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            'BlacksTreeService140@gmail.com',
            'blackstreeservice140@gmail.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com'],
 'facebook': 'https://www.facebook.com/pages/Blacks-Tree-Service/205784306214398',
 'instagram': 'http://instagram.com/wix',
 'linkedin': '',
 'twitter': 'https://twitter.com/BlacksTreeMOV'}
INFO: Ignoring response <403 http://www.cstreemulch.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/> (referer: None)
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=residential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote> (referer: https://herculestree.com/)
INFO: Ignoring response <403 http://www.ashtreeservicepro.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://herculestree.com/contact/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=residential>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/robots.txt> from <GET http://toddstreeservice.com/robots.txt>
DEBUG: Scraped from <200 https://herculestree.com/contact/request-quote>
{'emails': ['HerculesTree@gmail.com', 'info@herculesTrees.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://herculestree.com/contact/>
{'emails': ['Herculestree@gmail.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://herculestree.com/contact/request-quote/>
{'emails': ['HerculesTree@gmail.com', 'info@herculesTrees.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://extremetreeohio.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://affordabletreese/robots.txt> (failed 1 times): DNS lookup failed: no results for hostname lookup: affordabletreese.
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/robots.txt> from <GET http://hoffmantreeservice.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/robots.txt> from <GET http://www.roguetreesolutions.com/robots.txt>
DEBUG: Crawled (200) <GET http://urbanloggersohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://urbanloggersohio.com/> from <GET http://urbanloggersohio.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/northeast-cleveland-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Northeast%20Cleveland> (referer: None)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/> from <GET http://toddstreeservice.com/>
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 5 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 19 without any user agent to enforce it on.
DEBUG: Rule at line 21 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 34 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 60 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 68 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 73 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Rule at line 75 without any user agent to enforce it on.
DEBUG: Rule at line 76 without any user agent to enforce it on.
DEBUG: Rule at line 77 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 83 without any user agent to enforce it on.
DEBUG: Rule at line 85 without any user agent to enforce it on.
DEBUG: Rule at line 86 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 89 without any user agent to enforce it on.
DEBUG: Rule at line 90 without any user agent to enforce it on.
DEBUG: Rule at line 91 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 93 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 95 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 99 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 102 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 113 without any user agent to enforce it on.
DEBUG: Rule at line 114 without any user agent to enforce it on.
DEBUG: Rule at line 115 without any user agent to enforce it on.
DEBUG: Rule at line 116 without any user agent to enforce it on.
DEBUG: Rule at line 117 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Crawled (404) <GET http://www.boonestreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Crawled (404) <GET https://www.roguetreesolutions.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 52 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 59 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 109 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 111 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 119 without any user agent to enforce it on.
DEBUG: Rule at line 120 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 128 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 155 without any user agent to enforce it on.
DEBUG: Rule at line 165 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonresidential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/> from <GET http://www.roguetreesolutions.com/>
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/> from <GET http://hoffmantreeservice.com/>
DEBUG: Crawled (200) <GET https://www.roguetreesolutions.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=nonresidential>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET http://www.boonestreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.toddstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Retrying <GET https://affordabletreese/robots.txt> (failed 2 times): DNS lookup failed: no results for hostname lookup: affordabletreese.
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/robots.txt> from <GET http://tree-works-ohio.com/robots.txt>
DEBUG: Redirecting (302) to <GET https://www.greatdanetreeexperts.com/404.html> from <GET https://www.greatdanetreeexperts.com/robots.txt>
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/robots.txt> from <GET http://www.treeservicenow.net/robots.txt>
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/404.html> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 136 without any user agent to enforce it on.
DEBUG: Rule at line 141 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 147 without any user agent to enforce it on.
DEBUG: Rule at line 156 without any user agent to enforce it on.
DEBUG: Rule at line 157 without any user agent to enforce it on.
DEBUG: Rule at line 191 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://barbertontree.com/robots.txt> from <GET https://www.barbertontree.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/akron-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Akron> (referer: None)
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/contact-urban-loggers/> (referer: https://urbanloggersohio.com/)
DEBUG: Crawled (200) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://brushbandittree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://barbertontree.com/> from <GET https://www.barbertontree.com/>
DEBUG: Crawled (200) <GET https://premiertreesllc.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://urbanloggersohio.com/contact-urban-loggers/>
{'emails': ['Info@urbanloggersohio.com'],
 'facebook': '',
 'instagram': 'https://www.instagram.com/urbanloggersllc/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/robots.txt> from <GET http://www.lamannatreeservice.com/robots.txt>
DEBUG: Retrying <GET https://premiertreesllc.com/> (failed 1 times): 429 Unknown Status
DEBUG: Retrying <GET https://barbertontree.com/robots.txt> (failed 1 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
DEBUG: Crawled (200) <GET https://larochetree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/> from <GET http://www.lamannatreeservice.com/>
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.larochetree.com/> from <GET https://larochetree.com/>
DEBUG: Retrying <GET https://barbertontree.com/robots.txt> (failed 2 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/> (referer: None)
ERROR: Gave up retrying <GET https://barbertontree.com/robots.txt> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 21 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 34 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Crawled (403) <GET http://tomcotreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://premiertreesllc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/> from <GET http://tree-works-ohio.com/>
ERROR: Gave up retrying <GET https://affordabletreese/robots.txt> (failed 3 times): DNS lookup failed: no results for hostname lookup: affordabletreese.
ERROR: Error downloading <GET https://affordabletreese/robots.txt>: DNS lookup failed: no results for hostname lookup: affordabletreese.
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\defer.py", line 1693, in _inlineCallbacks
    result = context.run(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\python\failure.py", line 518, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\endpoints.py", line 1022, in startConnectionAttempts
    raise error.DNSLookupError(
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: affordabletreese.
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/contact/> (referer: https://lamannatreeservice.com/)
DEBUG: Retrying <GET https://barbertontree.com/> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://tomcotreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.larochetree.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://lamannatreeservice.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/lamannatreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/> (referer: None)
DEBUG: Retrying <GET https://barbertontree.com/> (failed 2 times): 429 Unknown Status
INFO: Ignoring response <403 http://tomcotreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/robots.txt> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 40, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/> (referer: None)
ERROR: Gave up retrying <GET https://barbertontree.com/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://barbertontree.com/> (referer: None)
INFO: Ignoring response <403 http://www.dolcestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.larochetree.com/> (referer: None)
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://brushbandittree.com/> (referer: None)
INFO: Ignoring response <429 https://barbertontree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (404) <GET https://www.napierandson.com/robots.txt> (referer: None)
ERROR: Gave up retrying <GET https://premiertreesllc.com/contact-us/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://premiertreesllc.com/contact-us/> (referer: https://premiertreesllc.com/)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/contact-us/> (referer: http://www.treeservicedelawareoh.com/)
INFO: Ignoring response <429 https://premiertreesllc.com/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/robots.txt> from <GET https://www.treeservicenow.net/robots.txt>
DEBUG: Scraped from <200 http://www.treeservicedelawareoh.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/biz/43015/James-Tree-Service/194987980849287/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.napierandson.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/contact-tree-works-for-all-your-emergency-services-tree-removal-stump-grinding-etc/> (referer: https://tree-works-ohio.com/)
DEBUG: Crawled (200) <GET https://brushbandittree.com/contact-us/> (referer: https://brushbandittree.com/)
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Retrying <GET https://affordabletreese> (failed 1 times): DNS lookup failed: no results for hostname lookup: affordabletreese.
DEBUG: Scraped from <200 https://tree-works-ohio.com/contact-tree-works-for-all-your-emergency-services-tree-removal-stump-grinding-etc/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Scraped from <200 https://brushbandittree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/brushbandittree/',
 'instagram': 'https://www.instagram.com/brushband1t/',
 'linkedin': '',
 'twitter': 'https://twitter.com/brushband1t%20'}
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/> from <GET http://www.treeservicenow.net/>
DEBUG: Crawled (200) <GET https://www.larochetree.com/contact> (referer: https://www.larochetree.com/)
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/> from <GET https://www.treeservicenow.net/>
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/contact-us/> (referer: https://treeservicecolumbusohio.net/)
DEBUG: Scraped from <200 https://www.larochetree.com/contact>
{'emails': ['605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            'dd0a55ccb8124b9c9d938e3acf41f8aa@sentry.wixpress.com',
            'contactus@larochetree.com',
            'ContactUs@larochetree.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com'],
 'facebook': 'https://www.facebook.com/LaRocheTree',
 'instagram': 'https://www.instagram.com/LaRochetree/',
 'linkedin': 'https://www.linkedin.com/company/laroche-tree-service-inc',
 'twitter': 'https://twitter.com/larochetree'}
DEBUG: Scraped from <200 https://treeservicecolumbusohio.net/contact-us/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/contact_us_1> (referer: https://treeservicenow.net/)
DEBUG: Scraped from <200 https://treeservicenow.net/contact_us_1>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Retrying <GET https://affordabletreese> (failed 2 times): DNS lookup failed: no results for hostname lookup: affordabletreese.
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/> (referer: None)
ERROR: Gave up retrying <GET https://affordabletreese> (failed 3 times): DNS lookup failed: no results for hostname lookup: affordabletreese.
ERROR: Error downloading <GET https://affordabletreese>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\defer.py", line 1693, in _inlineCallbacks
    result = context.run(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\python\failure.py", line 518, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\endpoints.py", line 1022, in startConnectionAttempts
    raise error.DNSLookupError(
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: affordabletreese.
INFO: Closing spider (finished)
INFO: Stored json feed (26 items) in: website_spider_output.json
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 6,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 6,
 'downloader/request_bytes': 66008,
 'downloader/request_count': 251,
 'downloader/request_method_count/GET': 251,
 'downloader/response_bytes': 3505479,
 'downloader/response_count': 245,
 'downloader/response_status_count/200': 145,
 'downloader/response_status_count/301': 55,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/403': 29,
 'downloader/response_status_count/404': 5,
 'downloader/response_status_count/429': 10,
 'dupefilter/filtered': 61,
 'elapsed_time_seconds': 12.250735,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 12, 28, 17, 11523),
 'httpcompression/response_bytes': 14909707,
 'httpcompression/response_count': 156,
 'httperror/response_ignored_count': 16,
 'httperror/response_ignored_status_count/403': 14,
 'httperror/response_ignored_status_count/429': 2,
 'item_scraped_count': 26,
 'log_count/DEBUG': 495,
 'log_count/ERROR': 8,
 'log_count/INFO': 27,
 'request_depth_max': 1,
 'response_received_count': 182,
 'retry/count': 11,
 'retry/max_reached': 5,
 'retry/reason_count/429 Unknown Status': 7,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 4,
 "robotstxt/exception_count/<class 'twisted.internet.error.DNSLookupError'>": 1,
 'robotstxt/request_count': 85,
 'robotstxt/response_count': 84,
 'robotstxt/response_status_count/200': 63,
 'robotstxt/response_status_count/403': 15,
 'robotstxt/response_status_count/404': 5,
 'robotstxt/response_status_count/429': 1,
 'scheduler/dequeued': 140,
 'scheduler/dequeued/memory': 140,
 'scheduler/enqueued': 140,
 'scheduler/enqueued/memory': 140,
 'start_time': datetime.datetime(2022, 12, 9, 12, 28, 4, 760788)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 38c9d0b51920e232
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1799154118816 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1799154118816 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1799154118816 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1799154118816 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/robots.txt> from <GET http://www.fandftrees.com/robots.txt>
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/robots.txt> (referer: None)
DEBUG: Filtered duplicate request: <GET http://hardwicktreecare.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET http://www.charteroakscompany.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/> from <GET http://www.fandftrees.com/>
INFO: Ignoring response <403 https://trapperstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://www.midohiotree.org/> (referer: None)
DEBUG: Crawled (404) <GET http://ohiotreeandexcavating.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/> (referer: None)
DEBUG: Crawled (200) <GET http://hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hardwicktreecare.com/> from <GET http://hardwicktreecare.com/>
INFO: Ignoring response <403 https://www.midohiotree.org/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/robots.txt> from <GET http://starwoodtree.com/robots.txt>
DEBUG: Redirecting (301) to <GET http://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.net/>
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/robots.txt> from <GET http://ohiotreeandexcavating.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET http://ohiotreecare.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/contact> (referer: https://www.treetechohio.com/)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.com/>
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.treetechohio.com/contact>
{'emails': ['605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            'info@mysite.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com'],
 'facebook': 'http://www.facebook.com/wix',
 'instagram': '',
 'linkedin': '',
 'twitter': 'http://www.twitter.com/wix'}
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treesaremybusiness.com/> from <GET http://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/> (referer: None)
INFO: Ignoring response <403 https://www.tackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown> (referer: None)
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/> (referer: None)
INFO: Ignoring response <403 http://www.hackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.charteroakscompany.com/> from <GET http://www.charteroakscompany.com/>
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/robots.txt> from <GET http://timberlandtreeohio.com/robots.txt>
INFO: Ignoring response <403 http://deeprootedtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/contact-hardwick-tree-care> (referer: https://www.hardwicktreecare.com/)
DEBUG: Redirecting (301) to <GET https://treesaremybusiness.com/> from <GET https://www.treesaremybusiness.com/>
DEBUG: Scraped from <200 https://www.hardwicktreecare.com/contact-hardwick-tree-care>
{'emails': ['605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com',
            'f1ffc0b5efe04e9eb9762cd808722520@sentry.wixpress.com',
            'info@HardwickTreeCare.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com'],
 'facebook': 'https://www.facebook.com/hardwicktreecarellc',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.independenttree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://herculestree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.whymonster.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.charteroakscompany.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/> from <GET http://timberlandtreeohio.com/>
DEBUG: Redirecting (301) to <GET https://www.monstertreeservice.com/akron/contact-us/> from <GET https://www.whymonster.com/akron/contact-us/>
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/> from <GET http://starwoodtree.com/>
DEBUG: Crawled (403) <GET http://cottstrees.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/contact-us/> (referer: https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/robots.txt> from <GET http://www.jstreeservicesllc.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://herculestree.com/> from <GET http://herculestree.com/>
DEBUG: Crawled (403) <GET http://cottstrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/akron/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsterTreeServiceofAkron/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': '',
 'twitter': ''}
INFO: Ignoring response <403 http://cottstrees.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website> (referer: None)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://roquetree.com/robots.txt> from <GET http://roquetree.com/robots.txt>
DEBUG: Crawled (200) <GET http://ohiotreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/robots.txt> from <GET http://www.basictreecare.com/robots.txt>
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/robots.txt> from <GET http://www.haneytreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.independenttree.com/contact-us/> (referer: https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/cleveland/?utm_source=GMB&utm_medium=organic&utm_campaign=AvonLake> (referer: None)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.kiddertreeservice.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.independenttree.com/contact-us/>
{'emails': ['info@independenttree.com'],
 'facebook': 'https://www.facebook.com/IndependentTreeOH/',
 'instagram': 'https://www.instagram.com/independenttreeservice/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://www.kiddertreemov.com/> from <GET http://www.kiddertreeservice.com/>
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/contact-us/> (referer: https://treesaremybusiness.com/)
DEBUG: Crawled (200) <GET https://www.basictreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://jstreeservicesllc.com/> from <GET http://www.jstreeservicesllc.com/>
DEBUG: Crawled (200) <GET https://roquetree.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://treesaremybusiness.com/contact-us/>
{'emails': ['millcraft@treesaremybusiness.com',
            'office@treesaremybusiness.com'],
 'facebook': 'https://www.facebook.com/treesaremybusinessohio/',
 'instagram': 'https://www.instagram.com/trees_are_my_business/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/> from <GET http://www.basictreecare.com/>
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/> from <GET http://www.haneytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/robots.txt> from <GET http://www.jttreeservicellc.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://roquetree.com/> from <GET http://roquetree.com/>
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/contact-us/> (referer: https://www.ewsmithtree.com/)
DEBUG: Crawled (200) <GET https://www.basictreecare.com/> (referer: None)
DEBUG: Scraped from <200 https://herculestree.com/contact>
{'emails': ['Herculestree@gmail.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://www.ewsmithtree.com/contact-us/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/index.html> from <GET http://haneytreeservice.com/>
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.roquetree.com/> from <GET https://roquetree.com/>
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote/> (referer: https://herculestree.com/)
INFO: Ignoring response <403 https://www.kandatreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://herculestree.com/contact/request-quote/>
{'emails': ['info@herculesTrees.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.davey.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/robots.txt> from <GET http://www.ripleytreeservice.com/robots.txt>
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://haneytreeservice.com/index.html> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/> (referer: None)
INFO: Ignoring response <403 http://www.jjsfamilytreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote> (referer: https://herculestree.com/)
DEBUG: Scraped from <200 https://herculestree.com/contact/request-quote>
{'emails': ['info@herculesTrees.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://parkstree.net/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/> from <GET http://www.jttreeservicellc.com/>
DEBUG: Crawled (200) <GET https://www.roquetree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/robots.txt> from <GET https://www.extremetreeservicestoledo.com/robots.txt>
DEBUG: Crawled (200) <GET https://herculestree.com/contact/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://www.rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus> (referer: None)
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://herculestree.com/contact/>
{'emails': ['Herculestree@gmail.com', 'HerculesTree@gmail.com'],
 'facebook': 'https://www.facebook.com/HerculesTreeLLC/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.savatree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.roquetree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://rawtreeserv.com/> from <GET https://www.rawtreeserv.com/>
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/> from <GET http://www.ripleytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.savatree.com/dayton-ohio-tree-service-lawn-care?utm_source=GMB&utm_medium=organic&utm_campaign=dayton> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/> from <GET https://www.extremetreeservicestoledo.com/>
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/cincinnati-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Cincinnati> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://blackstreemov.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.blackstreemov.com/> from <GET http://blackstreemov.com/>
DEBUG: Crawled (200) <GET https://rawtreeserv.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/> (referer: None)
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/contact-us/> (referer: https://starwoodtree.com/)
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/contact-us/> from <GET http://www.jstreeservicesllc.com/contact-us>
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://www.haymakertreeandlawn.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/?utm_source=googlelocal&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/contact-us/> (referer: https://jstreeservicesllc.com/)
DEBUG: Scraped from <200 https://starwoodtree.com/contact-us/>
{'emails': ['support@starwoodtree.com'],
 'facebook': 'https://www.facebook.com/Starwoodtreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=residential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
INFO: Ignoring response <403 http://www.cstreemulch.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/contact/> (referer: https://extremetreeservicestoledo.com/)
DEBUG: Scraped from <200 https://jstreeservicesllc.com/contact-us/>
{'emails': ['j_s.tree@yahoo.com'],
 'facebook': 'http://www.facebook.com/jandstreeservices',
 'instagram': 'http://www.instagram.com/jandstreeservices',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=residential>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/northeast-cleveland-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Northeast%20Cleveland> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/robots.txt> from <GET http://www.roguetreesolutions.com/robots.txt>
INFO: Ignoring response <403 http://www.ashtreeservicepro.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/robots.txt> from <GET http://toddstreeservice.com/robots.txt>
DEBUG: Scraped from <200 https://extremetreeservicestoledo.com/contact/>
{'emails': ['extremetreeswanton@gmail.com'],
 'facebook': 'https://www.facebook.com/ToledosExtremeTree/',
 'instagram': '',
 'linkedin': '',
 'twitter': 'https://twitter.com/SuperClimber101'}
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/contact-us/> (referer: None)
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/robots.txt> from <GET http://hoffmantreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/contact> (referer: https://www.blackstreemov.com/)
DEBUG: Crawled (200) <GET http://urbanloggersohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeohio.com/> (referer: None)
DEBUG: Scraped from <200 http://jstreeservicesllc.com/contact-us/>
{'emails': ['j_s.tree@yahoo.com'],
 'facebook': 'http://www.facebook.com/jandstreeservices',
 'instagram': 'http://www.instagram.com/jandstreeservices',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://www.blackstreemov.com/contact>
{'emails': ['605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'BlacksTreeService140@gmail.com',
            'blackstreeservice140@gmail.com'],
 'facebook': 'https://www.facebook.com/pages/Blacks-Tree-Service/205784306214398',
 'instagram': 'http://instagram.com/wix',
 'linkedin': '',
 'twitter': 'https://twitter.com/BlacksTreeMOV'}
DEBUG: Redirecting (301) to <GET https://urbanloggersohio.com/> from <GET http://urbanloggersohio.com/>
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://www.roguetreesolutions.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 52 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 59 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 109 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 111 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 119 without any user agent to enforce it on.
DEBUG: Rule at line 120 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 128 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 155 without any user agent to enforce it on.
DEBUG: Rule at line 165 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/> from <GET http://www.roguetreesolutions.com/>
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 5 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 19 without any user agent to enforce it on.
DEBUG: Rule at line 21 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 34 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 60 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 68 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 73 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Rule at line 75 without any user agent to enforce it on.
DEBUG: Rule at line 76 without any user agent to enforce it on.
DEBUG: Rule at line 77 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 83 without any user agent to enforce it on.
DEBUG: Rule at line 85 without any user agent to enforce it on.
DEBUG: Rule at line 86 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 89 without any user agent to enforce it on.
DEBUG: Rule at line 90 without any user agent to enforce it on.
DEBUG: Rule at line 91 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 93 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 95 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 99 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 102 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 113 without any user agent to enforce it on.
DEBUG: Rule at line 114 without any user agent to enforce it on.
DEBUG: Rule at line 115 without any user agent to enforce it on.
DEBUG: Rule at line 116 without any user agent to enforce it on.
DEBUG: Rule at line 117 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/> from <GET http://toddstreeservice.com/>
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET http://www.boonestreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.roguetreesolutions.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/> from <GET http://hoffmantreeservice.com/>
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.boonestreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://barbertontree.com/robots.txt> from <GET https://www.barbertontree.com/robots.txt>
DEBUG: Redirecting (302) to <GET https://www.greatdanetreeexperts.com/404.html> from <GET https://www.greatdanetreeexperts.com/robots.txt>
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.toddstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonresidential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/404.html> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 136 without any user agent to enforce it on.
DEBUG: Rule at line 141 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 147 without any user agent to enforce it on.
DEBUG: Rule at line 156 without any user agent to enforce it on.
DEBUG: Rule at line 157 without any user agent to enforce it on.
DEBUG: Rule at line 191 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/robots.txt> from <GET http://www.lamannatreeservice.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/robots.txt> from <GET http://www.treeservicenow.net/robots.txt>
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/robots.txt> from <GET http://tree-works-ohio.com/robots.txt>
DEBUG: Crawled (200) <GET https://brushbandittree.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=nonresidential>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://premiertreesllc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/> from <GET http://www.lamannatreeservice.com/>
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/contact-us/> (referer: http://www.treeservicedelawareoh.com/)
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
DEBUG: Retrying <GET https://premiertreesllc.com/> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/akron-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Akron> (referer: None)
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://larochetree.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 http://www.treeservicedelawareoh.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/biz/43015/James-Tree-Service/194987980849287/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Retrying <GET https://premiertreesllc.com/> (failed 2 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://www.larochetree.com/> from <GET https://larochetree.com/>
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/robots.txt> from <GET https://www.treeservicenow.net/robots.txt>
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://brushbandittree.com/> (referer: None)
DEBUG: Crawled (403) <GET http://tomcotreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/contact-urban-loggers/> (referer: https://urbanloggersohio.com/)
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/contact/> (referer: https://lamannatreeservice.com/)
DEBUG: Redirecting (301) to <GET https://barbertontree.com/> from <GET https://www.barbertontree.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonservicerequest> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/> (referer: None)
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/robots.txt> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 40, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.larochetree.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://urbanloggersohio.com/contact-urban-loggers/>
{'emails': ['Info@urbanloggersohio.com'],
 'facebook': '',
 'instagram': 'https://www.instagram.com/urbanloggersllc/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://lamannatreeservice.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/lamannatreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (403) <GET http://tomcotreecare.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/?type=nonservicerequest>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/> (referer: None)
DEBUG: Retrying <GET https://barbertontree.com/robots.txt> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://premiertreesllc.com/> (referer: None)
INFO: Ignoring response <403 http://tomcotreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.larochetree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/> from <GET http://tree-works-ohio.com/>
INFO: Ignoring response <403 http://www.dolcestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
DEBUG: Crawled (404) <GET https://www.napierandson.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://brushbandittree.com/contact-us/> (referer: https://brushbandittree.com/)
DEBUG: Retrying <GET https://barbertontree.com/> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.larochetree.com/contact> (referer: https://www.larochetree.com/)
DEBUG: Crawled (200) <GET https://www.napierandson.com/> (referer: None)
DEBUG: Scraped from <200 https://brushbandittree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/brushbandittree/',
 'instagram': 'https://www.instagram.com/brushband1t/',
 'linkedin': '',
 'twitter': 'https://twitter.com/brushband1t%20'}
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 2 times): 429 Unknown Status
DEBUG: Retrying <GET https://barbertontree.com/> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.larochetree.com/contact>
{'emails': ['605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            'contactus@larochetree.com',
            'dd0a55ccb8124b9c9d938e3acf41f8aa@sentry.wixpress.com',
            'ContactUs@larochetree.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com'],
 'facebook': 'https://www.facebook.com/LaRocheTree',
 'instagram': 'https://www.instagram.com/LaRochetree/',
 'linkedin': 'https://www.linkedin.com/company/laroche-tree-service-inc',
 'twitter': 'https://twitter.com/larochetree'}
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/> from <GET http://www.treeservicenow.net/>
ERROR: Gave up retrying <GET https://barbertontree.com/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://barbertontree.com/> (referer: None)
ERROR: Gave up retrying <GET https://premiertreesllc.com/contact-us/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://premiertreesllc.com/contact-us/> (referer: https://premiertreesllc.com/)
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/> (referer: None)
INFO: Ignoring response <429 https://barbertontree.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <429 https://premiertreesllc.com/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/contact-us/> (referer: https://treeservicecolumbusohio.net/)
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/contact-tree-works-for-all-your-emergency-services-tree-removal-stump-grinding-etc/> (referer: https://tree-works-ohio.com/)
DEBUG: Scraped from <200 https://treeservicecolumbusohio.net/contact-us/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Scraped from <200 https://tree-works-ohio.com/contact-tree-works-for-all-your-emergency-services-tree-removal-stump-grinding-etc/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/> from <GET https://www.treeservicenow.net/>
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/contact_us_1> (referer: https://treeservicenow.net/)
DEBUG: Scraped from <200 https://treeservicenow.net/contact_us_1>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 64162,
 'downloader/request_count': 245,
 'downloader/request_method_count/GET': 245,
 'downloader/response_bytes': 3503572,
 'downloader/response_count': 245,
 'downloader/response_status_count/200': 146,
 'downloader/response_status_count/301': 55,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/403': 29,
 'downloader/response_status_count/404': 5,
 'downloader/response_status_count/429': 9,
 'dupefilter/filtered': 59,
 'elapsed_time_seconds': 10.510258,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 12, 28, 54, 765747),
 'httpcompression/response_bytes': 14897292,
 'httpcompression/response_count': 157,
 'httperror/response_ignored_count': 16,
 'httperror/response_ignored_status_count/403': 14,
 'httperror/response_ignored_status_count/429': 2,
 'item_scraped_count': 26,
 'log_count/DEBUG': 476,
 'log_count/ERROR': 3,
 'log_count/INFO': 26,
 'request_depth_max': 1,
 'response_received_count': 182,
 'retry/count': 7,
 'retry/max_reached': 2,
 'retry/reason_count/429 Unknown Status': 7,
 'robotstxt/request_count': 84,
 'robotstxt/response_count': 84,
 'robotstxt/response_status_count/200': 64,
 'robotstxt/response_status_count/403': 15,
 'robotstxt/response_status_count/404': 5,
 'scheduler/dequeued': 138,
 'scheduler/dequeued/memory': 138,
 'scheduler/enqueued': 138,
 'scheduler/enqueued/memory': 138,
 'start_time': datetime.datetime(2022, 12, 9, 12, 28, 44, 255489)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 21cbfd6211fd5399
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2162878827296 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2162878827296 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2162878827296 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2162878827296 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/robots.txt> from <GET http://www.fandftrees.com/robots.txt>
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.treetechohio.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/> (referer: None)
DEBUG: Filtered duplicate request: <GET http://hardwicktreecare.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (404) <GET http://ohiotreeandexcavating.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.charteroakscompany.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://trapperstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/> from <GET http://www.fandftrees.com/>
INFO: Ignoring response <403 https://www.midohiotree.org/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hardwicktreecare.com/> from <GET http://hardwicktreecare.com/>
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/robots.txt> from <GET http://starwoodtree.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.treetechohio.com/contact> (referer: https://www.treetechohio.com/)
DEBUG: Redirecting (301) to <GET http://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.net/>
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/robots.txt> from <GET http://ohiotreeandexcavating.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.com/>
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treesaremybusiness.com/> from <GET http://www.treesaremybusiness.com/>
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/contact-hardwick-tree-care> (referer: https://www.hardwicktreecare.com/)
INFO: Ignoring response <403 http://www.hackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (404) <GET http://ohiotreecare.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://www.tackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.independenttree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.charteroakscompany.com/> from <GET http://www.charteroakscompany.com/>
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/robots.txt> from <GET http://timberlandtreeohio.com/robots.txt>
INFO: Ignoring response <403 http://deeprootedtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://treesaremybusiness.com/> from <GET https://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET http://herculestree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website> (referer: None)
DEBUG: Crawled (200) <GET https://www.whymonster.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/robots.txt> from <GET http://www.jstreeservicesllc.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.charteroakscompany.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/> from <GET http://timberlandtreeohio.com/>
DEBUG: Crawled (200) <GET https://starwoodtree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.monstertreeservice.com/akron/contact-us/> from <GET https://www.whymonster.com/akron/contact-us/>
DEBUG: Crawled (403) <GET http://cottstrees.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://herculestree.com/> from <GET http://herculestree.com/>
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/> from <GET http://starwoodtree.com/>
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://cottstrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/contact-us/> (referer: https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://cottstrees.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.independenttree.com/contact-us/> (referer: https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website)
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/robots.txt> from <GET http://www.basictreecare.com/robots.txt>
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://roquetree.com/robots.txt> from <GET http://roquetree.com/robots.txt>
DEBUG: Crawled (200) <GET http://ohiotreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.kiddertreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/robots.txt> from <GET http://www.haneytreeservice.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.kiddertreemov.com/> from <GET http://www.kiddertreeservice.com/>
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/cleveland/?utm_source=GMB&utm_medium=organic&utm_campaign=AvonLake> (referer: None)
DEBUG: Redirecting (301) to <GET https://jstreeservicesllc.com/> from <GET http://www.jstreeservicesllc.com/>
DEBUG: Crawled (200) <GET https://www.basictreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/> from <GET http://www.basictreecare.com/>
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/robots.txt> from <GET http://www.jttreeservicellc.com/robots.txt>
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/> from <GET http://www.haneytreeservice.com/>
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/contact-us/> (referer: https://treesaremybusiness.com/)
DEBUG: Crawled (200) <GET https://roquetree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/> (referer: None)
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://roquetree.com/> from <GET http://roquetree.com/>
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/contact-us/> (referer: https://www.ewsmithtree.com/)
DEBUG: Crawled (200) <GET https://www.basictreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/index.html> from <GET http://haneytreeservice.com/>
DEBUG: Crawled (200) <GET https://herculestree.com/contact> (referer: https://herculestree.com/)
DEBUG: Redirecting (301) to <GET https://www.roquetree.com/> from <GET https://roquetree.com/>
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://haneytreeservice.com/index.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://www.kandatreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/robots.txt> from <GET http://www.ripleytreeservice.com/robots.txt>
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/> from <GET http://www.jttreeservicellc.com/>
INFO: Ignoring response <403 http://www.jjsfamilytreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://www.roquetree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/robots.txt> from <GET https://www.extremetreeservicestoledo.com/robots.txt>
DEBUG: Crawled (200) <GET https://herculestree.com/contact/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://parkstree.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.roquetree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.savatree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.net/> (referer: None)
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Redirecting (301) to <GET https://rawtreeserv.com/> from <GET https://www.rawtreeserv.com/>
DEBUG: Crawled (200) <GET https://www.savatree.com/dayton-ohio-tree-service-lawn-care?utm_source=GMB&utm_medium=organic&utm_campaign=dayton> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/> from <GET http://www.ripleytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/> from <GET https://www.extremetreeservicestoledo.com/>
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/contact-us/> from <GET http://www.jstreeservicesllc.com/contact-us>
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/contact-us/> (referer: https://jstreeservicesllc.com/)
DEBUG: Crawled (200) <GET https://rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://blackstreemov.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/?utm_source=googlelocal&utm_medium=organic> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.blackstreemov.com/> from <GET http://blackstreemov.com/>
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonservicerequest> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/> (referer: None)
INFO: Ignoring response <403 http://www.haymakertreeandlawn.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/contact/> (referer: https://extremetreeservicestoledo.com/)
DEBUG: Crawled (200) <GET https://rawtreeserv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/contact-us/> (referer: None)
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/cincinnati-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Cincinnati> (referer: None)
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/> (referer: None)
INFO: Ignoring response <403 http://www.cstreemulch.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://starwoodtree.com/contact-us/> (referer: https://starwoodtree.com/)
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/robots.txt> from <GET http://www.roguetreesolutions.com/robots.txt>
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
INFO: Ignoring response <403 http://www.ashtreeservicepro.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/robots.txt> from <GET http://toddstreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/contact> (referer: https://www.blackstreemov.com/)
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/robots.txt> from <GET http://hoffmantreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET http://urbanloggersohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://urbanloggersohio.com/> from <GET http://urbanloggersohio.com/>
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 5 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 19 without any user agent to enforce it on.
DEBUG: Rule at line 21 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 34 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 60 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 68 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 73 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Rule at line 75 without any user agent to enforce it on.
DEBUG: Rule at line 76 without any user agent to enforce it on.
DEBUG: Rule at line 77 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 83 without any user agent to enforce it on.
DEBUG: Rule at line 85 without any user agent to enforce it on.
DEBUG: Rule at line 86 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 89 without any user agent to enforce it on.
DEBUG: Rule at line 90 without any user agent to enforce it on.
DEBUG: Rule at line 91 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 93 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 95 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 99 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 102 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 113 without any user agent to enforce it on.
DEBUG: Rule at line 114 without any user agent to enforce it on.
DEBUG: Rule at line 115 without any user agent to enforce it on.
DEBUG: Rule at line 116 without any user agent to enforce it on.
DEBUG: Rule at line 117 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/> from <GET http://toddstreeservice.com/>
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET http://www.boonestreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Crawled (404) <GET https://www.roguetreesolutions.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 52 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 59 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 109 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 111 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 119 without any user agent to enforce it on.
DEBUG: Rule at line 120 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 128 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 155 without any user agent to enforce it on.
DEBUG: Rule at line 165 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/> from <GET http://hoffmantreeservice.com/>
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/> from <GET http://www.roguetreesolutions.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonresidential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/> (referer: None)
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET https://www.roguetreesolutions.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.boonestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.toddstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://brushbandittree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/robots.txt> from <GET http://www.treeservicenow.net/robots.txt>
DEBUG: Redirecting (302) to <GET https://www.greatdanetreeexperts.com/404.html> from <GET https://www.greatdanetreeexperts.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://barbertontree.com/robots.txt> from <GET https://www.barbertontree.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/404.html> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 136 without any user agent to enforce it on.
DEBUG: Rule at line 141 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 147 without any user agent to enforce it on.
DEBUG: Rule at line 156 without any user agent to enforce it on.
DEBUG: Rule at line 157 without any user agent to enforce it on.
DEBUG: Rule at line 191 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/akron-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Akron> (referer: None)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/contact-us/> (referer: http://www.treeservicedelawareoh.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=residential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/robots.txt> from <GET http://www.lamannatreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/northeast-cleveland-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Northeast%20Cleveland> (referer: None)
DEBUG: Crawled (200) <GET https://premiertreesllc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/robots.txt> from <GET http://tree-works-ohio.com/robots.txt>
DEBUG: Crawled (200) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/> (referer: None)
DEBUG: Crawled (200) <GET https://larochetree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
DEBUG: Retrying <GET https://premiertreesllc.com/> (failed 1 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://barbertontree.com/> from <GET https://www.barbertontree.com/>
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://brushbandittree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/> from <GET http://www.lamannatreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.larochetree.com/> from <GET https://larochetree.com/>
DEBUG: Crawled (403) <GET http://tomcotreecare.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://barbertontree.com/robots.txt> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
DEBUG: Retrying <GET https://premiertreesllc.com/> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/contact-urban-loggers/> (referer: https://urbanloggersohio.com/)
DEBUG: Crawled (403) <GET http://tomcotreecare.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 40, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.larochetree.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://tomcotreecare.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.dolcestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Retrying <GET https://barbertontree.com/robots.txt> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/contact/> (referer: https://lamannatreeservice.com/)
DEBUG: Crawled (200) <GET https://premiertreesllc.com/> (referer: None)
ERROR: Gave up retrying <GET https://barbertontree.com/robots.txt> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 21 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 34 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/robots.txt> from <GET https://www.treeservicenow.net/robots.txt>
DEBUG: Crawled (200) <GET https://www.larochetree.com/> (referer: None)
DEBUG: Crawled (404) <GET https://www.napierandson.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://barbertontree.com/> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://brushbandittree.com/contact-us/> (referer: https://brushbandittree.com/)
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/robots.txt> (referer: None)
DEBUG: Retrying <GET https://barbertontree.com/> (failed 2 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/> from <GET http://tree-works-ohio.com/>
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.napierandson.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
ERROR: Gave up retrying <GET https://premiertreesllc.com/contact-us/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://premiertreesllc.com/contact-us/> (referer: https://premiertreesllc.com/)
DEBUG: Crawled (200) <GET https://www.larochetree.com/contact> (referer: https://www.larochetree.com/)
INFO: Ignoring response <429 https://premiertreesllc.com/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/> from <GET http://www.treeservicenow.net/>
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/contact-us/> (referer: https://treeservicecolumbusohio.net/)
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/> from <GET https://www.treeservicenow.net/>
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/contact-tree-works-for-all-your-emergency-services-tree-removal-stump-grinding-etc/> (referer: https://tree-works-ohio.com/)
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/> (referer: None)
DEBUG: Crawled (200) <GET https://barbertontree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/contact_us_1> (referer: https://treeservicenow.net/)
DEBUG: Crawled (200) <GET https://barbertontree.com/contactus/> (referer: https://barbertontree.com/)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 65165,
 'downloader/request_count': 247,
 'downloader/request_method_count/GET': 247,
 'downloader/response_bytes': 3575326,
 'downloader/response_count': 247,
 'downloader/response_status_count/200': 147,
 'downloader/response_status_count/301': 55,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/403': 29,
 'downloader/response_status_count/404': 5,
 'downloader/response_status_count/429': 10,
 'dupefilter/filtered': 61,
 'elapsed_time_seconds': 11.599519,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 12, 30, 14, 195634),
 'httpcompression/response_bytes': 15521159,
 'httpcompression/response_count': 158,
 'httperror/response_ignored_count': 15,
 'httperror/response_ignored_status_count/403': 14,
 'httperror/response_ignored_status_count/429': 1,
 'log_count/DEBUG': 467,
 'log_count/ERROR': 3,
 'log_count/INFO': 25,
 'request_depth_max': 1,
 'response_received_count': 183,
 'retry/count': 8,
 'retry/max_reached': 2,
 'retry/reason_count/429 Unknown Status': 8,
 'robotstxt/request_count': 84,
 'robotstxt/response_count': 84,
 'robotstxt/response_status_count/200': 63,
 'robotstxt/response_status_count/403': 15,
 'robotstxt/response_status_count/404': 5,
 'robotstxt/response_status_count/429': 1,
 'scheduler/dequeued': 139,
 'scheduler/dequeued/memory': 139,
 'scheduler/enqueued': 139,
 'scheduler/enqueued/memory': 139,
 'start_time': datetime.datetime(2022, 12, 9, 12, 30, 2, 596115)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: d106c38301cd835f
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/robots.txt> from <GET http://www.fandftrees.com/robots.txt>
DEBUG: Attempting to acquire lock 2759908645168 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2759908645168 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2759908645168 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2759908645168 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.treetechohio.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/robots.txt> (referer: None)
DEBUG: Filtered duplicate request: <GET http://hardwicktreecare.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/> from <GET http://www.fandftrees.com/>
DEBUG: Crawled (200) <GET https://www.treetechohio.com/> (referer: None)
DEBUG: Crawled (404) <GET http://ohiotreeandexcavating.net/robots.txt> (referer: None)
INFO: Ignoring response <403 https://trapperstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.charteroakscompany.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/> (referer: None)
DEBUG: Crawled (200) <GET http://hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.fandftrees.com/> (referer: None)
INFO: Ignoring response <403 https://www.midohiotree.org/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.hardwicktreecare.com/> from <GET http://hardwicktreecare.com/>
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/robots.txt> from <GET http://starwoodtree.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.net/>
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/robots.txt> from <GET http://ohiotreeandexcavating.com/robots.txt>
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/contact> (referer: https://www.treetechohio.com/)
DEBUG: Crawled (404) <GET http://ohiotreecare.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.com/>
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treesaremybusiness.com/> from <GET http://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/contact-hardwick-tree-care> (referer: https://www.hardwicktreecare.com/)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown> (referer: None)
INFO: Ignoring response <403 https://www.tackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/> (referer: None)
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.independenttree.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://www.hackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.charteroakscompany.com/> from <GET http://www.charteroakscompany.com/>
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/robots.txt> from <GET http://timberlandtreeohio.com/robots.txt>
INFO: Ignoring response <403 http://deeprootedtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://treesaremybusiness.com/> from <GET https://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET http://herculestree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website> (referer: None)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/robots.txt> from <GET http://www.jstreeservicesllc.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.whymonster.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/> from <GET http://timberlandtreeohio.com/>
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.monstertreeservice.com/akron/contact-us/> from <GET https://www.whymonster.com/akron/contact-us/>
DEBUG: Crawled (200) <GET https://www.charteroakscompany.com/> (referer: None)
DEBUG: Crawled (403) <GET http://cottstrees.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://herculestree.com/> from <GET http://herculestree.com/>
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/> from <GET http://starwoodtree.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/contact-us/> (referer: https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://cottstrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.independenttree.com/contact-us/> (referer: https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://cottstrees.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.independenttree.com/contact-us/>
{'emails': ['info@independenttree.com'],
 'facebook': 'https://www.facebook.com/IndependentTreeOH/',
 'instagram': 'https://www.instagram.com/independenttreeservice/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET http://ohiotreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://roquetree.com/robots.txt> from <GET http://roquetree.com/robots.txt>
DEBUG: Crawled (200) <GET http://www.kiddertreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/cleveland/?utm_source=GMB&utm_medium=organic&utm_campaign=AvonLake> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.kiddertreemov.com/> from <GET http://www.kiddertreeservice.com/>
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/robots.txt> from <GET http://www.haneytreeservice.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/robots.txt> from <GET http://www.basictreecare.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://jstreeservicesllc.com/> from <GET http://www.jstreeservicesllc.com/>
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/robots.txt> from <GET http://www.jttreeservicellc.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.basictreecare.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/> from <GET http://www.haneytreeservice.com/>
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/contact-us/> (referer: https://treesaremybusiness.com/)
DEBUG: Crawled (200) <GET https://roquetree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/> from <GET http://www.basictreecare.com/>
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/contact-us/> (referer: https://www.ewsmithtree.com/)
DEBUG: Redirecting (301) to <GET https://roquetree.com/> from <GET http://roquetree.com/>
DEBUG: Crawled (200) <GET https://herculestree.com/contact> (referer: https://herculestree.com/)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/index.html> from <GET http://haneytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.basictreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.roquetree.com/> from <GET https://roquetree.com/>
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.kandatreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://haneytreeservice.com/index.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/robots.txt> from <GET http://www.ripleytreeservice.com/robots.txt>
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.jjsfamilytreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/> from <GET http://www.jttreeservicellc.com/>
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://www.roquetree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/robots.txt> from <GET https://www.extremetreeservicestoledo.com/robots.txt>
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.roquetree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.savatree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/> from <GET http://www.ripleytreeservice.com/>
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET https://www.rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.savatree.com/dayton-ohio-tree-service-lawn-care?utm_source=GMB&utm_medium=organic&utm_campaign=dayton> (referer: None)
DEBUG: Redirecting (301) to <GET https://rawtreeserv.com/> from <GET https://www.rawtreeserv.com/>
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/> from <GET https://www.extremetreeservicestoledo.com/>
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/cincinnati-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Cincinnati> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 40, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: adres:%2050%20Hillside%20Dr,%20Delaware,%20OH%2043015,%20Stany%20Zjednoczone
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/contact-us/> from <GET http://www.jstreeservicesllc.com/contact-us>
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/contact-us/> (referer: https://jstreeservicesllc.com/)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/> (referer: None)
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://jstreeservicesllc.com/contact-us/>
{'emails': ['j_s.tree@yahoo.com'],
 'facebook': 'http://www.facebook.com/jandstreeservices',
 'instagram': 'http://www.instagram.com/jandstreeservices',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/?utm_source=googlelocal&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/contact-us/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=residential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/contact/> (referer: https://extremetreeservicestoledo.com/)
DEBUG: Scraped from <200 http://jstreeservicesllc.com/contact-us/>
{'emails': ['j_s.tree@yahoo.com'],
 'facebook': 'http://www.facebook.com/jandstreeservices',
 'instagram': 'http://www.instagram.com/jandstreeservices',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://rawtreeserv.com/> (referer: None)
DEBUG: Scraped from <200 https://extremetreeservicestoledo.com/contact/>
{'emails': ['extremetreeswanton@gmail.com'],
 'facebook': 'https://www.facebook.com/ToledosExtremeTree/',
 'instagram': '',
 'linkedin': '',
 'twitter': 'https://twitter.com/SuperClimber101'}
DEBUG: Crawled (200) <GET https://starwoodtree.com/contact-us/> (referer: https://starwoodtree.com/)
DEBUG: Scraped from <200 https://starwoodtree.com/contact-us/>
{'emails': ['support@starwoodtree.com'],
 'facebook': 'https://www.facebook.com/Starwoodtreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/contact-us/> (referer: http://www.treeservicedelawareoh.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonservicerequest> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonresidential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 39466,
 'downloader/request_count': 147,
 'downloader/request_method_count/GET': 147,
 'downloader/response_bytes': 2116595,
 'downloader/response_count': 147,
 'downloader/response_status_count/200': 95,
 'downloader/response_status_count/301': 34,
 'downloader/response_status_count/403': 16,
 'downloader/response_status_count/404': 2,
 'dupefilter/filtered': 29,
 'elapsed_time_seconds': 7.155596,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 12, 30, 49, 142098),
 'httpcompression/response_bytes': 9555494,
 'httpcompression/response_count': 102,
 'httperror/response_ignored_count': 8,
 'httperror/response_ignored_status_count/403': 8,
 'item_scraped_count': 5,
 'log_count/DEBUG': 178,
 'log_count/ERROR': 1,
 'log_count/INFO': 18,
 'request_depth_max': 1,
 'response_received_count': 113,
 'robotstxt/request_count': 52,
 'robotstxt/response_count': 52,
 'robotstxt/response_status_count/200': 42,
 'robotstxt/response_status_count/403': 8,
 'robotstxt/response_status_count/404': 2,
 'scheduler/dequeued': 84,
 'scheduler/dequeued/memory': 84,
 'scheduler/enqueued': 84,
 'scheduler/enqueued/memory': 84,
 'start_time': datetime.datetime(2022, 12, 9, 12, 30, 41, 986502)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: b29100bc1128a28d
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1772028846064 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1772028846064 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1772028846064 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1772028846064 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 42 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.treetechohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.columbustreeservicesllc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/robots.txt> from <GET http://www.fandftrees.com/robots.txt>
DEBUG: Crawled (403) <GET https://trapperstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/> (referer: None)
DEBUG: Filtered duplicate request: <GET http://hardwicktreecare.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (403) <GET https://www.midohiotree.org/> (referer: None)
INFO: Ignoring response <403 https://trapperstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.fandftrees.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.fandftrees.com/> from <GET http://www.fandftrees.com/>
DEBUG: Crawled (200) <GET http://www.charteroakscompany.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://www.midohiotree.org/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.fandftrees.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hardwicktreecare.com/> from <GET http://hardwicktreecare.com/>
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/robots.txt> from <GET http://starwoodtree.com/robots.txt>
DEBUG: Crawled (404) <GET http://ohiotreeandexcavating.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.treetechohio.com/contact> (referer: https://www.treetechohio.com/)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.net/>
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.russelltreeexperts.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.hardwicktreecare.com/contact-hardwick-tree-care> (referer: https://www.hardwicktreecare.com/)
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/robots.txt> from <GET http://ohiotreeandexcavating.com/robots.txt>
DEBUG: Crawled (403) <GET https://www.tackettstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown> (referer: None)
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.treesaremybusiness.com/> from <GET http://www.treesaremybusiness.com/>
DEBUG: Redirecting (301) to <GET https://ohiotreeandexcavating.com/> from <GET http://ohiotreeandexcavating.com/>
DEBUG: Crawled (404) <GET http://ohiotreecare.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
INFO: Ignoring response <403 https://www.tackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.hackettstreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.charteroakscompany.com/> from <GET http://www.charteroakscompany.com/>
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://www.hackettstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://deeprootedtreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/robots.txt> from <GET http://timberlandtreeohio.com/robots.txt>
INFO: Ignoring response <403 http://deeprootedtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://ohiotreeandexcavating.com/> (referer: None)
DEBUG: Crawled (200) <GET https://specialtytreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET http://herculestree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://treesaremybusiness.com/> from <GET https://www.treesaremybusiness.com/>
DEBUG: Crawled (200) <GET https://www.charteroakscompany.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.independenttree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.whymonster.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/robots.txt> from <GET http://www.jstreeservicesllc.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://starwoodtree.com/> from <GET http://starwoodtree.com/>
DEBUG: Crawled (403) <GET http://cottstrees.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.timberlandtreeohio.com/> from <GET http://timberlandtreeohio.com/>
DEBUG: Redirecting (301) to <GET https://www.monstertreeservice.com/akron/contact-us/> from <GET https://www.whymonster.com/akron/contact-us/>
DEBUG: Crawled (403) <GET http://cottstrees.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://herculestree.com/> from <GET http://herculestree.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/akron/contact-us/> (referer: https://www.monstertreeservice.com/akron/?utm_source=GMB&utm_medium=organic&utm_campaign=doylestown)
INFO: Ignoring response <403 http://cottstrees.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://roquetree.com/robots.txt> from <GET http://roquetree.com/robots.txt>
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website> (referer: None)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/cleveland/?utm_source=GMB&utm_medium=organic&utm_campaign=AvonLake> (referer: None)
DEBUG: Crawled (200) <GET http://ohiotreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/robots.txt> from <GET http://www.basictreecare.com/robots.txt>
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/robots.txt> from <GET http://www.haneytreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET http://www.kiddertreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.kiddertreemov.com/> from <GET http://www.kiddertreeservice.com/>
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://jstreeservicesllc.com/> from <GET http://www.jstreeservicesllc.com/>
DEBUG: Crawled (200) <GET https://www.independenttree.com/contact-us/> (referer: https://www.independenttree.com/?utm_source=gmb&utm_medium=local&utm_campaign=website)
DEBUG: Crawled (200) <GET https://roquetree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.independenttree.com/contact-us/>
{'emails': ['info@independenttree.com'],
 'facebook': 'https://www.facebook.com/IndependentTreeOH/',
 'instagram': 'https://www.instagram.com/independenttreeservice/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://roquetree.com/> from <GET http://roquetree.com/>
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/robots.txt> from <GET http://www.jttreeservicellc.com/robots.txt>
DEBUG: Crawled (200) <GET https://treesaremybusiness.com/contact-us/> (referer: https://treesaremybusiness.com/)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/> from <GET http://www.haneytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.basictreecare.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.kiddertreemov.com/> (referer: None)
DEBUG: Crawled (200) <GET http://haneytreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.roquetree.com/> from <GET https://roquetree.com/>
DEBUG: Redirecting (301) to <GET https://www.basictreecare.com/> from <GET http://www.basictreecare.com/>
DEBUG: Crawled (200) <GET http://www.timberlandtreeohio.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ewsmithtree.com/contact-us/> (referer: https://www.ewsmithtree.com/)
DEBUG: Redirecting (301) to <GET http://haneytreeservice.com/index.html> from <GET http://haneytreeservice.com/>
DEBUG: Crawled (200) <GET https://herculestree.com/contact> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.basictreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://starwoodtree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://haneytreeservice.com/index.html> (referer: None)
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.kandatreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.jjsfamilytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.roquetree.com/robots.txt> (referer: None)
INFO: Ignoring response <403 https://www.kandatreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/robots.txt> from <GET http://www.ripleytreeservice.com/robots.txt>
INFO: Ignoring response <403 http://www.jjsfamilytreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.jttreeservicellc.com/> from <GET http://www.jttreeservicellc.com/>
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://www.roquetree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://herculestree.com/contact/request-quote/> (referer: https://herculestree.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.jttreeservicellc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.savatree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/robots.txt> from <GET https://www.extremetreeservicestoledo.com/robots.txt>
DEBUG: Crawled (200) <GET https://parkstree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://oak-tree-services-tree-service.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (200) <GET https://www.savatree.com/dayton-ohio-tree-service-lawn-care?utm_source=GMB&utm_medium=organic&utm_campaign=dayton> (referer: None)
DEBUG: Crawled (200) <GET https://parkstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://rawtreeserv.com/> from <GET https://www.rawtreeserv.com/>
DEBUG: Redirecting (301) to <GET https://www.ripleytreeservice.com/> from <GET http://www.ripleytreeservice.com/>
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/cincinnati-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Cincinnati> (referer: None)
DEBUG: Redirecting (301) to <GET https://extremetreeservicestoledo.com/> from <GET https://www.extremetreeservicestoledo.com/>
DEBUG: Crawled (200) <GET https://starwoodtree.com/contact-us/> (referer: https://starwoodtree.com/)
DEBUG: Redirecting (301) to <GET http://jstreeservicesllc.com/contact-us/> from <GET http://www.jstreeservicesllc.com/contact-us>
DEBUG: Crawled (200) <GET https://www.ripleytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://rawtreeserv.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://starwoodtree.com/contact-us/>
{'emails': ['support@starwoodtree.com'],
 'facebook': 'https://www.facebook.com/Starwoodtreeservice/',
 'instagram': '',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET http://blackstreemov.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jstreeservicesllc.com/contact-us/> (referer: https://jstreeservicesllc.com/)
DEBUG: Redirecting (301) to <GET https://www.blackstreemov.com/> from <GET http://blackstreemov.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=residential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET http://www.haymakertreeandlawn.com/> (referer: None)
DEBUG: Scraped from <200 https://jstreeservicesllc.com/contact-us/>
{'emails': ['j_s.tree@yahoo.com'],
 'facebook': 'http://www.facebook.com/jandstreeservices',
 'instagram': 'http://www.instagram.com/jandstreeservices',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://rawtreeserv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://affordabletreeservicesofohiollc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/northeast-cleveland-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Northeast%20Cleveland> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://jstreeservicesllc.com/contact-us/> (referer: None)
INFO: Ignoring response <403 http://www.haymakertreeandlawn.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeservicestoledo.com/contact/> (referer: https://extremetreeservicestoledo.com/)
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/> (referer: None)
DEBUG: Scraped from <200 http://jstreeservicesllc.com/contact-us/>
{'emails': ['j_s.tree@yahoo.com'],
 'facebook': 'http://www.facebook.com/jandstreeservices',
 'instagram': 'http://www.instagram.com/jandstreeservices',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (403) <GET http://www.cstreemulch.com/> (referer: None)
DEBUG: Scraped from <200 https://extremetreeservicestoledo.com/contact/>
{'emails': ['extremetreeswanton@gmail.com'],
 'facebook': 'https://www.facebook.com/ToledosExtremeTree/',
 'instagram': '',
 'linkedin': '',
 'twitter': 'https://twitter.com/SuperClimber101'}
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/robots.txt> (referer: None)
INFO: Ignoring response <403 http://www.cstreemulch.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.ashtreeservicepro.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treesrus-treeservice.business.site/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/robots.txt> from <GET http://www.roguetreesolutions.com/robots.txt>
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/robots.txt> from <GET http://toddstreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.blackstreemov.com/contact> (referer: https://www.blackstreemov.com/)
INFO: Ignoring response <403 http://www.ashtreeservicepro.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://extremetreeohio.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/robots.txt> from <GET http://hoffmantreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET http://urbanloggersohio.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://extremetreeohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://urbanloggersohio.com/> from <GET http://urbanloggersohio.com/>
DEBUG: Crawled (404) <GET https://www.roguetreesolutions.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 52 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 59 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 109 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 111 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 119 without any user agent to enforce it on.
DEBUG: Rule at line 120 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 128 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 155 without any user agent to enforce it on.
DEBUG: Rule at line 165 without any user agent to enforce it on.
DEBUG: Crawled (404) <GET http://www.boonestreeservice.com/robots.txt> (referer: None)
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 8 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.roguetreesolutions.com/> from <GET http://www.roguetreesolutions.com/>
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 5 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 19 without any user agent to enforce it on.
DEBUG: Rule at line 21 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 34 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 60 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 68 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 73 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Rule at line 75 without any user agent to enforce it on.
DEBUG: Rule at line 76 without any user agent to enforce it on.
DEBUG: Rule at line 77 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 81 without any user agent to enforce it on.
DEBUG: Rule at line 83 without any user agent to enforce it on.
DEBUG: Rule at line 85 without any user agent to enforce it on.
DEBUG: Rule at line 86 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 89 without any user agent to enforce it on.
DEBUG: Rule at line 90 without any user agent to enforce it on.
DEBUG: Rule at line 91 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 93 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 95 without any user agent to enforce it on.
DEBUG: Rule at line 96 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 99 without any user agent to enforce it on.
DEBUG: Rule at line 100 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 102 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 106 without any user agent to enforce it on.
DEBUG: Rule at line 107 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 112 without any user agent to enforce it on.
DEBUG: Rule at line 113 without any user agent to enforce it on.
DEBUG: Rule at line 114 without any user agent to enforce it on.
DEBUG: Rule at line 115 without any user agent to enforce it on.
DEBUG: Rule at line 116 without any user agent to enforce it on.
DEBUG: Rule at line 117 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.stevestoledotree.com/?utm_source=googlelocal&utm_me&%20Excavating%22> (referer: None)
DEBUG: Crawled (200) <GET https://www.roguetreesolutions.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.toddstreeservice.com/> from <GET http://toddstreeservice.com/>
DEBUG: Redirecting (301) to <GET https://hoffmantreeservice.com/> from <GET http://hoffmantreeservice.com/>
DEBUG: Crawled (200) <GET http://www.boonestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonservicerequest> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://hoffmantreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://rstreeservicellc.com/?utm_source=gmb&utm_medium=referral> (referer: None)
DEBUG: Crawled (403) <GET http://www.toddstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://challengerstreeservice.com/> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.greatdanetreeexperts.com/404.html> from <GET https://www.greatdanetreeexperts.com/robots.txt>
INFO: Ignoring response <403 http://www.toddstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://barbertontree.com/robots.txt> from <GET https://www.barbertontree.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/?type=nonresidential> (referer: https://www.davey.com/residential-tree-services/local-offices/columbus-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Columbus)
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/404.html> (referer: None)
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 12 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 47 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 136 without any user agent to enforce it on.
DEBUG: Rule at line 141 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 147 without any user agent to enforce it on.
DEBUG: Rule at line 156 without any user agent to enforce it on.
DEBUG: Rule at line 157 without any user agent to enforce it on.
DEBUG: Rule at line 191 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/robots.txt> from <GET http://www.lamannatreeservice.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/robots.txt> from <GET http://www.treeservicenow.net/robots.txt>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/akron-tree-service-and-lawn-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Akron> (referer: None)
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/robots.txt> from <GET http://tree-works-ohio.com/robots.txt>
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/> from <GET http://www.lamannatreeservice.com/>
DEBUG: Crawled (200) <GET https://brushbandittree.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://lamannatreeservice.com/?robots=1> from <GET https://lamannatreeservice.com/robots.txt>
DEBUG: Crawled (200) <GET https://premiertreesllc.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/?robots=1> (referer: None)
DEBUG: Crawled (200) <GET https://www.greatdanetreeexperts.com/> (referer: None)
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://larochetree.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://premiertreesllc.com/> (failed 1 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://www.larochetree.com/> from <GET https://larochetree.com/>
DEBUG: Crawled (200) <GET https://urbanloggersohio.com/contact-urban-loggers/> (referer: https://urbanloggersohio.com/)
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://lamannatreeservice.com/contact/> (referer: https://lamannatreeservice.com/)
DEBUG: Crawled (403) <GET http://tomcotreecare.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://urbanloggersohio.com/contact-urban-loggers/>
{'emails': ['Info@urbanloggersohio.com'],
 'facebook': '',
 'instagram': 'https://www.instagram.com/urbanloggersllc/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.delmartreeservices.com/> (referer: None)
DEBUG: Retrying <GET https://premiertreesllc.com/> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (403) <GET http://tomcotreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.larochetree.com/robots.txt> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 40, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (403) <GET http://www.dolcestreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://barbertontree.com/> from <GET https://www.barbertontree.com/>
INFO: Ignoring response <403 http://tomcotreecare.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.dolcestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Retrying <GET https://barbertontree.com/robots.txt> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.larochetree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://www.napierandson.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://premiertreesllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://brushbandittree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.napierandson.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.larochetree.com/contact> (referer: https://www.larochetree.com/)
DEBUG: Redirecting (301) to <GET https://tree-works-ohio.com/> from <GET http://tree-works-ohio.com/>
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 1 times): 429 Unknown Status
DEBUG: Retrying <GET https://premiertreesllc.com/contact-us/> (failed 2 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/robots.txt> from <GET https://www.treeservicenow.net/robots.txt>
DEBUG: Crawled (200) <GET https://brushbandittree.com/contact-us/> (referer: https://brushbandittree.com/)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://barbertontree.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
ERROR: Gave up retrying <GET https://premiertreesllc.com/contact-us/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://premiertreesllc.com/contact-us/> (referer: https://premiertreesllc.com/)
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/> (referer: None)
INFO: Ignoring response <429 https://premiertreesllc.com/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Retrying <GET https://barbertontree.com/> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/> (referer: None)
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/> (referer: None)
DEBUG: Retrying <GET https://barbertontree.com/> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://treeservicecolumbusohio.net/contact-us/> (referer: https://treeservicecolumbusohio.net/)
ERROR: Gave up retrying <GET https://barbertontree.com/> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://barbertontree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.treeservicedelawareoh.com/contact-us/> (referer: http://www.treeservicedelawareoh.com/)
INFO: Ignoring response <429 https://barbertontree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://tree-works-ohio.com/contact-tree-works-for-all-your-emergency-services-tree-removal-stump-grinding-etc/> (referer: https://tree-works-ohio.com/)
DEBUG: Redirecting (301) to <GET https://www.treeservicenow.net/> from <GET http://www.treeservicenow.net/>
DEBUG: Redirecting (301) to <GET https://treeservicenow.net/> from <GET https://www.treeservicenow.net/>
DEBUG: Crawled (200) <GET https://treeservicenow.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicenow.net/contact_us_1> (referer: https://treeservicenow.net/)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 64679,
 'downloader/request_count': 245,
 'downloader/request_method_count/GET': 245,
 'downloader/response_bytes': 3503515,
 'downloader/response_count': 245,
 'downloader/response_status_count/200': 146,
 'downloader/response_status_count/301': 55,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/403': 29,
 'downloader/response_status_count/404': 5,
 'downloader/response_status_count/429': 9,
 'dupefilter/filtered': 59,
 'elapsed_time_seconds': 11.368154,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 12, 34, 52, 852511),
 'httpcompression/response_bytes': 14896794,
 'httpcompression/response_count': 157,
 'httperror/response_ignored_count': 16,
 'httperror/response_ignored_status_count/403': 14,
 'httperror/response_ignored_status_count/429': 2,
 'item_scraped_count': 6,
 'log_count/DEBUG': 456,
 'log_count/ERROR': 3,
 'log_count/INFO': 26,
 'request_depth_max': 1,
 'response_received_count': 182,
 'retry/count': 7,
 'retry/max_reached': 2,
 'retry/reason_count/429 Unknown Status': 7,
 'robotstxt/request_count': 84,
 'robotstxt/response_count': 84,
 'robotstxt/response_status_count/200': 64,
 'robotstxt/response_status_count/403': 15,
 'robotstxt/response_status_count/404': 5,
 'scheduler/dequeued': 138,
 'scheduler/dequeued/memory': 138,
 'scheduler/enqueued': 138,
 'scheduler/enqueued/memory': 138,
 'start_time': datetime.datetime(2022, 12, 9, 12, 34, 41, 484357)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: d3dfd6babab51b93
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/robots.txt> from <GET http://www.cal-a-vie.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://kellysspa.com/robots.txt> from <GET http://kellysspa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/robots.txt> from <GET http://www.goldenhaven.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/robots.txt> from <GET https://kellysspa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/robots.txt> from <GET http://www.glenivy.com/robots.txt>
DEBUG: Crawled (200) <GET https://goldendoor.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/robots.txt> (referer: None)
DEBUG: Attempting to acquire lock 1903208985504 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1903208985504 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1903208985504 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1903208985504 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Crawled (200) <GET https://www.omnihotels.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://cadayspa.com/robots.txt> from <GET http://cadayspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/robots.txt> (referer: None)
DEBUG: Filtered duplicate request: <GET https://goldendoor.com/contact-us/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Crawled (200) <GET https://www.osmosis.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.wispausa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Crawled (404) <GET https://www.ritzcarlton.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.madonnainn.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://aubergeresorts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 24 without any user agent to enforce it on.
DEBUG: Rule at line 25 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 41 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 68 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Redirecting (301) to <GET https://glenivy.com/robots.txt> from <GET https://www.glenivy.com/robots.txt>
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Redirecting (301) to <GET http://boonhotels.com/robots.txt> from <GET http://www.boonhotels.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/robots.txt> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://glenivy.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/robots.txt> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/)
DEBUG: Crawled (200) <GET http://boonhotels.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
ERROR: Gave up retrying <GET https://www.hyatt.com/robots.txt> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.terranea.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/robots.txt> from <GET http://www.evo-spa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://wispausa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.constantcontact.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET https://www.constantcontact.com/legal/service-provider>
DEBUG: Crawled (200) <GET https://www.evo-spa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/robots.txt> from <GET http://www.sycamoresprings.com/robots.txt>
DEBUG: Crawled (200) <GET https://glenivy.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://boonhotels.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://the-spring.com/contact/> (referer: https://the-spring.com/)
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/robots.txt> from <GET http://www.ranchovalencia.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/robots.txt> from <GET http://www.sweetwaterspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ranchovalencia.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Redirecting (301) to <GET https://banyancay.com/robots.txt> from <GET https://www.banyancay.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://wecarespa.com/robots.txt> from <GET http://www.wecarespa.com/robots.txt>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://sweetwaterspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/robots.txt> from <GET http://www.beverlyhotsprings.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/robots.txt> from <GET http://www.lapeauspafresno.com/robots.txt>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://www.canyonranch.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://sweetwaterspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://wecarespa.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://banyancay.com/robots.txt> (referer: None)
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 7 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 18 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 24 without any user agent to enforce it on.
DEBUG: Rule at line 25 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 52 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 59 without any user agent to enforce it on.
DEBUG: Rule at line 60 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/robots.txt> from <GET http://www.lagunacanyonspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.carnerosresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://wecarespa.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Redirecting (301) to <GET https://banyancay.com/contact-us.html> from <GET https://www.banyancay.com/contact-us.html>
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://banyancay.com/robots.txt> (referer: None)
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 7 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 18 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 24 without any user agent to enforce it on.
DEBUG: Rule at line 25 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 52 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 59 without any user agent to enforce it on.
DEBUG: Rule at line 60 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://carnerosresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://theravenspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Crawled (404) <GET https://www.ranchobernardoinn.com/robots.txt> (referer: None)
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 73 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Rule at line 83 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 141 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 146 without any user agent to enforce it on.
DEBUG: Rule at line 152 without any user agent to enforce it on.
DEBUG: Rule at line 173 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 260 without any user agent to enforce it on.
DEBUG: Rule at line 265 without any user agent to enforce it on.
DEBUG: Rule at line 268 without any user agent to enforce it on.
DEBUG: Rule at line 271 without any user agent to enforce it on.
DEBUG: Rule at line 274 without any user agent to enforce it on.
DEBUG: Rule at line 277 without any user agent to enforce it on.
DEBUG: Rule at line 280 without any user agent to enforce it on.
DEBUG: Rule at line 283 without any user agent to enforce it on.
DEBUG: Rule at line 288 without any user agent to enforce it on.
DEBUG: Rule at line 293 without any user agent to enforce it on.
DEBUG: Rule at line 296 without any user agent to enforce it on.
DEBUG: Rule at line 299 without any user agent to enforce it on.
DEBUG: Rule at line 302 without any user agent to enforce it on.
DEBUG: Rule at line 305 without any user agent to enforce it on.
DEBUG: Rule at line 308 without any user agent to enforce it on.
DEBUG: Rule at line 311 without any user agent to enforce it on.
DEBUG: Rule at line 314 without any user agent to enforce it on.
DEBUG: Rule at line 320 without any user agent to enforce it on.
DEBUG: Rule at line 325 without any user agent to enforce it on.
DEBUG: Rule at line 330 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 336 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 342 without any user agent to enforce it on.
DEBUG: Rule at line 345 without any user agent to enforce it on.
DEBUG: Rule at line 348 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 358 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 368 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 374 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 380 without any user agent to enforce it on.
DEBUG: Rule at line 385 without any user agent to enforce it on.
DEBUG: Rule at line 390 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 398 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 404 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 410 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 416 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 422 without any user agent to enforce it on.
DEBUG: Rule at line 425 without any user agent to enforce it on.
DEBUG: Rule at line 430 without any user agent to enforce it on.
DEBUG: Rule at line 435 without any user agent to enforce it on.
DEBUG: Rule at line 438 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 444 without any user agent to enforce it on.
DEBUG: Rule at line 450 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 458 without any user agent to enforce it on.
DEBUG: Rule at line 463 without any user agent to enforce it on.
DEBUG: Rule at line 466 without any user agent to enforce it on.
DEBUG: Rule at line 469 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 475 without any user agent to enforce it on.
DEBUG: Rule at line 478 without any user agent to enforce it on.
DEBUG: Rule at line 490 without any user agent to enforce it on.
DEBUG: Rule at line 491 without any user agent to enforce it on.
DEBUG: Rule at line 511 without any user agent to enforce it on.
DEBUG: Rule at line 543 without any user agent to enforce it on.
DEBUG: Rule at line 545 without any user agent to enforce it on.
DEBUG: Rule at line 550 without any user agent to enforce it on.
DEBUG: Rule at line 551 without any user agent to enforce it on.
DEBUG: Rule at line 552 without any user agent to enforce it on.
DEBUG: Rule at line 620 without any user agent to enforce it on.
DEBUG: Rule at line 627 without any user agent to enforce it on.
DEBUG: Rule at line 629 without any user agent to enforce it on.
DEBUG: Rule at line 633 without any user agent to enforce it on.
DEBUG: Rule at line 637 without any user agent to enforce it on.
DEBUG: Rule at line 641 without any user agent to enforce it on.
DEBUG: Rule at line 642 without any user agent to enforce it on.
DEBUG: Rule at line 643 without any user agent to enforce it on.
DEBUG: Rule at line 644 without any user agent to enforce it on.
DEBUG: Rule at line 658 without any user agent to enforce it on.
DEBUG: Rule at line 662 without any user agent to enforce it on.
DEBUG: Rule at line 663 without any user agent to enforce it on.
DEBUG: Rule at line 664 without any user agent to enforce it on.
DEBUG: Rule at line 665 without any user agent to enforce it on.
DEBUG: Rule at line 666 without any user agent to enforce it on.
DEBUG: Rule at line 684 without any user agent to enforce it on.
DEBUG: Rule at line 685 without any user agent to enforce it on.
DEBUG: Rule at line 686 without any user agent to enforce it on.
DEBUG: Rule at line 693 without any user agent to enforce it on.
DEBUG: Rule at line 694 without any user agent to enforce it on.
DEBUG: Rule at line 698 without any user agent to enforce it on.
DEBUG: Rule at line 699 without any user agent to enforce it on.
DEBUG: Rule at line 700 without any user agent to enforce it on.
DEBUG: Rule at line 701 without any user agent to enforce it on.
DEBUG: Rule at line 702 without any user agent to enforce it on.
DEBUG: Rule at line 703 without any user agent to enforce it on.
DEBUG: Rule at line 705 without any user agent to enforce it on.
DEBUG: Rule at line 707 without any user agent to enforce it on.
DEBUG: Rule at line 747 without any user agent to enforce it on.
DEBUG: Rule at line 754 without any user agent to enforce it on.
DEBUG: Rule at line 755 without any user agent to enforce it on.
DEBUG: Rule at line 780 without any user agent to enforce it on.
DEBUG: Rule at line 787 without any user agent to enforce it on.
DEBUG: Rule at line 788 without any user agent to enforce it on.
DEBUG: Rule at line 818 without any user agent to enforce it on.
DEBUG: Rule at line 821 without any user agent to enforce it on.
DEBUG: Rule at line 828 without any user agent to enforce it on.
DEBUG: Rule at line 829 without any user agent to enforce it on.
DEBUG: Rule at line 834 without any user agent to enforce it on.
DEBUG: Rule at line 836 without any user agent to enforce it on.
DEBUG: Rule at line 839 without any user agent to enforce it on.
DEBUG: Rule at line 840 without any user agent to enforce it on.
DEBUG: Rule at line 841 without any user agent to enforce it on.
DEBUG: Rule at line 894 without any user agent to enforce it on.
DEBUG: Rule at line 895 without any user agent to enforce it on.
DEBUG: Rule at line 896 without any user agent to enforce it on.
DEBUG: Rule at line 897 without any user agent to enforce it on.
DEBUG: Rule at line 898 without any user agent to enforce it on.
DEBUG: Rule at line 900 without any user agent to enforce it on.
DEBUG: Rule at line 905 without any user agent to enforce it on.
DEBUG: Rule at line 906 without any user agent to enforce it on.
DEBUG: Rule at line 907 without any user agent to enforce it on.
DEBUG: Rule at line 908 without any user agent to enforce it on.
DEBUG: Rule at line 913 without any user agent to enforce it on.
DEBUG: Rule at line 932 without any user agent to enforce it on.
DEBUG: Rule at line 933 without any user agent to enforce it on.
DEBUG: Rule at line 944 without any user agent to enforce it on.
DEBUG: Rule at line 953 without any user agent to enforce it on.
DEBUG: Rule at line 956 without any user agent to enforce it on.
DEBUG: Rule at line 961 without any user agent to enforce it on.
DEBUG: Rule at line 970 without any user agent to enforce it on.
DEBUG: Rule at line 986 without any user agent to enforce it on.
DEBUG: Rule at line 987 without any user agent to enforce it on.
DEBUG: Rule at line 988 without any user agent to enforce it on.
DEBUG: Rule at line 989 without any user agent to enforce it on.
DEBUG: Rule at line 995 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/robots.txt> from <GET http://www.trilogyspa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/robots.txt> from <GET http://www.thebluedoorhanford.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Redirecting (301) to <GET https://banyancay.com/> from <GET https://banyancay.com/contact-us.html>
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://harbin.org/robots.txt> from <GET http://www.harbin.org/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/robots.txt> from <GET http://www.teahousespa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.paseahotel.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/robots.txt> from <GET http://www.missioninn.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://harbin.org/robots.txt> from <GET http://harbin.org/robots.txt>
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/robots.txt> from <GET http://doubleeagle.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.missioninn.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://banyancay.com/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://harbin.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.montagehotels.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Crawled (200) <GET https://harbin.org/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/robots.txt> from <GET https://www.mysheerbliss.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/robots.txt> from <GET https://doubleeagle.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/robots.txt> from <GET https://bardessono.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/blogs> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/robots.txt> from <GET http://www.senspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET https://petitespa.net/robots.txt> (referer: None)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 1 times): 502 Bad Gateway
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 2 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://www.bardessono.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://petitespa.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/robots.txt> (referer: None)
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.senspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/robots.txt> from <GET https://sheer-bliss-organic-spa.myshopify.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Crawled (200) <GET http://metropolissalonspa.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET http://metropolissalonspa.com/>
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://mysheerbliss.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/pages/contact-us-spa-policy> from <GET https://sheer-bliss-organic-spa.myshopify.com/pages/contact-us-spa-policy>
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://www.bardessono.com/robots.txt> (referer: None)
DEBUG: Crawled (451) <GET https://www.morongocasinoresort.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
DEBUG: Rule at line 4 without any user agent to enforce it on.
DEBUG: Rule at line 6 without any user agent to enforce it on.
DEBUG: Rule at line 27 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 41 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 76 without any user agent to enforce it on.
DEBUG: Rule at line 77 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 82 without any user agent to enforce it on.
DEBUG: Rule at line 86 without any user agent to enforce it on.
DEBUG: Rule at line 89 without any user agent to enforce it on.
DEBUG: Rule at line 90 without any user agent to enforce it on.
DEBUG: Rule at line 91 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 93 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 102 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 109 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 114 without any user agent to enforce it on.
DEBUG: Rule at line 115 without any user agent to enforce it on.
DEBUG: Rule at line 116 without any user agent to enforce it on.
DEBUG: Rule at line 118 without any user agent to enforce it on.
DEBUG: Rule at line 119 without any user agent to enforce it on.
DEBUG: Rule at line 120 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 124 without any user agent to enforce it on.
DEBUG: Rule at line 125 without any user agent to enforce it on.
DEBUG: Rule at line 126 without any user agent to enforce it on.
DEBUG: Rule at line 127 without any user agent to enforce it on.
DEBUG: Rule at line 128 without any user agent to enforce it on.
DEBUG: Rule at line 131 without any user agent to enforce it on.
DEBUG: Rule at line 132 without any user agent to enforce it on.
DEBUG: Rule at line 133 without any user agent to enforce it on.
DEBUG: Rule at line 137 without any user agent to enforce it on.
DEBUG: Rule at line 140 without any user agent to enforce it on.
DEBUG: Rule at line 143 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 146 without any user agent to enforce it on.
DEBUG: Rule at line 147 without any user agent to enforce it on.
DEBUG: Rule at line 148 without any user agent to enforce it on.
DEBUG: Rule at line 150 without any user agent to enforce it on.
DEBUG: Rule at line 151 without any user agent to enforce it on.
DEBUG: Rule at line 154 without any user agent to enforce it on.
DEBUG: Rule at line 155 without any user agent to enforce it on.
DEBUG: Rule at line 156 without any user agent to enforce it on.
DEBUG: Rule at line 157 without any user agent to enforce it on.
DEBUG: Rule at line 160 without any user agent to enforce it on.
DEBUG: Rule at line 161 without any user agent to enforce it on.
DEBUG: Rule at line 164 without any user agent to enforce it on.
DEBUG: Rule at line 167 without any user agent to enforce it on.
DEBUG: Rule at line 170 without any user agent to enforce it on.
DEBUG: Rule at line 173 without any user agent to enforce it on.
DEBUG: Rule at line 174 without any user agent to enforce it on.
DEBUG: Rule at line 189 without any user agent to enforce it on.
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Crawled (451) <GET https://www.morongocasinoresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
INFO: Ignoring response <451 https://www.morongocasinoresort.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb-listing&utm_content=brentwood> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Redirecting (301) to <GET https://oceanohalfmoonbay.com/robots.txt> from <GET http://www.oceanohalfmoonbay.com/robots.txt>
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (404) <GET https://www.ventanabigsur.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/contact> (referer: https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Redirecting (301) to <GET https://oceanohalfmoonbay.com/> from <GET http://www.oceanohalfmoonbay.com/>
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/contact/> (referer: https://oceanohalfmoonbay.com/)
DEBUG: Crawled (200) <GET https://www.ventanabigsur.com/spa/overview> (referer: None)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 2,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 2,
 'downloader/request_bytes': 81448,
 'downloader/request_count': 287,
 'downloader/request_method_count/GET': 287,
 'downloader/response_bytes': 5590976,
 'downloader/response_count': 287,
 'downloader/response_status_count/200': 184,
 'downloader/response_status_count/301': 82,
 'downloader/response_status_count/403': 1,
 'downloader/response_status_count/404': 6,
 'downloader/response_status_count/429': 6,
 'downloader/response_status_count/451': 2,
 'downloader/response_status_count/502': 6,
 'dupefilter/filtered': 29,
 'elapsed_time_seconds': 23.117353,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 12, 55, 26, 694133),
 'httpcompression/response_bytes': 18974351,
 'httpcompression/response_count': 169,
 'httperror/response_ignored_count': 5,
 'httperror/response_ignored_status_count/403': 1,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'httperror/response_ignored_status_count/451': 1,
 'httperror/response_ignored_status_count/502': 1,
 'log_count/DEBUG': 660,
 'log_count/ERROR': 4,
 'log_count/INFO': 15,
 'request_depth_max': 1,
 'response_received_count': 197,
 'retry/count': 8,
 'retry/max_reached': 4,
 'retry/reason_count/429 Unknown Status': 4,
 'retry/reason_count/502 Bad Gateway': 4,
 'robotstxt/forbidden': 2,
 'robotstxt/request_count': 92,
 'robotstxt/response_count': 92,
 'robotstxt/response_status_count/200': 84,
 'robotstxt/response_status_count/404': 5,
 'robotstxt/response_status_count/429': 1,
 'robotstxt/response_status_count/451': 1,
 'robotstxt/response_status_count/502': 1,
 'scheduler/dequeued': 160,
 'scheduler/dequeued/memory': 160,
 'scheduler/enqueued': 160,
 'scheduler/enqueued/memory': 160,
 'start_time': datetime.datetime(2022, 12, 9, 12, 55, 3, 576780)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: c6fc2a761244e918
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://kellysspa.com/robots.txt> from <GET http://kellysspa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/robots.txt> from <GET http://www.cal-a-vie.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/robots.txt> from <GET https://kellysspa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/robots.txt> from <GET http://www.goldenhaven.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/robots.txt> from <GET http://www.glenivy.com/robots.txt>
DEBUG: Attempting to acquire lock 2623880652800 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2623880652800 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2623880652800 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2623880652800 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.omnihotels.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Crawled (200) <GET https://goldendoor.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://cadayspa.com/robots.txt> from <GET http://cadayspa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.wispausa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Filtered duplicate request: <GET https://goldendoor.com/contact-us/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://www.osmosis.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.madonnainn.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://www.ritzcarlton.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': ['cavinfo@cal-a-vie.com'],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': '',
 'twitter': 'https://twitter.com/calaviespa'}
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Crawled (200) <GET https://aubergeresorts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 24 without any user agent to enforce it on.
DEBUG: Rule at line 25 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 41 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 68 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://glenivy.com/robots.txt> from <GET https://www.glenivy.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://boonhotels.com/robots.txt> from <GET http://www.boonhotels.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET http://boonhotels.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://the-spring.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://glenivy.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/robots.txt> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Retrying <GET https://www.hyatt.com/robots.txt> (failed 2 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/robots.txt> from <GET http://www.evo-spa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
ERROR: Gave up retrying <GET https://www.hyatt.com/robots.txt> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://boonhotels.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://wispausa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://banyancay.com/robots.txt> from <GET https://www.banyancay.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/robots.txt> from <GET http://www.sycamoresprings.com/robots.txt>
DEBUG: Crawled (200) <GET https://glenivy.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/robots.txt> from <GET http://www.ranchovalencia.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.constantcontact.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET https://www.constantcontact.com/legal/service-provider>
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': ['info@wispausa.com'],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': '',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Crawled (200) <GET https://banyancay.com/robots.txt> (referer: None)
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 7 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 18 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 24 without any user agent to enforce it on.
DEBUG: Rule at line 25 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 52 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 59 without any user agent to enforce it on.
DEBUG: Rule at line 60 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/robots.txt> from <GET http://www.sweetwaterspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.ranchovalencia.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/contact/> (referer: https://the-spring.com/)
DEBUG: Scraped from <200 https://the-spring.com/contact/>
{'emails': ['info@the-spring.com'],
 'facebook': 'https://www.facebook.com/thespringresortandspa/',
 'instagram': 'https://www.instagram.com/thespringresort/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Redirecting (301) to <GET http://wecarespa.com/robots.txt> from <GET http://www.wecarespa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/robots.txt> from <GET http://www.lapeauspafresno.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.canyonranch.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Crawled (404) <GET https://sweetwaterspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/robots.txt> from <GET http://www.beverlyhotsprings.com/robots.txt>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://wecarespa.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Redirecting (301) to <GET https://banyancay.com/contact-us.html> from <GET https://www.banyancay.com/contact-us.html>
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/robots.txt> from <GET http://www.lagunacanyonspa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Crawled (200) <GET https://banyancay.com/robots.txt> (referer: None)
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 7 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 18 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 24 without any user agent to enforce it on.
DEBUG: Rule at line 25 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 52 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 59 without any user agent to enforce it on.
DEBUG: Rule at line 60 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://sweetwaterspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://banyancay.com/> from <GET https://banyancay.com/contact-us.html>
DEBUG: Crawled (200) <GET http://www.carnerosresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Crawled (200) <GET https://banyancay.com/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://paradisepoint.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://wecarespa.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Scraped from <200 https://azurepalmhotsprings.com/contact-us/>
{'emails': ['info@azurepalm.com'],
 'facebook': 'https://www.facebook.com/azurepalmhotsprings',
 'instagram': 'https://www.instagram.com/azurepalmhotsprings/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://theravenspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET http://carnerosresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/robots.txt> from <GET http://www.trilogyspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Crawled (404) <GET https://www.ranchobernardoinn.com/robots.txt> (referer: None)
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 73 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Rule at line 83 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 141 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 146 without any user agent to enforce it on.
DEBUG: Rule at line 152 without any user agent to enforce it on.
DEBUG: Rule at line 173 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 260 without any user agent to enforce it on.
DEBUG: Rule at line 265 without any user agent to enforce it on.
DEBUG: Rule at line 268 without any user agent to enforce it on.
DEBUG: Rule at line 271 without any user agent to enforce it on.
DEBUG: Rule at line 274 without any user agent to enforce it on.
DEBUG: Rule at line 277 without any user agent to enforce it on.
DEBUG: Rule at line 280 without any user agent to enforce it on.
DEBUG: Rule at line 283 without any user agent to enforce it on.
DEBUG: Rule at line 288 without any user agent to enforce it on.
DEBUG: Rule at line 293 without any user agent to enforce it on.
DEBUG: Rule at line 296 without any user agent to enforce it on.
DEBUG: Rule at line 299 without any user agent to enforce it on.
DEBUG: Rule at line 302 without any user agent to enforce it on.
DEBUG: Rule at line 305 without any user agent to enforce it on.
DEBUG: Rule at line 308 without any user agent to enforce it on.
DEBUG: Rule at line 311 without any user agent to enforce it on.
DEBUG: Rule at line 314 without any user agent to enforce it on.
DEBUG: Rule at line 320 without any user agent to enforce it on.
DEBUG: Rule at line 325 without any user agent to enforce it on.
DEBUG: Rule at line 330 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 336 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 342 without any user agent to enforce it on.
DEBUG: Rule at line 345 without any user agent to enforce it on.
DEBUG: Rule at line 348 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 358 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 368 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 374 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 380 without any user agent to enforce it on.
DEBUG: Rule at line 385 without any user agent to enforce it on.
DEBUG: Rule at line 390 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 398 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 404 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 410 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 416 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 422 without any user agent to enforce it on.
DEBUG: Rule at line 425 without any user agent to enforce it on.
DEBUG: Rule at line 430 without any user agent to enforce it on.
DEBUG: Rule at line 435 without any user agent to enforce it on.
DEBUG: Rule at line 438 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 444 without any user agent to enforce it on.
DEBUG: Rule at line 450 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 458 without any user agent to enforce it on.
DEBUG: Rule at line 463 without any user agent to enforce it on.
DEBUG: Rule at line 466 without any user agent to enforce it on.
DEBUG: Rule at line 469 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 475 without any user agent to enforce it on.
DEBUG: Rule at line 478 without any user agent to enforce it on.
DEBUG: Rule at line 490 without any user agent to enforce it on.
DEBUG: Rule at line 491 without any user agent to enforce it on.
DEBUG: Rule at line 511 without any user agent to enforce it on.
DEBUG: Rule at line 543 without any user agent to enforce it on.
DEBUG: Rule at line 545 without any user agent to enforce it on.
DEBUG: Rule at line 550 without any user agent to enforce it on.
DEBUG: Rule at line 551 without any user agent to enforce it on.
DEBUG: Rule at line 552 without any user agent to enforce it on.
DEBUG: Rule at line 620 without any user agent to enforce it on.
DEBUG: Rule at line 627 without any user agent to enforce it on.
DEBUG: Rule at line 629 without any user agent to enforce it on.
DEBUG: Rule at line 633 without any user agent to enforce it on.
DEBUG: Rule at line 637 without any user agent to enforce it on.
DEBUG: Rule at line 641 without any user agent to enforce it on.
DEBUG: Rule at line 642 without any user agent to enforce it on.
DEBUG: Rule at line 643 without any user agent to enforce it on.
DEBUG: Rule at line 644 without any user agent to enforce it on.
DEBUG: Rule at line 658 without any user agent to enforce it on.
DEBUG: Rule at line 662 without any user agent to enforce it on.
DEBUG: Rule at line 663 without any user agent to enforce it on.
DEBUG: Rule at line 664 without any user agent to enforce it on.
DEBUG: Rule at line 665 without any user agent to enforce it on.
DEBUG: Rule at line 666 without any user agent to enforce it on.
DEBUG: Rule at line 684 without any user agent to enforce it on.
DEBUG: Rule at line 685 without any user agent to enforce it on.
DEBUG: Rule at line 686 without any user agent to enforce it on.
DEBUG: Rule at line 693 without any user agent to enforce it on.
DEBUG: Rule at line 694 without any user agent to enforce it on.
DEBUG: Rule at line 698 without any user agent to enforce it on.
DEBUG: Rule at line 699 without any user agent to enforce it on.
DEBUG: Rule at line 700 without any user agent to enforce it on.
DEBUG: Rule at line 701 without any user agent to enforce it on.
DEBUG: Rule at line 702 without any user agent to enforce it on.
DEBUG: Rule at line 703 without any user agent to enforce it on.
DEBUG: Rule at line 705 without any user agent to enforce it on.
DEBUG: Rule at line 707 without any user agent to enforce it on.
DEBUG: Rule at line 747 without any user agent to enforce it on.
DEBUG: Rule at line 754 without any user agent to enforce it on.
DEBUG: Rule at line 755 without any user agent to enforce it on.
DEBUG: Rule at line 780 without any user agent to enforce it on.
DEBUG: Rule at line 787 without any user agent to enforce it on.
DEBUG: Rule at line 788 without any user agent to enforce it on.
DEBUG: Rule at line 818 without any user agent to enforce it on.
DEBUG: Rule at line 821 without any user agent to enforce it on.
DEBUG: Rule at line 828 without any user agent to enforce it on.
DEBUG: Rule at line 829 without any user agent to enforce it on.
DEBUG: Rule at line 834 without any user agent to enforce it on.
DEBUG: Rule at line 836 without any user agent to enforce it on.
DEBUG: Rule at line 839 without any user agent to enforce it on.
DEBUG: Rule at line 840 without any user agent to enforce it on.
DEBUG: Rule at line 841 without any user agent to enforce it on.
DEBUG: Rule at line 894 without any user agent to enforce it on.
DEBUG: Rule at line 895 without any user agent to enforce it on.
DEBUG: Rule at line 896 without any user agent to enforce it on.
DEBUG: Rule at line 897 without any user agent to enforce it on.
DEBUG: Rule at line 898 without any user agent to enforce it on.
DEBUG: Rule at line 900 without any user agent to enforce it on.
DEBUG: Rule at line 905 without any user agent to enforce it on.
DEBUG: Rule at line 906 without any user agent to enforce it on.
DEBUG: Rule at line 907 without any user agent to enforce it on.
DEBUG: Rule at line 908 without any user agent to enforce it on.
DEBUG: Rule at line 913 without any user agent to enforce it on.
DEBUG: Rule at line 932 without any user agent to enforce it on.
DEBUG: Rule at line 933 without any user agent to enforce it on.
DEBUG: Rule at line 944 without any user agent to enforce it on.
DEBUG: Rule at line 953 without any user agent to enforce it on.
DEBUG: Rule at line 956 without any user agent to enforce it on.
DEBUG: Rule at line 961 without any user agent to enforce it on.
DEBUG: Rule at line 970 without any user agent to enforce it on.
DEBUG: Rule at line 986 without any user agent to enforce it on.
DEBUG: Rule at line 987 without any user agent to enforce it on.
DEBUG: Rule at line 988 without any user agent to enforce it on.
DEBUG: Rule at line 989 without any user agent to enforce it on.
DEBUG: Rule at line 995 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/robots.txt> from <GET http://www.thebluedoorhanford.com/robots.txt>
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Redirecting (301) to <GET http://harbin.org/robots.txt> from <GET http://www.harbin.org/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/robots.txt> from <GET http://www.teahousespa.com/robots.txt>
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/> (referer: https://www.sweetwaterspa.com/)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': ['info@wecarespa.com'],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': '',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': '',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/robots.txt> from <GET http://www.missioninn.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Redirecting (301) to <GET https://harbin.org/robots.txt> from <GET http://harbin.org/robots.txt>
DEBUG: Crawled (200) <GET https://www.paseahotel.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.missioninn.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': '',
 'linkedin': '',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Crawled (200) <GET https://www.teahousespa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Crawled (200) <GET https://www.montagehotels.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/robots.txt> from <GET https://bardessono.com/robots.txt>
DEBUG: Crawled (200) <GET https://harbin.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/robots.txt> from <GET https://www.mysheerbliss.com/robots.txt>
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/robots.txt> from <GET http://doubleeagle.com/robots.txt>
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/blogs> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://harbin.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://petitespa.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/contact> (referer: https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Crawled (200) <GET https://petitespa.net/> (referer: None)
DEBUG: Scraped from <200 https://www.romanspahotsprings.com/contact>
{'emails': ['Reservations75@Romanspahotsprings.com'],
 'facebook': 'https://www.facebook.com/romanspahotsprings',
 'instagram': 'https://www.instagram.com/romanspahotspringsresort/?ref=badge',
 'linkedin': '',
 'twitter': 'https://twitter.com/romansparesort'}
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Crawled (200) <GET https://www.bardessono.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/robots.txt> from <GET https://sheer-bliss-organic-spa.myshopify.com/robots.txt>
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 1 times): 502 Bad Gateway
DEBUG: Redirecting (301) to <GET https://www.senspa.com/robots.txt> from <GET http://www.senspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://mysheerbliss.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 2 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/pages/contact-us-spa-policy> from <GET https://sheer-bliss-organic-spa.myshopify.com/pages/contact-us-spa-policy>
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://metropolissalonspa.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET http://metropolissalonspa.com/>
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Redirecting (301) to <GET https://oceanohalfmoonbay.com/robots.txt> from <GET http://www.oceanohalfmoonbay.com/robots.txt>
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb-listing&utm_content=brentwood> (referer: None)
DEBUG: Crawled (404) <GET https://www.ventanabigsur.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.senspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/robots.txt> (referer: None)
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
DEBUG: Redirecting (301) to <GET https://oceanohalfmoonbay.com/> from <GET http://www.oceanohalfmoonbay.com/>
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Redirecting (301) to <GET https://www.rushcreeklodge.com/robots.txt> from <GET http://www.rushcreeklodge.com/robots.txt>
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/robots.txt> from <GET https://doubleeagle.com/robots.txt>
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/> (referer: None)
DEBUG: Crawled (451) <GET https://www.morongocasinoresort.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
DEBUG: Rule at line 4 without any user agent to enforce it on.
DEBUG: Rule at line 6 without any user agent to enforce it on.
DEBUG: Rule at line 27 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 41 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 76 without any user agent to enforce it on.
DEBUG: Rule at line 77 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 82 without any user agent to enforce it on.
DEBUG: Rule at line 86 without any user agent to enforce it on.
DEBUG: Rule at line 89 without any user agent to enforce it on.
DEBUG: Rule at line 90 without any user agent to enforce it on.
DEBUG: Rule at line 91 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 93 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 102 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 109 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 114 without any user agent to enforce it on.
DEBUG: Rule at line 115 without any user agent to enforce it on.
DEBUG: Rule at line 116 without any user agent to enforce it on.
DEBUG: Rule at line 118 without any user agent to enforce it on.
DEBUG: Rule at line 119 without any user agent to enforce it on.
DEBUG: Rule at line 120 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 124 without any user agent to enforce it on.
DEBUG: Rule at line 125 without any user agent to enforce it on.
DEBUG: Rule at line 126 without any user agent to enforce it on.
DEBUG: Rule at line 127 without any user agent to enforce it on.
DEBUG: Rule at line 128 without any user agent to enforce it on.
DEBUG: Rule at line 131 without any user agent to enforce it on.
DEBUG: Rule at line 132 without any user agent to enforce it on.
DEBUG: Rule at line 133 without any user agent to enforce it on.
DEBUG: Rule at line 137 without any user agent to enforce it on.
DEBUG: Rule at line 140 without any user agent to enforce it on.
DEBUG: Rule at line 143 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 146 without any user agent to enforce it on.
DEBUG: Rule at line 147 without any user agent to enforce it on.
DEBUG: Rule at line 148 without any user agent to enforce it on.
DEBUG: Rule at line 150 without any user agent to enforce it on.
DEBUG: Rule at line 151 without any user agent to enforce it on.
DEBUG: Rule at line 154 without any user agent to enforce it on.
DEBUG: Rule at line 155 without any user agent to enforce it on.
DEBUG: Rule at line 156 without any user agent to enforce it on.
DEBUG: Rule at line 157 without any user agent to enforce it on.
DEBUG: Rule at line 160 without any user agent to enforce it on.
DEBUG: Rule at line 161 without any user agent to enforce it on.
DEBUG: Rule at line 164 without any user agent to enforce it on.
DEBUG: Rule at line 167 without any user agent to enforce it on.
DEBUG: Rule at line 170 without any user agent to enforce it on.
DEBUG: Rule at line 173 without any user agent to enforce it on.
DEBUG: Rule at line 174 without any user agent to enforce it on.
DEBUG: Rule at line 189 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://paradisepoint.com/?utm_source=google-local&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (451) <GET https://www.morongocasinoresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/contact/> (referer: https://oceanohalfmoonbay.com/)
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
INFO: Ignoring response <451 https://www.morongocasinoresort.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://oceanohalfmoonbay.com/contact/>
{'emails': ['admin@oceanohalfmoonbay.com'],
 'facebook': 'https://www.facebook.com/oceanohotelspa/',
 'instagram': 'https://www.instagram.com/oceanohotelspa/?ref=badge',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://aquasoleilhotel.com/robots.txt> from <GET http://www.aquasoleilhotel.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.rushcreeklodge.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.thespaatfgv.com/robots.txt> from <GET http://www.thespaatfgv.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.rushcreeklodge.com/> from <GET http://www.rushcreeklodge.com/>
DEBUG: Crawled (200) <GET http://www.thankyouandbewell.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET http://www.thankyouandbewell.com/>
DEBUG: Redirecting (301) to <GET https://www.miramonteresort.com/robots.txt> from <GET http://www.miramonteresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://aquasoleilhotel.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://aquasoleilhotel.com/> from <GET http://www.aquasoleilhotel.com/>
DEBUG: Crawled (200) <GET https://aquasoleilhotel.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://truerest.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://winerose.com/robots.txt> from <GET http://winerose.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ventanabigsur.com/spa/overview> (referer: None)
DEBUG: Crawled (200) <GET https://www.rushcreeklodge.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lidopalms.com/robots.txt> from <GET http://www.lidopalms.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.miramonteresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.lidopalms.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lidopalms.com/> from <GET http://www.lidopalms.com/>
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://winerose.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/robots.txt> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 34, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 2777: character maps to <undefined>
DEBUG: Redirecting (301) to <GET https://www.miramonteresort.com/spa> from <GET http://www.miramonteresort.com/spa>
DEBUG: Redirecting (301) to <GET https://winerose.com/> from <GET http://winerose.com/>
DEBUG: Crawled (200) <GET https://www.rushcreeklodge.com/us/contact-us/> (referer: https://www.rushcreeklodge.com/)
DEBUG: Crawled (200) <GET https://www.lidopalms.com/> (referer: None)
DEBUG: Crawled (403) <GET https://truerest.com/locations/fresno/> (referer: None)
DEBUG: Scraped from <200 https://www.rushcreeklodge.com/us/contact-us/>
{'emails': ['info@rushcreeklodge.com.'],
 'facebook': 'https://www.facebook.com/RushCreekLodge/',
 'instagram': 'https://www.instagram.com/yosemite_rushcreek/',
 'linkedin': '',
 'twitter': ''}
INFO: Ignoring response <403 https://truerest.com/locations/fresno/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://winerose.com/> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.kissmemedspa.com/robots.txt> from <GET http://kissmemedspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://aquasoleilhotel.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.miramonteresort.com/the-well-spa/> from <GET https://www.miramonteresort.com/spa>
DEBUG: Crawled (200) <GET https://www.miramonteresort.com/the-well-spa/> (referer: None)
DEBUG: Crawled (200) <GET https://mystiquemedicalspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://aquasoleilhotel.com/contact/> (referer: https://aquasoleilhotel.com/)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/contact/> (referer: https://www.macarthurplace.com/)
DEBUG: Crawled (200) <GET https://mystiquemedicalspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.kissmemedspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://mystiquemedicalspa.com/about-us/contact/> (referer: https://mystiquemedicalspa.com/)
DEBUG: Scraped from <200 https://mystiquemedicalspa.com/about-us/contact/>
{'emails': ['questions@mystiquemedicalspa.com'],
 'facebook': 'https://www.facebook.com/MystiqueFresno',
 'instagram': 'https://www.instagram.com/mystiquemedspa/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (302) to <GET https://www.kissmemedspa.com/> from <GET http://kissmemedspa.com/>
DEBUG: Crawled (200) <GET https://www.kissmemedspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.kissmemedspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://thespaatfgv.com/robots.txt> from <GET https://www.thespaatfgv.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thespaatfgv.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.thespaatfgv.com/> from <GET http://www.thespaatfgv.com/>
DEBUG: Redirecting (301) to <GET https://thespaatfgv.com/> from <GET https://www.thespaatfgv.com/>
DEBUG: Crawled (200) <GET https://thespaatfgv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://thespaatfgv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thespaatfgv.com/contact/> (referer: https://thespaatfgv.com/)
DEBUG: Scraped from <200 https://thespaatfgv.com/contact/>
{'emails': ['tammie@hungryhairsalon.com'],
 'facebook': 'https://www.facebook.com/SpaHungryHair/',
 'instagram': 'https://www.instagram.com/themedicalspa_hungryhair/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 3,
 'downloader/request_bytes': 92554,
 'downloader/request_count': 334,
 'downloader/request_method_count/GET': 334,
 'downloader/response_bytes': 6254568,
 'downloader/response_count': 334,
 'downloader/response_status_count/200': 213,
 'downloader/response_status_count/301': 97,
 'downloader/response_status_count/302': 2,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 6,
 'downloader/response_status_count/429': 6,
 'downloader/response_status_count/451': 2,
 'downloader/response_status_count/502': 6,
 'dupefilter/filtered': 42,
 'elapsed_time_seconds': 30.76051,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 13, 25, 18, 378224),
 'httpcompression/response_bytes': 21180161,
 'httpcompression/response_count': 196,
 'httperror/response_ignored_count': 6,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'httperror/response_ignored_status_count/451': 1,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 12,
 'log_count/DEBUG': 720,
 'log_count/ERROR': 5,
 'log_count/INFO': 16,
 'request_depth_max': 1,
 'response_received_count': 227,
 'retry/count': 8,
 'retry/max_reached': 4,
 'retry/reason_count/429 Unknown Status': 4,
 'retry/reason_count/502 Bad Gateway': 4,
 'robotstxt/forbidden': 3,
 'robotstxt/request_count': 106,
 'robotstxt/response_count': 106,
 'robotstxt/response_status_count/200': 98,
 'robotstxt/response_status_count/404': 5,
 'robotstxt/response_status_count/429': 1,
 'robotstxt/response_status_count/451': 1,
 'robotstxt/response_status_count/502': 1,
 'scheduler/dequeued': 186,
 'scheduler/dequeued/memory': 186,
 'scheduler/enqueued': 186,
 'scheduler/enqueued/memory': 186,
 'start_time': datetime.datetime(2022, 12, 9, 13, 24, 47, 617714)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 1ad21271b3eb6e11
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/robots.txt> from <GET http://www.cal-a-vie.com/robots.txt>
DEBUG: Attempting to acquire lock 2479866446896 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2479866446896 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2479866446896 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2479866446896 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.omnihotels.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://kellysspa.com/robots.txt> from <GET http://kellysspa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/robots.txt> from <GET https://kellysspa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/robots.txt> from <GET http://www.goldenhaven.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/robots.txt> from <GET http://www.glenivy.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://cadayspa.com/robots.txt> from <GET http://cadayspa.com/robots.txt>
DEBUG: Crawled (200) <GET http://www.wispausa.com/robots.txt> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.omnihotels.com/forms/contact-us> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Crawled (404) <GET https://www.ritzcarlton.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.osmosis.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://www.madonnainn.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 24 without any user agent to enforce it on.
DEBUG: Rule at line 25 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 41 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 68 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://aubergeresorts.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Crawled (200) <GET https://www.fourseasons.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': ['cavinfo@cal-a-vie.com'],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': '',
 'twitter': 'https://twitter.com/calaviespa'}
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Redirecting (301) to <GET https://glenivy.com/robots.txt> from <GET https://www.glenivy.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Redirecting (301) to <GET http://boonhotels.com/robots.txt> from <GET http://www.boonhotels.com/robots.txt>
DEBUG: Crawled (200) <GET http://boonhotels.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/robots.txt> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://glenivy.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/robots.txt> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.terranea.com/robots.txt> (referer: None)
ERROR: Gave up retrying <GET https://www.hyatt.com/robots.txt> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/)
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://boonhotels.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/robots.txt> from <GET http://www.evo-spa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/robots.txt> from <GET http://www.beverlyhotsprings.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://thesisleyspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.evo-spa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/robots.txt> from <GET http://www.sycamoresprings.com/robots.txt>
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Redirecting (301) to <GET https://banyancay.com/robots.txt> from <GET https://www.banyancay.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/robots.txt> from <GET http://www.sweetwaterspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://glenivy.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://banyancay.com/robots.txt> (referer: None)
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 7 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 18 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 24 without any user agent to enforce it on.
DEBUG: Rule at line 25 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 52 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 59 without any user agent to enforce it on.
DEBUG: Rule at line 60 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://wispausa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/robots.txt> from <GET http://www.ranchovalencia.com/robots.txt>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://sweetwaterspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.constantcontact.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET https://www.constantcontact.com/legal/service-provider>
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Crawled (404) <GET https://sweetwaterspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ranchovalencia.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/contact/> (referer: https://the-spring.com/)
DEBUG: Redirecting (301) to <GET http://wecarespa.com/robots.txt> from <GET http://www.wecarespa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.canyonranch.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Scraped from <200 https://the-spring.com/contact/>
{'emails': ['info@the-spring.com'],
 'facebook': 'https://www.facebook.com/thespringresortandspa/',
 'instagram': 'https://www.instagram.com/thespringresort/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/robots.txt> from <GET http://www.lapeauspafresno.com/robots.txt>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': ['info@wispausa.com'],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': '',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://banyancay.com/contact-us.html> from <GET https://www.banyancay.com/contact-us.html>
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://wecarespa.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://banyancay.com/robots.txt> (referer: None)
DEBUG: Rule at line 2 without any user agent to enforce it on.
DEBUG: Rule at line 7 without any user agent to enforce it on.
DEBUG: Rule at line 9 without any user agent to enforce it on.
DEBUG: Rule at line 10 without any user agent to enforce it on.
DEBUG: Rule at line 11 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 16 without any user agent to enforce it on.
DEBUG: Rule at line 17 without any user agent to enforce it on.
DEBUG: Rule at line 18 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 24 without any user agent to enforce it on.
DEBUG: Rule at line 25 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 33 without any user agent to enforce it on.
DEBUG: Rule at line 37 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 39 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 48 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 51 without any user agent to enforce it on.
DEBUG: Rule at line 52 without any user agent to enforce it on.
DEBUG: Rule at line 53 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 59 without any user agent to enforce it on.
DEBUG: Rule at line 60 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 65 without any user agent to enforce it on.
DEBUG: Rule at line 66 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 80 without any user agent to enforce it on.
DEBUG: Rule at line 87 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/robots.txt> from <GET http://www.lagunacanyonspa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://banyancay.com/> from <GET https://banyancay.com/contact-us.html>
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET http://www.carnerosresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&ut0> (referer: None)
DEBUG: Crawled (200) <GET https://banyancay.com/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': '',
 'linkedin': '',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Scraped from <200 https://azurepalmhotsprings.com/contact-us/>
{'emails': ['info@azurepalm.com'],
 'facebook': 'https://www.facebook.com/azurepalmhotsprings',
 'instagram': 'https://www.instagram.com/azurepalmhotsprings/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://theravenspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&ut0)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Crawled (200) <GET https://wecarespa.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/robots.txt> from <GET http://www.thebluedoorhanford.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/robots.txt> from <GET http://www.trilogyspa.com/robots.txt>
DEBUG: Crawled (200) <GET http://carnerosresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/robots.txt> from <GET http://doubleeagle.com/robots.txt>
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://www.ranchobernardoinn.com/robots.txt> (referer: None)
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 73 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Rule at line 83 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 141 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 146 without any user agent to enforce it on.
DEBUG: Rule at line 152 without any user agent to enforce it on.
DEBUG: Rule at line 173 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 260 without any user agent to enforce it on.
DEBUG: Rule at line 265 without any user agent to enforce it on.
DEBUG: Rule at line 268 without any user agent to enforce it on.
DEBUG: Rule at line 271 without any user agent to enforce it on.
DEBUG: Rule at line 274 without any user agent to enforce it on.
DEBUG: Rule at line 277 without any user agent to enforce it on.
DEBUG: Rule at line 280 without any user agent to enforce it on.
DEBUG: Rule at line 283 without any user agent to enforce it on.
DEBUG: Rule at line 288 without any user agent to enforce it on.
DEBUG: Rule at line 293 without any user agent to enforce it on.
DEBUG: Rule at line 296 without any user agent to enforce it on.
DEBUG: Rule at line 299 without any user agent to enforce it on.
DEBUG: Rule at line 302 without any user agent to enforce it on.
DEBUG: Rule at line 305 without any user agent to enforce it on.
DEBUG: Rule at line 308 without any user agent to enforce it on.
DEBUG: Rule at line 311 without any user agent to enforce it on.
DEBUG: Rule at line 314 without any user agent to enforce it on.
DEBUG: Rule at line 320 without any user agent to enforce it on.
DEBUG: Rule at line 325 without any user agent to enforce it on.
DEBUG: Rule at line 330 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 336 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 342 without any user agent to enforce it on.
DEBUG: Rule at line 345 without any user agent to enforce it on.
DEBUG: Rule at line 348 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 358 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 368 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 374 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 380 without any user agent to enforce it on.
DEBUG: Rule at line 385 without any user agent to enforce it on.
DEBUG: Rule at line 390 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 398 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 404 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 410 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 416 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 422 without any user agent to enforce it on.
DEBUG: Rule at line 425 without any user agent to enforce it on.
DEBUG: Rule at line 430 without any user agent to enforce it on.
DEBUG: Rule at line 435 without any user agent to enforce it on.
DEBUG: Rule at line 438 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 444 without any user agent to enforce it on.
DEBUG: Rule at line 450 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 458 without any user agent to enforce it on.
DEBUG: Rule at line 463 without any user agent to enforce it on.
DEBUG: Rule at line 466 without any user agent to enforce it on.
DEBUG: Rule at line 469 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 475 without any user agent to enforce it on.
DEBUG: Rule at line 478 without any user agent to enforce it on.
DEBUG: Rule at line 490 without any user agent to enforce it on.
DEBUG: Rule at line 491 without any user agent to enforce it on.
DEBUG: Rule at line 511 without any user agent to enforce it on.
DEBUG: Rule at line 543 without any user agent to enforce it on.
DEBUG: Rule at line 545 without any user agent to enforce it on.
DEBUG: Rule at line 550 without any user agent to enforce it on.
DEBUG: Rule at line 551 without any user agent to enforce it on.
DEBUG: Rule at line 552 without any user agent to enforce it on.
DEBUG: Rule at line 620 without any user agent to enforce it on.
DEBUG: Rule at line 627 without any user agent to enforce it on.
DEBUG: Rule at line 629 without any user agent to enforce it on.
DEBUG: Rule at line 633 without any user agent to enforce it on.
DEBUG: Rule at line 637 without any user agent to enforce it on.
DEBUG: Rule at line 641 without any user agent to enforce it on.
DEBUG: Rule at line 642 without any user agent to enforce it on.
DEBUG: Rule at line 643 without any user agent to enforce it on.
DEBUG: Rule at line 644 without any user agent to enforce it on.
DEBUG: Rule at line 658 without any user agent to enforce it on.
DEBUG: Rule at line 662 without any user agent to enforce it on.
DEBUG: Rule at line 663 without any user agent to enforce it on.
DEBUG: Rule at line 664 without any user agent to enforce it on.
DEBUG: Rule at line 665 without any user agent to enforce it on.
DEBUG: Rule at line 666 without any user agent to enforce it on.
DEBUG: Rule at line 684 without any user agent to enforce it on.
DEBUG: Rule at line 685 without any user agent to enforce it on.
DEBUG: Rule at line 686 without any user agent to enforce it on.
DEBUG: Rule at line 693 without any user agent to enforce it on.
DEBUG: Rule at line 694 without any user agent to enforce it on.
DEBUG: Rule at line 698 without any user agent to enforce it on.
DEBUG: Rule at line 699 without any user agent to enforce it on.
DEBUG: Rule at line 700 without any user agent to enforce it on.
DEBUG: Rule at line 701 without any user agent to enforce it on.
DEBUG: Rule at line 702 without any user agent to enforce it on.
DEBUG: Rule at line 703 without any user agent to enforce it on.
DEBUG: Rule at line 705 without any user agent to enforce it on.
DEBUG: Rule at line 707 without any user agent to enforce it on.
DEBUG: Rule at line 747 without any user agent to enforce it on.
DEBUG: Rule at line 754 without any user agent to enforce it on.
DEBUG: Rule at line 755 without any user agent to enforce it on.
DEBUG: Rule at line 780 without any user agent to enforce it on.
DEBUG: Rule at line 787 without any user agent to enforce it on.
DEBUG: Rule at line 788 without any user agent to enforce it on.
DEBUG: Rule at line 818 without any user agent to enforce it on.
DEBUG: Rule at line 821 without any user agent to enforce it on.
DEBUG: Rule at line 828 without any user agent to enforce it on.
DEBUG: Rule at line 829 without any user agent to enforce it on.
DEBUG: Rule at line 834 without any user agent to enforce it on.
DEBUG: Rule at line 836 without any user agent to enforce it on.
DEBUG: Rule at line 839 without any user agent to enforce it on.
DEBUG: Rule at line 840 without any user agent to enforce it on.
DEBUG: Rule at line 841 without any user agent to enforce it on.
DEBUG: Rule at line 894 without any user agent to enforce it on.
DEBUG: Rule at line 895 without any user agent to enforce it on.
DEBUG: Rule at line 896 without any user agent to enforce it on.
DEBUG: Rule at line 897 without any user agent to enforce it on.
DEBUG: Rule at line 898 without any user agent to enforce it on.
DEBUG: Rule at line 900 without any user agent to enforce it on.
DEBUG: Rule at line 905 without any user agent to enforce it on.
DEBUG: Rule at line 906 without any user agent to enforce it on.
DEBUG: Rule at line 907 without any user agent to enforce it on.
DEBUG: Rule at line 908 without any user agent to enforce it on.
DEBUG: Rule at line 913 without any user agent to enforce it on.
DEBUG: Rule at line 932 without any user agent to enforce it on.
DEBUG: Rule at line 933 without any user agent to enforce it on.
DEBUG: Rule at line 944 without any user agent to enforce it on.
DEBUG: Rule at line 953 without any user agent to enforce it on.
DEBUG: Rule at line 956 without any user agent to enforce it on.
DEBUG: Rule at line 961 without any user agent to enforce it on.
DEBUG: Rule at line 970 without any user agent to enforce it on.
DEBUG: Rule at line 986 without any user agent to enforce it on.
DEBUG: Rule at line 987 without any user agent to enforce it on.
DEBUG: Rule at line 988 without any user agent to enforce it on.
DEBUG: Rule at line 989 without any user agent to enforce it on.
DEBUG: Rule at line 995 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/robots.txt> from <GET http://www.missioninn.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.missioninn.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/robots.txt> from <GET http://www.teahousespa.com/robots.txt>
DEBUG: Redirecting (301) to <GET http://harbin.org/robots.txt> from <GET http://www.harbin.org/robots.txt>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/> (referer: https://www.sweetwaterspa.com/)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': '',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://harbin.org/robots.txt> from <GET http://harbin.org/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/robots.txt> from <GET https://bardessono.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Crawled (200) <GET https://www.montagehotels.com/robots.txt> (referer: None)
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/robots.txt> from <GET https://doubleeagle.com/robots.txt>
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': ['info@wecarespa.com'],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': '',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://harbin.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/robots.txt> from <GET https://www.mysheerbliss.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/blogs> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Crawled (200) <GET https://mysheerbliss.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://harbin.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 1 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 2 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/robots.txt> from <GET http://www.senspa.com/robots.txt>
DEBUG: Crawled (200) <GET http://metropolissalonspa.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET http://metropolissalonspa.com/>
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://petitespa.net/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/contact> (referer: https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Crawled (200) <GET https://petitespa.net/> (referer: None)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Redirecting (301) to <GET https://oceanohalfmoonbay.com/robots.txt> from <GET http://www.oceanohalfmoonbay.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/robots.txt> from <GET https://sheer-bliss-organic-spa.myshopify.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Scraped from <200 https://www.romanspahotsprings.com/contact>
{'emails': ['Reservations75@Romanspahotsprings.com'],
 'facebook': 'https://www.facebook.com/romanspahotsprings',
 'instagram': 'https://www.instagram.com/romanspahotspringsresort/?ref=badge',
 'linkedin': '',
 'twitter': 'https://twitter.com/romansparesort'}
DEBUG: Crawled (404) <GET https://www.ventanabigsur.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://mysheerbliss.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/pages/contact-us-spa-policy> from <GET https://sheer-bliss-organic-spa.myshopify.com/pages/contact-us-spa-policy>
DEBUG: Redirecting (301) to <GET https://oceanohalfmoonbay.com/> from <GET http://www.oceanohalfmoonbay.com/>
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.rushcreeklodge.com/robots.txt> from <GET http://www.rushcreeklodge.com/robots.txt>
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/> (referer: None)
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.senspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb-listing&utm_content=brentwood> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Crawled (451) <GET https://www.morongocasinoresort.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
DEBUG: Rule at line 4 without any user agent to enforce it on.
DEBUG: Rule at line 6 without any user agent to enforce it on.
DEBUG: Rule at line 27 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 41 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 76 without any user agent to enforce it on.
DEBUG: Rule at line 77 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 82 without any user agent to enforce it on.
DEBUG: Rule at line 86 without any user agent to enforce it on.
DEBUG: Rule at line 89 without any user agent to enforce it on.
DEBUG: Rule at line 90 without any user agent to enforce it on.
DEBUG: Rule at line 91 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 93 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 102 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 109 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 114 without any user agent to enforce it on.
DEBUG: Rule at line 115 without any user agent to enforce it on.
DEBUG: Rule at line 116 without any user agent to enforce it on.
DEBUG: Rule at line 118 without any user agent to enforce it on.
DEBUG: Rule at line 119 without any user agent to enforce it on.
DEBUG: Rule at line 120 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 124 without any user agent to enforce it on.
DEBUG: Rule at line 125 without any user agent to enforce it on.
DEBUG: Rule at line 126 without any user agent to enforce it on.
DEBUG: Rule at line 127 without any user agent to enforce it on.
DEBUG: Rule at line 128 without any user agent to enforce it on.
DEBUG: Rule at line 131 without any user agent to enforce it on.
DEBUG: Rule at line 132 without any user agent to enforce it on.
DEBUG: Rule at line 133 without any user agent to enforce it on.
DEBUG: Rule at line 137 without any user agent to enforce it on.
DEBUG: Rule at line 140 without any user agent to enforce it on.
DEBUG: Rule at line 143 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 146 without any user agent to enforce it on.
DEBUG: Rule at line 147 without any user agent to enforce it on.
DEBUG: Rule at line 148 without any user agent to enforce it on.
DEBUG: Rule at line 150 without any user agent to enforce it on.
DEBUG: Rule at line 151 without any user agent to enforce it on.
DEBUG: Rule at line 154 without any user agent to enforce it on.
DEBUG: Rule at line 155 without any user agent to enforce it on.
DEBUG: Rule at line 156 without any user agent to enforce it on.
DEBUG: Rule at line 157 without any user agent to enforce it on.
DEBUG: Rule at line 160 without any user agent to enforce it on.
DEBUG: Rule at line 161 without any user agent to enforce it on.
DEBUG: Rule at line 164 without any user agent to enforce it on.
DEBUG: Rule at line 167 without any user agent to enforce it on.
DEBUG: Rule at line 170 without any user agent to enforce it on.
DEBUG: Rule at line 173 without any user agent to enforce it on.
DEBUG: Rule at line 174 without any user agent to enforce it on.
DEBUG: Rule at line 189 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://aquasoleilhotel.com/robots.txt> from <GET http://www.aquasoleilhotel.com/robots.txt>
DEBUG: Crawled (200) <GET https://paradisepoint.com/?utm_source=google-local&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Crawled (451) <GET https://www.morongocasinoresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/contact/> (referer: https://oceanohalfmoonbay.com/)
DEBUG: Crawled (200) <GET https://aquasoleilhotel.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://aquasoleilhotel.com/> from <GET http://www.aquasoleilhotel.com/>
INFO: Ignoring response <451 https://www.morongocasinoresort.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://aquasoleilhotel.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://oceanohalfmoonbay.com/contact/>
{'emails': ['admin@oceanohalfmoonbay.com'],
 'facebook': 'https://www.facebook.com/oceanohotelspa/',
 'instagram': 'https://www.instagram.com/oceanohotelspa/?ref=badge',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET http://www.thankyouandbewell.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET http://www.thankyouandbewell.com/>
DEBUG: Crawled (200) <GET https://aquasoleilhotel.com/> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 34, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 4042: character maps to <undefined>
DEBUG: Redirecting (301) to <GET https://www.thespaatfgv.com/robots.txt> from <GET http://www.thespaatfgv.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://aquasoleilhotel.com/contact/> (referer: https://aquasoleilhotel.com/)
DEBUG: Redirecting (301) to <GET https://www.miramonteresort.com/robots.txt> from <GET http://www.miramonteresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.rushcreeklodge.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.rushcreeklodge.com/> from <GET http://www.rushcreeklodge.com/>
DEBUG: Redirecting (301) to <GET https://thespaatfgv.com/robots.txt> from <GET https://www.thespaatfgv.com/robots.txt>
DEBUG: Crawled (200) <GET https://truerest.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ventanabigsur.com/spa/overview> (referer: None)
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.rushcreeklodge.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.miramonteresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Crawled (403) <GET https://truerest.com/locations/fresno/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.miramonteresort.com/spa> from <GET http://www.miramonteresort.com/spa>
INFO: Ignoring response <403 https://truerest.com/locations/fresno/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.rushcreeklodge.com/us/contact-us/> (referer: https://www.rushcreeklodge.com/)
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/contact/> (referer: https://www.macarthurplace.com/)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Scraped from <200 https://www.rushcreeklodge.com/us/contact-us/>
{'emails': ['info@rushcreeklodge.com.'],
 'facebook': 'https://www.facebook.com/RushCreekLodge/',
 'instagram': 'https://www.instagram.com/yosemite_rushcreek/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://www.miramonteresort.com/the-well-spa/> from <GET https://www.miramonteresort.com/spa>
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Crawled (200) <GET https://www.miramonteresort.com/the-well-spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://thespaatfgv.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.thespaatfgv.com/> from <GET http://www.thespaatfgv.com/>
DEBUG: Redirecting (301) to <GET https://thespaatfgv.com/> from <GET https://www.thespaatfgv.com/>
DEBUG: Crawled (200) <GET https://thespaatfgv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thespaatfgv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thespaatfgv.com/contact/> (referer: https://thespaatfgv.com/)
DEBUG: Scraped from <200 https://thespaatfgv.com/contact/>
{'emails': ['tammie@hungryhairsalon.com'],
 'facebook': 'https://www.facebook.com/SpaHungryHair/',
 'instagram': 'https://www.instagram.com/themedicalspa_hungryhair/',
 'linkedin': '',
 'twitter': ''}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 3,
 'downloader/request_bytes': 89280,
 'downloader/request_count': 319,
 'downloader/request_method_count/GET': 319,
 'downloader/response_bytes': 5954200,
 'downloader/response_count': 319,
 'downloader/response_status_count/200': 204,
 'downloader/response_status_count/301': 93,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 6,
 'downloader/response_status_count/429': 6,
 'downloader/response_status_count/451': 2,
 'downloader/response_status_count/502': 6,
 'dupefilter/filtered': 38,
 'elapsed_time_seconds': 20.067712,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 13, 31, 47, 67248),
 'httpcompression/response_bytes': 20733238,
 'httpcompression/response_count': 188,
 'httperror/response_ignored_count': 6,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'httperror/response_ignored_status_count/451': 1,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 11,
 'log_count/DEBUG': 704,
 'log_count/ERROR': 5,
 'log_count/INFO': 16,
 'request_depth_max': 1,
 'response_received_count': 218,
 'retry/count': 8,
 'retry/max_reached': 4,
 'retry/reason_count/429 Unknown Status': 4,
 'retry/reason_count/502 Bad Gateway': 4,
 'robotstxt/forbidden': 3,
 'robotstxt/request_count': 101,
 'robotstxt/response_count': 101,
 'robotstxt/response_status_count/200': 93,
 'robotstxt/response_status_count/404': 5,
 'robotstxt/response_status_count/429': 1,
 'robotstxt/response_status_count/451': 1,
 'robotstxt/response_status_count/502': 1,
 'scheduler/dequeued': 179,
 'scheduler/dequeued/memory': 179,
 'scheduler/enqueued': 179,
 'scheduler/enqueued/memory': 179,
 'start_time': datetime.datetime(2022, 12, 9, 13, 31, 26, 999536)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 6178c32ac67dc0aa
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://kellysspa.com/robots.txt> from <GET http://kellysspa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/robots.txt> from <GET http://www.cal-a-vie.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/robots.txt> from <GET https://kellysspa.com/robots.txt>
DEBUG: Attempting to acquire lock 1492690144368 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1492690144368 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1492690144368 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1492690144368 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.omnihotels.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/robots.txt> from <GET http://www.goldenhaven.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/robots.txt> from <GET http://www.glenivy.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://cadayspa.com/robots.txt> from <GET http://cadayspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.wispausa.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://www.kellysspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-location
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.madonnainn.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://cadayspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://www.osmosis.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://www.ritzcarlton.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
ERROR: Spider error processing <GET https://www.madonnainn.com/spa> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': ['cavinfo@cal-a-vie.com'],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': '',
 'twitter': 'https://twitter.com/calaviespa'}
ERROR: Spider error processing <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact/
ERROR: Spider error processing <GET https://www.goldenhaven.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.fourseasons.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://aubergeresorts.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 24 without any user agent to enforce it on.
DEBUG: Rule at line 25 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 41 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 68 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
ERROR: Spider error processing <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us/
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
ERROR: Spider error processing <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Redirecting (301) to <GET https://glenivy.com/robots.txt> from <GET https://www.glenivy.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
ERROR: Spider error processing <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Redirecting (301) to <GET http://boonhotels.com/robots.txt> from <GET http://www.boonhotels.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET http://boonhotels.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://the-spring.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
ERROR: Spider error processing <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /solage/contact-us/
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
ERROR: Spider error processing <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Retrying <GET https://www.hyatt.com/robots.txt> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
ERROR: Spider error processing <GET https://www.southcoastwinery.com/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/robots.txt> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://glenivy.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: #contacts
DEBUG: Crawled (200) <GET https://www.terranea.com/robots.txt> (referer: None)
ERROR: Gave up retrying <GET https://www.hyatt.com/robots.txt> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
ERROR: Spider error processing <GET https://www.urbanretreatspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
ERROR: Spider error processing <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/robots.txt> from <GET http://www.evo-spa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/robots.txt> from <GET http://www.sycamoresprings.com/robots.txt>
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://boonhotels.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
ERROR: Spider error processing <GET https://www.evo-spa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/robots.txt> from <GET http://www.ranchovalencia.com/robots.txt>
DEBUG: Crawled (200) <GET https://glenivy.com/robots.txt> (referer: None)
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Crawled (200) <GET https://www.constantcontact.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET https://www.constantcontact.com/legal/service-provider>
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/robots.txt> from <GET http://www.sweetwaterspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
ERROR: Spider error processing <GET https://www.sycamoresprings.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Crawled (200) <GET https://www.ranchovalencia.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': ['info@wispausa.com'],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': '',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/robots.txt> from <GET http://www.lapeauspafresno.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Redirecting (301) to <GET http://wecarespa.com/robots.txt> from <GET http://www.wecarespa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.canyonranch.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
ERROR: Spider error processing <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us/
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://glenivy.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-info/
DEBUG: Crawled (200) <GET http://wecarespa.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/robots.txt> from <GET http://www.lagunacanyonspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://sweetwaterspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.carnerosresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Filtered duplicate request: <GET https://ranchovalencia.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Crawled (404) <GET https://sweetwaterspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
ERROR: Spider error processing <GET https://www.lapeauspafresno.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
ERROR: Spider error processing <GET https://www.estanciadayspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://paradisepoint.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://lagunacanyonspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us
DEBUG: Crawled (200) <GET https://amenitiesspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://theravenspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://wecarespa.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET http://carnerosresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/robots.txt> from <GET http://www.beverlyhotsprings.com/robots.txt>
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Crawled (404) <GET https://www.ranchobernardoinn.com/robots.txt> (referer: None)
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 73 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Rule at line 83 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 141 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 146 without any user agent to enforce it on.
DEBUG: Rule at line 152 without any user agent to enforce it on.
DEBUG: Rule at line 173 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 260 without any user agent to enforce it on.
DEBUG: Rule at line 265 without any user agent to enforce it on.
DEBUG: Rule at line 268 without any user agent to enforce it on.
DEBUG: Rule at line 271 without any user agent to enforce it on.
DEBUG: Rule at line 274 without any user agent to enforce it on.
DEBUG: Rule at line 277 without any user agent to enforce it on.
DEBUG: Rule at line 280 without any user agent to enforce it on.
DEBUG: Rule at line 283 without any user agent to enforce it on.
DEBUG: Rule at line 288 without any user agent to enforce it on.
DEBUG: Rule at line 293 without any user agent to enforce it on.
DEBUG: Rule at line 296 without any user agent to enforce it on.
DEBUG: Rule at line 299 without any user agent to enforce it on.
DEBUG: Rule at line 302 without any user agent to enforce it on.
DEBUG: Rule at line 305 without any user agent to enforce it on.
DEBUG: Rule at line 308 without any user agent to enforce it on.
DEBUG: Rule at line 311 without any user agent to enforce it on.
DEBUG: Rule at line 314 without any user agent to enforce it on.
DEBUG: Rule at line 320 without any user agent to enforce it on.
DEBUG: Rule at line 325 without any user agent to enforce it on.
DEBUG: Rule at line 330 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 336 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 342 without any user agent to enforce it on.
DEBUG: Rule at line 345 without any user agent to enforce it on.
DEBUG: Rule at line 348 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 358 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 368 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 374 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 380 without any user agent to enforce it on.
DEBUG: Rule at line 385 without any user agent to enforce it on.
DEBUG: Rule at line 390 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 398 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 404 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 410 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 416 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 422 without any user agent to enforce it on.
DEBUG: Rule at line 425 without any user agent to enforce it on.
DEBUG: Rule at line 430 without any user agent to enforce it on.
DEBUG: Rule at line 435 without any user agent to enforce it on.
DEBUG: Rule at line 438 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 444 without any user agent to enforce it on.
DEBUG: Rule at line 450 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 458 without any user agent to enforce it on.
DEBUG: Rule at line 463 without any user agent to enforce it on.
DEBUG: Rule at line 466 without any user agent to enforce it on.
DEBUG: Rule at line 469 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 475 without any user agent to enforce it on.
DEBUG: Rule at line 478 without any user agent to enforce it on.
DEBUG: Rule at line 490 without any user agent to enforce it on.
DEBUG: Rule at line 491 without any user agent to enforce it on.
DEBUG: Rule at line 511 without any user agent to enforce it on.
DEBUG: Rule at line 543 without any user agent to enforce it on.
DEBUG: Rule at line 545 without any user agent to enforce it on.
DEBUG: Rule at line 550 without any user agent to enforce it on.
DEBUG: Rule at line 551 without any user agent to enforce it on.
DEBUG: Rule at line 552 without any user agent to enforce it on.
DEBUG: Rule at line 620 without any user agent to enforce it on.
DEBUG: Rule at line 627 without any user agent to enforce it on.
DEBUG: Rule at line 629 without any user agent to enforce it on.
DEBUG: Rule at line 633 without any user agent to enforce it on.
DEBUG: Rule at line 637 without any user agent to enforce it on.
DEBUG: Rule at line 641 without any user agent to enforce it on.
DEBUG: Rule at line 642 without any user agent to enforce it on.
DEBUG: Rule at line 643 without any user agent to enforce it on.
DEBUG: Rule at line 644 without any user agent to enforce it on.
DEBUG: Rule at line 658 without any user agent to enforce it on.
DEBUG: Rule at line 662 without any user agent to enforce it on.
DEBUG: Rule at line 663 without any user agent to enforce it on.
DEBUG: Rule at line 664 without any user agent to enforce it on.
DEBUG: Rule at line 665 without any user agent to enforce it on.
DEBUG: Rule at line 666 without any user agent to enforce it on.
DEBUG: Rule at line 684 without any user agent to enforce it on.
DEBUG: Rule at line 685 without any user agent to enforce it on.
DEBUG: Rule at line 686 without any user agent to enforce it on.
DEBUG: Rule at line 693 without any user agent to enforce it on.
DEBUG: Rule at line 694 without any user agent to enforce it on.
DEBUG: Rule at line 698 without any user agent to enforce it on.
DEBUG: Rule at line 699 without any user agent to enforce it on.
DEBUG: Rule at line 700 without any user agent to enforce it on.
DEBUG: Rule at line 701 without any user agent to enforce it on.
DEBUG: Rule at line 702 without any user agent to enforce it on.
DEBUG: Rule at line 703 without any user agent to enforce it on.
DEBUG: Rule at line 705 without any user agent to enforce it on.
DEBUG: Rule at line 707 without any user agent to enforce it on.
DEBUG: Rule at line 747 without any user agent to enforce it on.
DEBUG: Rule at line 754 without any user agent to enforce it on.
DEBUG: Rule at line 755 without any user agent to enforce it on.
DEBUG: Rule at line 780 without any user agent to enforce it on.
DEBUG: Rule at line 787 without any user agent to enforce it on.
DEBUG: Rule at line 788 without any user agent to enforce it on.
DEBUG: Rule at line 818 without any user agent to enforce it on.
DEBUG: Rule at line 821 without any user agent to enforce it on.
DEBUG: Rule at line 828 without any user agent to enforce it on.
DEBUG: Rule at line 829 without any user agent to enforce it on.
DEBUG: Rule at line 834 without any user agent to enforce it on.
DEBUG: Rule at line 836 without any user agent to enforce it on.
DEBUG: Rule at line 839 without any user agent to enforce it on.
DEBUG: Rule at line 840 without any user agent to enforce it on.
DEBUG: Rule at line 841 without any user agent to enforce it on.
DEBUG: Rule at line 894 without any user agent to enforce it on.
DEBUG: Rule at line 895 without any user agent to enforce it on.
DEBUG: Rule at line 896 without any user agent to enforce it on.
DEBUG: Rule at line 897 without any user agent to enforce it on.
DEBUG: Rule at line 898 without any user agent to enforce it on.
DEBUG: Rule at line 900 without any user agent to enforce it on.
DEBUG: Rule at line 905 without any user agent to enforce it on.
DEBUG: Rule at line 906 without any user agent to enforce it on.
DEBUG: Rule at line 907 without any user agent to enforce it on.
DEBUG: Rule at line 908 without any user agent to enforce it on.
DEBUG: Rule at line 913 without any user agent to enforce it on.
DEBUG: Rule at line 932 without any user agent to enforce it on.
DEBUG: Rule at line 933 without any user agent to enforce it on.
DEBUG: Rule at line 944 without any user agent to enforce it on.
DEBUG: Rule at line 953 without any user agent to enforce it on.
DEBUG: Rule at line 956 without any user agent to enforce it on.
DEBUG: Rule at line 961 without any user agent to enforce it on.
DEBUG: Rule at line 970 without any user agent to enforce it on.
DEBUG: Rule at line 986 without any user agent to enforce it on.
DEBUG: Rule at line 987 without any user agent to enforce it on.
DEBUG: Rule at line 988 without any user agent to enforce it on.
DEBUG: Rule at line 989 without any user agent to enforce it on.
DEBUG: Rule at line 995 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
ERROR: Spider error processing <GET https://www.laquintaresort.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /map-and-contact/
ERROR: Spider error processing <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us
ERROR: Spider error processing <GET https://amenitiesspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
ERROR: Spider error processing <GET https://theravenspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact/
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/robots.txt> from <GET http://www.thebluedoorhanford.com/robots.txt>
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Redirecting (301) to <GET http://harbin.org/robots.txt> from <GET http://www.harbin.org/robots.txt>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/robots.txt> from <GET http://www.trilogyspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
ERROR: Spider error processing <GET https://www.sweetwaterspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us/#sweetwater-location
ERROR: Spider error processing <GET https://carnerosresort.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
ERROR: Spider error processing <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://thehealingcornerca.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/robots.txt> from <GET http://www.teahousespa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.paseahotel.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/robots.txt> from <GET http://www.missioninn.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://harbin.org/robots.txt> from <GET http://harbin.org/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.missioninn.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
ERROR: Spider error processing <GET https://www.missioninn.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
ERROR: Spider error processing <GET https://www.thebluedoorhanford.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
ERROR: Spider error processing <GET https://www.thelandingtahoe.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.teahousespa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://harbin.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.montagehotels.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
ERROR: Spider error processing <GET https://www.trilogyspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/robots.txt> from <GET https://bardessono.com/robots.txt>
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/robots.txt> from <GET https://www.mysheerbliss.com/robots.txt>
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
ERROR: Spider error processing <GET https://www.teahousespa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-join-our-team
DEBUG: Crawled (200) <GET https://mysheerbliss.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': ['info@wecarespa.com'],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': '',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://harbin.org/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 1 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://www.bardessono.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 2 times): 502 Bad Gateway
ERROR: Spider error processing <GET https://mysheerbliss.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /pages/contact-us-spa-policy
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/robots.txt> from <GET http://doubleeagle.com/robots.txt>
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/contact> (referer: https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact/
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://petitespa.net/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/robots.txt> from <GET http://www.senspa.com/robots.txt>
DEBUG: Scraped from <200 https://www.romanspahotsprings.com/contact>
{'emails': ['Reservations75@Romanspahotsprings.com'],
 'facebook': 'https://www.facebook.com/romanspahotsprings',
 'instagram': 'https://www.instagram.com/romanspahotspringsresort/?ref=badge',
 'linkedin': '',
 'twitter': 'https://twitter.com/romansparesort'}
ERROR: Spider error processing <GET https://harbin.org/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us/
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://petitespa.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET http://metropolissalonspa.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET http://metropolissalonspa.com/>
DEBUG: Redirecting (301) to <GET https://oceanohalfmoonbay.com/robots.txt> from <GET http://www.oceanohalfmoonbay.com/robots.txt>
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': '',
 'linkedin': '',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
ERROR: Spider error processing <GET https://petitespa.net/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us-1
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
DEBUG: Crawled (404) <GET https://www.ventanabigsur.com/robots.txt> (referer: None)
DEBUG: Rule at line 20 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 54 without any user agent to enforce it on.
DEBUG: Rule at line 55 without any user agent to enforce it on.
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 34, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 4809: character maps to <undefined>
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://oceanohalfmoonbay.com/> from <GET http://www.oceanohalfmoonbay.com/>
DEBUG: Crawled (200) <GET https://www.senspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb-listing&utm_content=brentwood> (referer: None)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
ERROR: Spider error processing <GET https://milkandhoneyspa.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb-listing&utm_content=brentwood> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://paradisepoint.com/?utm_source=google-local&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (451) <GET https://www.morongocasinoresort.com/robots.txt> (referer: None)
DEBUG: Rule at line 3 without any user agent to enforce it on.
DEBUG: Rule at line 4 without any user agent to enforce it on.
DEBUG: Rule at line 6 without any user agent to enforce it on.
DEBUG: Rule at line 27 without any user agent to enforce it on.
DEBUG: Rule at line 28 without any user agent to enforce it on.
DEBUG: Rule at line 29 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 41 without any user agent to enforce it on.
DEBUG: Rule at line 43 without any user agent to enforce it on.
DEBUG: Rule at line 44 without any user agent to enforce it on.
DEBUG: Rule at line 45 without any user agent to enforce it on.
DEBUG: Rule at line 46 without any user agent to enforce it on.
DEBUG: Rule at line 49 without any user agent to enforce it on.
DEBUG: Rule at line 50 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 58 without any user agent to enforce it on.
DEBUG: Rule at line 64 without any user agent to enforce it on.
DEBUG: Rule at line 69 without any user agent to enforce it on.
DEBUG: Rule at line 70 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 72 without any user agent to enforce it on.
DEBUG: Rule at line 76 without any user agent to enforce it on.
DEBUG: Rule at line 77 without any user agent to enforce it on.
DEBUG: Rule at line 78 without any user agent to enforce it on.
DEBUG: Rule at line 79 without any user agent to enforce it on.
DEBUG: Rule at line 82 without any user agent to enforce it on.
DEBUG: Rule at line 86 without any user agent to enforce it on.
DEBUG: Rule at line 89 without any user agent to enforce it on.
DEBUG: Rule at line 90 without any user agent to enforce it on.
DEBUG: Rule at line 91 without any user agent to enforce it on.
DEBUG: Rule at line 92 without any user agent to enforce it on.
DEBUG: Rule at line 93 without any user agent to enforce it on.
DEBUG: Rule at line 94 without any user agent to enforce it on.
DEBUG: Rule at line 98 without any user agent to enforce it on.
DEBUG: Rule at line 102 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 108 without any user agent to enforce it on.
DEBUG: Rule at line 109 without any user agent to enforce it on.
DEBUG: Rule at line 110 without any user agent to enforce it on.
DEBUG: Rule at line 114 without any user agent to enforce it on.
DEBUG: Rule at line 115 without any user agent to enforce it on.
DEBUG: Rule at line 116 without any user agent to enforce it on.
DEBUG: Rule at line 118 without any user agent to enforce it on.
DEBUG: Rule at line 119 without any user agent to enforce it on.
DEBUG: Rule at line 120 without any user agent to enforce it on.
DEBUG: Rule at line 121 without any user agent to enforce it on.
DEBUG: Rule at line 122 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 124 without any user agent to enforce it on.
DEBUG: Rule at line 125 without any user agent to enforce it on.
DEBUG: Rule at line 126 without any user agent to enforce it on.
DEBUG: Rule at line 127 without any user agent to enforce it on.
DEBUG: Rule at line 128 without any user agent to enforce it on.
DEBUG: Rule at line 131 without any user agent to enforce it on.
DEBUG: Rule at line 132 without any user agent to enforce it on.
DEBUG: Rule at line 133 without any user agent to enforce it on.
DEBUG: Rule at line 137 without any user agent to enforce it on.
DEBUG: Rule at line 140 without any user agent to enforce it on.
DEBUG: Rule at line 143 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 146 without any user agent to enforce it on.
DEBUG: Rule at line 147 without any user agent to enforce it on.
DEBUG: Rule at line 148 without any user agent to enforce it on.
DEBUG: Rule at line 150 without any user agent to enforce it on.
DEBUG: Rule at line 151 without any user agent to enforce it on.
DEBUG: Rule at line 154 without any user agent to enforce it on.
DEBUG: Rule at line 155 without any user agent to enforce it on.
DEBUG: Rule at line 156 without any user agent to enforce it on.
DEBUG: Rule at line 157 without any user agent to enforce it on.
DEBUG: Rule at line 160 without any user agent to enforce it on.
DEBUG: Rule at line 161 without any user agent to enforce it on.
DEBUG: Rule at line 164 without any user agent to enforce it on.
DEBUG: Rule at line 167 without any user agent to enforce it on.
DEBUG: Rule at line 170 without any user agent to enforce it on.
DEBUG: Rule at line 173 without any user agent to enforce it on.
DEBUG: Rule at line 174 without any user agent to enforce it on.
DEBUG: Rule at line 189 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/contact/> (referer: https://oceanohalfmoonbay.com/)
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Scraped from <200 https://oceanohalfmoonbay.com/contact/>
{'emails': ['admin@oceanohalfmoonbay.com'],
 'facebook': 'https://www.facebook.com/oceanohotelspa/',
 'instagram': 'https://www.instagram.com/oceanohotelspa/?ref=badge',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (451) <GET https://www.morongocasinoresort.com/> (referer: None)
ERROR: Spider error processing <GET https://www.senspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/robots.txt> (referer: None)
INFO: Ignoring response <451 https://www.morongocasinoresort.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/robots.txt> from <GET https://doubleeagle.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.ventanabigsur.com/spa/overview> (referer: None)
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/> (referer: None)
ERROR: Spider error processing <GET https://www.ventanabigsur.com/spa/overview> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/contact/> (referer: https://www.macarthurplace.com/)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
ERROR: Spider error processing <GET https://www.doubleeagle.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 2,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 2,
 'downloader/request_bytes': 76073,
 'downloader/request_count': 273,
 'downloader/request_method_count/GET': 273,
 'downloader/response_bytes': 5363409,
 'downloader/response_count': 273,
 'downloader/response_status_count/200': 175,
 'downloader/response_status_count/301': 77,
 'downloader/response_status_count/403': 1,
 'downloader/response_status_count/404': 6,
 'downloader/response_status_count/429': 6,
 'downloader/response_status_count/451': 2,
 'downloader/response_status_count/502': 6,
 'dupefilter/filtered': 5,
 'elapsed_time_seconds': 23.360665,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 13, 46, 21, 193821),
 'httpcompression/response_bytes': 18624103,
 'httpcompression/response_count': 161,
 'httperror/response_ignored_count': 5,
 'httperror/response_ignored_status_count/403': 1,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'httperror/response_ignored_status_count/451': 1,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 6,
 'log_count/DEBUG': 560,
 'log_count/ERROR': 48,
 'log_count/INFO': 15,
 'request_depth_max': 1,
 'response_received_count': 188,
 'retry/count': 8,
 'retry/max_reached': 4,
 'retry/reason_count/429 Unknown Status': 4,
 'retry/reason_count/502 Bad Gateway': 4,
 'robotstxt/forbidden': 2,
 'robotstxt/request_count': 90,
 'robotstxt/response_count': 90,
 'robotstxt/response_status_count/200': 82,
 'robotstxt/response_status_count/404': 5,
 'robotstxt/response_status_count/429': 1,
 'robotstxt/response_status_count/451': 1,
 'robotstxt/response_status_count/502': 1,
 'scheduler/dequeued': 150,
 'scheduler/dequeued/memory': 150,
 'scheduler/enqueued': 150,
 'scheduler/enqueued/memory': 150,
 'spider_exceptions/ValueError': 43,
 'start_time': datetime.datetime(2022, 12, 9, 13, 45, 57, 833156)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 3ddea8ba8deb4036
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://kellysspa.com/robots.txt> from <GET http://kellysspa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/robots.txt> from <GET http://www.cal-a-vie.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/robots.txt> from <GET https://kellysspa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/robots.txt> from <GET http://www.goldenhaven.com/robots.txt>
DEBUG: Attempting to acquire lock 1830220843472 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1830220843472 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1830220843472 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1830220843472 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.omnihotels.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/robots.txt> from <GET http://www.glenivy.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Crawled (200) <GET https://goldendoor.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://cadayspa.com/robots.txt> from <GET http://cadayspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
ERROR: Spider error processing <GET https://www.kellysspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-location
DEBUG: Crawled (200) <GET http://www.wispausa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
ERROR: Spider error processing <GET https://cadayspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us
DEBUG: Crawled (404) <GET https://www.ritzcarlton.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://www.madonnainn.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Crawled (200) <GET https://www.osmosis.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/robots.txt>
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': ['shop@goldendoor.com',
            'reservations@goldendoor.com',
            'molly@thestoriedgroup.com',
            'guestservices@goldendoor.com.',
            'guestservices@goldendoor.com'],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': '',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://aubergeresorts.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
ERROR: Spider error processing <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
ERROR: Spider error processing <GET https://www.madonnainn.com/spa> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.fourseasons.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 22 without any user agent to enforce it on.
DEBUG: Rule at line 23 without any user agent to enforce it on.
DEBUG: Rule at line 24 without any user agent to enforce it on.
DEBUG: Rule at line 25 without any user agent to enforce it on.
DEBUG: Rule at line 26 without any user agent to enforce it on.
DEBUG: Rule at line 30 without any user agent to enforce it on.
DEBUG: Rule at line 31 without any user agent to enforce it on.
DEBUG: Rule at line 32 without any user agent to enforce it on.
DEBUG: Rule at line 35 without any user agent to enforce it on.
DEBUG: Rule at line 36 without any user agent to enforce it on.
DEBUG: Rule at line 38 without any user agent to enforce it on.
DEBUG: Rule at line 40 without any user agent to enforce it on.
DEBUG: Rule at line 41 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 68 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': ['cavinfo@cal-a-vie.com'],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': '',
 'twitter': 'https://twitter.com/calaviespa'}
ERROR: Spider error processing <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact/
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
ERROR: Spider error processing <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us/
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': '',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
ERROR: Spider error processing <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://glenivy.com/robots.txt> from <GET https://www.glenivy.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://www.goldenhaven.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
ERROR: Spider error processing <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Redirecting (301) to <GET http://boonhotels.com/robots.txt> from <GET http://www.boonhotels.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET http://boonhotels.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['rhiannon@purpleorchid.com',
            'events@purpleorchid.com',
            'info@purpleorchid.com',
            'spa@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
ERROR: Spider error processing <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /solage/contact-us/
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://the-spring.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Retrying <GET https://www.hyatt.com/robots.txt> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://glenivy.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Retrying <GET https://www.hyatt.com/robots.txt> (failed 2 times): 429 Unknown Status
DEBUG: Scraped from <200 https://montereyplazahotel.com/hotel/contact>
{'emails': ['sales@montereyplazahotel.com',
            'coastalcurator@montereyplazahotel.com',
            'forms@tambourine.com',
            'reservations@montereyplazahotel.com',
            'weddings@montereyplazahotel.com',
            'housekeeping@montereyplazahotel.com'],
 'facebook': 'https://www.facebook.com/montereyplazahotel',
 'instagram': 'https://www.instagram.com/montereyplaza/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['golf@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'resv@silveradoresort.com',
            'sales@silveradoresort.com',
            'spa@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'tennis@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'info@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
ERROR: Gave up retrying <GET https://www.hyatt.com/robots.txt> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
ERROR: Spider error processing <GET https://www.southcoastwinery.com/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
ERROR: Spider error processing <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: #contacts
DEBUG: Crawled (200) <GET https://www.terranea.com/robots.txt> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://boonhotels.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/robots.txt> from <GET http://www.evo-spa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
ERROR: Spider error processing <GET https://www.urbanretreatspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
ERROR: Spider error processing <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/robots.txt> from <GET http://www.sycamoresprings.com/robots.txt>
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['spareservations@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'groupevents@ranchovalencia.com',
            'villas@ranchovalencia.com',
            'donations@ranchovalencia.com',
            'tennis@ranchovalencia.com',
            'concierge@ranchovalencia.com',
            'reservations@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': '',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET https://thesisleyspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Crawled (200) <GET https://glenivy.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/robots.txt> from <GET http://www.sweetwaterspa.com/robots.txt>
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://boonhotels.com/contact/>
{'emails': ['events@boonbrand.com', 'info@boonhotels.com'],
 'facebook': 'http://www.facebook.com/boonhotelspa',
 'instagram': 'https://www.instagram.com/boonhotelspa/',
 'linkedin': '',
 'twitter': 'https://twitter.com/boonhotelspa'}
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/robots.txt> from <GET http://www.ranchovalencia.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://www.sycamoresprings.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
ERROR: Spider error processing <GET https://www.evo-spa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Scraped from <200 https://thesisleyspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SisleySpaUSA/',
 'instagram': 'https://www.instagram.com/sisleyspausa/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.ranchovalencia.com/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://sweetwaterspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/robots.txt> from <GET http://www.lapeauspafresno.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Redirecting (301) to <GET http://wecarespa.com/robots.txt> from <GET http://www.wecarespa.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (404) <GET https://sweetwaterspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
ERROR: Spider error processing <GET https://glenivy.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-info/
ERROR: Error downloading <GET https:///robots.txt>: Empty domain
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\defer.py", line 1693, in _inlineCallbacks
    result = context.run(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\python\failure.py", line 518, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 72, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 75, in download_request
    return handler.download_request(request, spider)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 65, in download_request
    return agent.download_request(request)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 340, in download_request
    d = agent.request(method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\web\client.py", line 1148, in request
    endpoint = self._getEndpoint(parsedURI)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\web\client.py", line 1132, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\web\client.py", line 1003, in endpointForURI
    connectionCreator = self._policyForHTTPS.creatorForNetloc(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\contextfactory.py", line 67, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext(),
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\tls.py", line 40, in __init__
    super().__init__(hostname, ctx)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\_sslverify.py", line 1124, in __init__
    self._hostnameBytes = _idnaBytes(hostname)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\_idna.py", line 31, in _idnaBytes
    return idna.encode(text)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\idna\core.py", line 355, in encode
    raise IDNAError('Empty domain')
idna.core.IDNAError: Empty domain
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': ['info@wispausa.com'],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': '',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Crawled (200) <GET https://www.canyonranch.com/robots.txt> (referer: None)
DEBUG: Filtered duplicate request: <GET http://www.ranchovalencia.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Crawled (200) <GET http://wecarespa.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
ERROR: Error downloading <GET https:///om/ranchovalencia/>
idna.core.IDNAError: Empty domain

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\defer.py", line 1693, in _inlineCallbacks
    result = context.run(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\python\failure.py", line 518, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 72, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 75, in download_request
    return handler.download_request(request, spider)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 65, in download_request
    return agent.download_request(request)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 340, in download_request
    d = agent.request(method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\web\client.py", line 1148, in request
    endpoint = self._getEndpoint(parsedURI)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\web\client.py", line 1132, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\web\client.py", line 1003, in endpointForURI
    connectionCreator = self._policyForHTTPS.creatorForNetloc(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\contextfactory.py", line 67, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext(),
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\tls.py", line 40, in __init__
    super().__init__(hostname, ctx)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\_sslverify.py", line 1124, in __init__
    self._hostnameBytes = _idnaBytes(hostname)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\_idna.py", line 31, in _idnaBytes
    return idna.encode(text)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\idna\core.py", line 355, in encode
    raise IDNAError('Empty domain')
idna.core.IDNAError: Empty domain
DEBUG: Crawled (200) <GET https://www.constantcontact.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET https://www.constantcontact.com/legal/service-provider>
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/robots.txt> from <GET http://www.beverlyhotsprings.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/robots.txt> from <GET http://www.lagunacanyonspa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
ERROR: Spider error processing <GET https://www.lapeauspafresno.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
DEBUG: Crawled (200) <GET http://www.carnerosresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us/
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
ERROR: Spider error processing <GET https://www.laquintaresort.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /map-and-contact/
DEBUG: Crawled (200) <GET https://amenitiesspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
ERROR: Spider error processing <GET https://lagunacanyonspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us
DEBUG: Crawled (200) <GET https://paradisepoint.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://www.estanciadayspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Crawled (200) <GET https://theravenspa.com/robots.txt> (referer: None)
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Crawled (200) <GET https://wecarespa.com/robots.txt> (referer: None)
DEBUG: Rule at line 1 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Crawled (200) <GET http://carnerosresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/robots.txt> from <GET http://www.trilogyspa.com/robots.txt>
DEBUG: Crawled (404) <GET https://www.ranchobernardoinn.com/robots.txt> (referer: None)
DEBUG: Rule at line 14 without any user agent to enforce it on.
DEBUG: Rule at line 15 without any user agent to enforce it on.
DEBUG: Rule at line 56 without any user agent to enforce it on.
DEBUG: Rule at line 57 without any user agent to enforce it on.
DEBUG: Rule at line 61 without any user agent to enforce it on.
DEBUG: Rule at line 62 without any user agent to enforce it on.
DEBUG: Rule at line 63 without any user agent to enforce it on.
DEBUG: Rule at line 67 without any user agent to enforce it on.
DEBUG: Rule at line 71 without any user agent to enforce it on.
DEBUG: Rule at line 73 without any user agent to enforce it on.
DEBUG: Rule at line 74 without any user agent to enforce it on.
DEBUG: Rule at line 83 without any user agent to enforce it on.
DEBUG: Rule at line 88 without any user agent to enforce it on.
DEBUG: Rule at line 101 without any user agent to enforce it on.
DEBUG: Rule at line 103 without any user agent to enforce it on.
DEBUG: Rule at line 104 without any user agent to enforce it on.
DEBUG: Rule at line 123 without any user agent to enforce it on.
DEBUG: Rule at line 141 without any user agent to enforce it on.
DEBUG: Rule at line 144 without any user agent to enforce it on.
DEBUG: Rule at line 145 without any user agent to enforce it on.
DEBUG: Rule at line 146 without any user agent to enforce it on.
DEBUG: Rule at line 152 without any user agent to enforce it on.
DEBUG: Rule at line 173 without any user agent to enforce it on.
DEBUG: Rule at line 241 without any user agent to enforce it on.
DEBUG: Rule at line 242 without any user agent to enforce it on.
DEBUG: Rule at line 249 without any user agent to enforce it on.
DEBUG: Rule at line 260 without any user agent to enforce it on.
DEBUG: Rule at line 265 without any user agent to enforce it on.
DEBUG: Rule at line 268 without any user agent to enforce it on.
DEBUG: Rule at line 271 without any user agent to enforce it on.
DEBUG: Rule at line 274 without any user agent to enforce it on.
DEBUG: Rule at line 277 without any user agent to enforce it on.
DEBUG: Rule at line 280 without any user agent to enforce it on.
DEBUG: Rule at line 283 without any user agent to enforce it on.
DEBUG: Rule at line 288 without any user agent to enforce it on.
DEBUG: Rule at line 293 without any user agent to enforce it on.
DEBUG: Rule at line 296 without any user agent to enforce it on.
DEBUG: Rule at line 299 without any user agent to enforce it on.
DEBUG: Rule at line 302 without any user agent to enforce it on.
DEBUG: Rule at line 305 without any user agent to enforce it on.
DEBUG: Rule at line 308 without any user agent to enforce it on.
DEBUG: Rule at line 311 without any user agent to enforce it on.
DEBUG: Rule at line 314 without any user agent to enforce it on.
DEBUG: Rule at line 320 without any user agent to enforce it on.
DEBUG: Rule at line 325 without any user agent to enforce it on.
DEBUG: Rule at line 330 without any user agent to enforce it on.
DEBUG: Rule at line 333 without any user agent to enforce it on.
DEBUG: Rule at line 336 without any user agent to enforce it on.
DEBUG: Rule at line 339 without any user agent to enforce it on.
DEBUG: Rule at line 342 without any user agent to enforce it on.
DEBUG: Rule at line 345 without any user agent to enforce it on.
DEBUG: Rule at line 348 without any user agent to enforce it on.
DEBUG: Rule at line 353 without any user agent to enforce it on.
DEBUG: Rule at line 358 without any user agent to enforce it on.
DEBUG: Rule at line 365 without any user agent to enforce it on.
DEBUG: Rule at line 368 without any user agent to enforce it on.
DEBUG: Rule at line 371 without any user agent to enforce it on.
DEBUG: Rule at line 374 without any user agent to enforce it on.
DEBUG: Rule at line 377 without any user agent to enforce it on.
DEBUG: Rule at line 380 without any user agent to enforce it on.
DEBUG: Rule at line 385 without any user agent to enforce it on.
DEBUG: Rule at line 390 without any user agent to enforce it on.
DEBUG: Rule at line 395 without any user agent to enforce it on.
DEBUG: Rule at line 398 without any user agent to enforce it on.
DEBUG: Rule at line 401 without any user agent to enforce it on.
DEBUG: Rule at line 404 without any user agent to enforce it on.
DEBUG: Rule at line 407 without any user agent to enforce it on.
DEBUG: Rule at line 410 without any user agent to enforce it on.
DEBUG: Rule at line 413 without any user agent to enforce it on.
DEBUG: Rule at line 416 without any user agent to enforce it on.
DEBUG: Rule at line 419 without any user agent to enforce it on.
DEBUG: Rule at line 422 without any user agent to enforce it on.
DEBUG: Rule at line 425 without any user agent to enforce it on.
DEBUG: Rule at line 430 without any user agent to enforce it on.
DEBUG: Rule at line 435 without any user agent to enforce it on.
DEBUG: Rule at line 438 without any user agent to enforce it on.
DEBUG: Rule at line 441 without any user agent to enforce it on.
DEBUG: Rule at line 444 without any user agent to enforce it on.
DEBUG: Rule at line 450 without any user agent to enforce it on.
DEBUG: Rule at line 453 without any user agent to enforce it on.
DEBUG: Rule at line 458 without any user agent to enforce it on.
DEBUG: Rule at line 463 without any user agent to enforce it on.
DEBUG: Rule at line 466 without any user agent to enforce it on.
DEBUG: Rule at line 469 without any user agent to enforce it on.
DEBUG: Rule at line 472 without any user agent to enforce it on.
DEBUG: Rule at line 475 without any user agent to enforce it on.
DEBUG: Rule at line 478 without any user agent to enforce it on.
DEBUG: Rule at line 490 without any user agent to enforce it on.
DEBUG: Rule at line 491 without any user agent to enforce it on.
DEBUG: Rule at line 511 without any user agent to enforce it on.
DEBUG: Rule at line 543 without any user agent to enforce it on.
DEBUG: Rule at line 545 without any user agent to enforce it on.
DEBUG: Rule at line 550 without any user agent to enforce it on.
DEBUG: Rule at line 551 without any user agent to enforce it on.
DEBUG: Rule at line 552 without any user agent to enforce it on.
DEBUG: Rule at line 620 without any user agent to enforce it on.
DEBUG: Rule at line 627 without any user agent to enforce it on.
DEBUG: Rule at line 629 without any user agent to enforce it on.
DEBUG: Rule at line 633 without any user agent to enforce it on.
DEBUG: Rule at line 637 without any user agent to enforce it on.
DEBUG: Rule at line 641 without any user agent to enforce it on.
DEBUG: Rule at line 642 without any user agent to enforce it on.
DEBUG: Rule at line 643 without any user agent to enforce it on.
DEBUG: Rule at line 644 without any user agent to enforce it on.
DEBUG: Rule at line 658 without any user agent to enforce it on.
DEBUG: Rule at line 662 without any user agent to enforce it on.
DEBUG: Rule at line 663 without any user agent to enforce it on.
DEBUG: Rule at line 664 without any user agent to enforce it on.
DEBUG: Rule at line 665 without any user agent to enforce it on.
DEBUG: Rule at line 666 without any user agent to enforce it on.
DEBUG: Rule at line 684 without any user agent to enforce it on.
DEBUG: Rule at line 685 without any user agent to enforce it on.
DEBUG: Rule at line 686 without any user agent to enforce it on.
DEBUG: Rule at line 693 without any user agent to enforce it on.
DEBUG: Rule at line 694 without any user agent to enforce it on.
DEBUG: Rule at line 698 without any user agent to enforce it on.
DEBUG: Rule at line 699 without any user agent to enforce it on.
DEBUG: Rule at line 700 without any user agent to enforce it on.
DEBUG: Rule at line 701 without any user agent to enforce it on.
DEBUG: Rule at line 702 without any user agent to enforce it on.
DEBUG: Rule at line 703 without any user agent to enforce it on.
DEBUG: Rule at line 705 without any user agent to enforce it on.
DEBUG: Rule at line 707 without any user agent to enforce it on.
DEBUG: Rule at line 747 without any user agent to enforce it on.
DEBUG: Rule at line 754 without any user agent to enforce it on.
DEBUG: Rule at line 755 without any user agent to enforce it on.
DEBUG: Rule at line 780 without any user agent to enforce it on.
DEBUG: Rule at line 787 without any user agent to enforce it on.
DEBUG: Rule at line 788 without any user agent to enforce it on.
DEBUG: Rule at line 818 without any user agent to enforce it on.
DEBUG: Rule at line 821 without any user agent to enforce it on.
DEBUG: Rule at line 828 without any user agent to enforce it on.
DEBUG: Rule at line 829 without any user agent to enforce it on.
DEBUG: Rule at line 834 without any user agent to enforce it on.
DEBUG: Rule at line 836 without any user agent to enforce it on.
DEBUG: Rule at line 839 without any user agent to enforce it on.
DEBUG: Rule at line 840 without any user agent to enforce it on.
DEBUG: Rule at line 841 without any user agent to enforce it on.
DEBUG: Rule at line 894 without any user agent to enforce it on.
DEBUG: Rule at line 895 without any user agent to enforce it on.
DEBUG: Rule at line 896 without any user agent to enforce it on.
DEBUG: Rule at line 897 without any user agent to enforce it on.
DEBUG: Rule at line 898 without any user agent to enforce it on.
DEBUG: Rule at line 900 without any user agent to enforce it on.
DEBUG: Rule at line 905 without any user agent to enforce it on.
DEBUG: Rule at line 906 without any user agent to enforce it on.
DEBUG: Rule at line 907 without any user agent to enforce it on.
DEBUG: Rule at line 908 without any user agent to enforce it on.
DEBUG: Rule at line 913 without any user agent to enforce it on.
DEBUG: Rule at line 932 without any user agent to enforce it on.
DEBUG: Rule at line 933 without any user agent to enforce it on.
DEBUG: Rule at line 944 without any user agent to enforce it on.
DEBUG: Rule at line 953 without any user agent to enforce it on.
DEBUG: Rule at line 956 without any user agent to enforce it on.
DEBUG: Rule at line 961 without any user agent to enforce it on.
DEBUG: Rule at line 970 without any user agent to enforce it on.
DEBUG: Rule at line 986 without any user agent to enforce it on.
DEBUG: Rule at line 987 without any user agent to enforce it on.
DEBUG: Rule at line 988 without any user agent to enforce it on.
DEBUG: Rule at line 989 without any user agent to enforce it on.
DEBUG: Rule at line 995 without any user agent to enforce it on.
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.indianspringscalistoga.com/contact-us>
{'emails': ['reservations@indianspringscalistoga.com',
            'forms@tambourine.com',
            'inquiries@indianspringscalistoga.com'],
 'facebook': 'https://www.facebook.com/ISRNAPA/',
 'instagram': 'https://www.instagram.com/indianspringscalistoga/',
 'linkedin': '',
 'twitter': ''}
ERROR: Spider error processing <GET https://amenitiesspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
ERROR: Spider error processing <GET https://theravenspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact/
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/robots.txt> from <GET http://www.thebluedoorhanford.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Scraped from <200 https://carmelvalleyranch.com/contact/>
{'emails': ['spa@carmelvalleyranch.com',
            'activities@carmelvalleyranch.com',
            'cvrclubhouse@carmelvalleyranch.com',
            'guestservices@carmelvalleyranch.com',
            'cvrevents@carmelvalleyranch.com',
            'cvrriverranch@carmelvalleyranch.com',
            'tennis@carmelvalleyranch.com',
            'cvrreservations@carmelvalleyranch.com',
            'cvrwedding@carmelvalleyranch.com',
            'cvrvalleykitchen@carmelvalleyranch.com',
            'cvrmembership@carmelvalleyranch.com',
            'cvrgolf@carmelvalleyranch.com'],
 'facebook': 'https://www.facebook.com/carmelvalleyranch/',
 'instagram': 'https://www.instagram.com/carmelvranch',
 'linkedin': '',
 'twitter': ''}
DEBUG: Redirecting (301) to <GET http://harbin.org/robots.txt> from <GET http://www.harbin.org/robots.txt>
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['sales@paradisepoint.com',
            'reservations@paradisepoint.com',
            'marketing@paradisepoint.com',
            'weddings@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
ERROR: Spider error processing <GET https://thehealingcornerca.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
ERROR: Spider error processing <GET https://www.sweetwaterspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us/#sweetwater-location
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/robots.txt> from <GET http://doubleeagle.com/robots.txt>
ERROR: Spider error processing <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us
ERROR: Spider error processing <GET https://carnerosresort.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/robots.txt> from <GET http://www.teahousespa.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/robots.txt> from <GET http://www.missioninn.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.paseahotel.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://www.trilogyspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.missioninn.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://harbin.org/robots.txt> from <GET http://harbin.org/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
ERROR: Spider error processing <GET https://www.missioninn.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
ERROR: Spider error processing <GET https://www.thelandingtahoe.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
ERROR: Spider error processing <GET https://www.thebluedoorhanford.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': '',
 'linkedin': '',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Crawled (200) <GET https://www.montagehotels.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/robots.txt> from <GET https://bardessono.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/robots.txt> from <GET https://www.mysheerbliss.com/robots.txt>
ERROR: Spider error processing <GET https://www.teahousespa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-join-our-team
DEBUG: Crawled (200) <GET https://harbin.org/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': ['info@wecarespa.com'],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': '',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Crawled (200) <GET https://mysheerbliss.com/robots.txt> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 34, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 7551: character maps to <undefined>
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/robots.txt> from <GET https://doubleeagle.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 1 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/contact> (referer: https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Scraped from <200 https://www.paseahotel.com/contact/press-room>
{'emails': ['forms@tambourine.com',
            'marketing@paseahotel.com',
            'frontdesk@paseahotel.com'],
 'facebook': 'https://www.facebook.com/PaseaHotel/',
 'instagram': 'https://www.instagram.com/paseahotel/',
 'linkedin': '',
 'twitter': ''}
DEBUG: Crawled (200) <GET https://harbin.org/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://mysheerbliss.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /pages/contact-us-spa-policy
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 2 times): 502 Bad Gateway
DEBUG: Redirecting (301) to <GET https://www.senspa.com/robots.txt> from <GET http://www.senspa.com/robots.txt>
DEBUG: Scraped from <200 https://www.romanspahotsprings.com/contact>
{'emails': ['Reservations75@Romanspahotsprings.com'],
 'facebook': 'https://www.facebook.com/romanspahotsprings',
 'instagram': 'https://www.instagram.com/romanspahotspringsresort/?ref=badge',
 'linkedin': '',
 'twitter': 'https://twitter.com/romansparesort'}
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/robots.txt> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/robots.txt> (referer: None)
ERROR: Spider error processing <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact/
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
ERROR: Spider error processing <GET https://harbin.org/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact-us/
DEBUG: Crawled (200) <GET https://www.senspa.com/robots.txt> (referer: None)
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': ['catering@miraclesprings.com',
            'spa@miraclesprings.com',
            'events@miraclesprings.com',
            'reservations@miraclesprings.com'],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': '',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Crawled (200) <GET https://www.bardessono.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
ERROR: Spider error processing <GET https://www.senspa.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Scraped from <200 https://www.bardessono.com/contact.htm>
{'emails': [],
 'facebook': 'https://www.facebook.com/bardessonohotelspa/',
 'instagram': 'https://www.instagram.com/bardessonoyountville/',
 'linkedin': '',
 'twitter': 'https://twitter.com/BardessonoHotel'}
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Scraped from <200 http://www.athenaspa-mv.com/contact-us>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
ERROR: Spider error processing <GET https://www.doubleeagle.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/idna.core.IDNAError': 2,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 1,
 'downloader/request_bytes': 71923,
 'downloader/request_count': 256,
 'downloader/request_method_count/GET': 256,
 'downloader/response_bytes': 5010009,
 'downloader/response_count': 254,
 'downloader/response_status_count/200': 161,
 'downloader/response_status_count/301': 75,
 'downloader/response_status_count/403': 1,
 'downloader/response_status_count/404': 5,
 'downloader/response_status_count/429': 6,
 'downloader/response_status_count/502': 6,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 20.607473,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 13, 51, 7, 191067),
 'httpcompression/response_bytes': 16550516,
 'httpcompression/response_count': 147,
 'httperror/response_ignored_count': 4,
 'httperror/response_ignored_status_count/403': 1,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 21,
 'log_count/DEBUG': 467,
 'log_count/ERROR': 47,
 'log_count/INFO': 14,
 'request_depth_max': 1,
 'response_received_count': 171,
 'retry/count': 8,
 'retry/max_reached': 4,
 'retry/reason_count/429 Unknown Status': 4,
 'retry/reason_count/502 Bad Gateway': 4,
 "robotstxt/exception_count/<class 'idna.core.IDNAError'>": 1,
 'robotstxt/forbidden': 1,
 'robotstxt/request_count': 83,
 'robotstxt/response_count': 82,
 'robotstxt/response_status_count/200': 76,
 'robotstxt/response_status_count/404': 4,
 'robotstxt/response_status_count/429': 1,
 'robotstxt/response_status_count/502': 1,
 'scheduler/dequeued': 140,
 'scheduler/dequeued/memory': 140,
 'scheduler/enqueued': 140,
 'scheduler/enqueued/memory': 140,
 'spider_exceptions/ValueError': 40,
 'start_time': datetime.datetime(2022, 12, 9, 13, 50, 46, 583594)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 66689ae53e032fe0
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Attempting to acquire lock 1245627314912 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1245627314912 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1245627314912 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1245627314912 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
ERROR: Spider error processing <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: #contacts
ERROR: Spider error processing <GET https://www.southcoastwinery.com/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['info@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'resv@silveradoresort.com',
            'sales@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'tennis@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'spa@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'golf@silveradoresort.com',
            'silveradoreservations@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
ERROR: Spider error processing <GET https://www.laquintaresort.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /map-and-contact/
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5254,
 'downloader/request_count': 18,
 'downloader/request_method_count/GET': 18,
 'downloader/response_bytes': 552001,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 13,
 'downloader/response_status_count/301': 5,
 'elapsed_time_seconds': 5.863988,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 18, 12, 551564),
 'httpcompression/response_bytes': 620927,
 'httpcompression/response_count': 9,
 'item_scraped_count': 2,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 3,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'robotstxt/request_count': 6,
 'robotstxt/response_count': 6,
 'robotstxt/response_status_count/200': 6,
 'scheduler/dequeued': 10,
 'scheduler/dequeued/memory': 10,
 'scheduler/enqueued': 10,
 'scheduler/enqueued/memory': 10,
 'spider_exceptions/ValueError': 3,
 'start_time': datetime.datetime(2022, 12, 9, 14, 18, 6, 687576)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 9932ac15aec5f302
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 40, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Attempting to acquire lock 2814235418368 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2814235418368 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2814235418368 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2814235418368 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
ERROR: Spider error processing <GET https://www.southcoastwinery.com/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
ERROR: Spider error processing <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: #contacts
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['silveradoreservations@silveradoresort.com',
            'sales@silveradoresort.com',
            'resv@silveradoresort.com',
            'tennis@silveradoresort.com',
            'golf@silveradoresort.com',
            'spa@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'info@silveradoresort.com',
            'silverado.concierge@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
ERROR: Spider error processing <GET https://www.laquintaresort.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /map-and-contact/
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5254,
 'downloader/request_count': 18,
 'downloader/request_method_count/GET': 18,
 'downloader/response_bytes': 540594,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 13,
 'downloader/response_status_count/301': 5,
 'elapsed_time_seconds': 4.884223,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 18, 59, 455802),
 'httpcompression/response_bytes': 580053,
 'httpcompression/response_count': 9,
 'item_scraped_count': 2,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 4,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'robotstxt/request_count': 6,
 'robotstxt/response_count': 6,
 'robotstxt/response_status_count/200': 6,
 'scheduler/dequeued': 10,
 'scheduler/dequeued/memory': 10,
 'scheduler/enqueued': 10,
 'scheduler/enqueued/memory': 10,
 'spider_exceptions/ValueError': 3,
 'start_time': datetime.datetime(2022, 12, 9, 14, 18, 54, 571579)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 419843e384627907
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 40, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Attempting to acquire lock 2098659586496 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2098659586496 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2098659586496 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2098659586496 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
ERROR: Spider error processing <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 98, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: #contacts
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['silveradoreservations@silveradoresort.com',
            'tennis@silveradoresort.com',
            'sales@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'info@silveradoresort.com',
            'resv@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'golf@silveradoresort.com',
            'spa@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.linkedin.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET https://www.linkedin.com/company/south-coast-winery-&-spa/>
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://instagram.com/robots.txt> from <GET http://instagram.com/robots.txt>
DEBUG: Crawled (200) <GET https://instagram.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET http://instagram.com/laquintaresort>
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 2,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 2,
 'downloader/request_bytes': 5926,
 'downloader/request_count': 21,
 'downloader/request_method_count/GET': 21,
 'downloader/response_bytes': 548518,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 15,
 'downloader/response_status_count/301': 6,
 'elapsed_time_seconds': 6.028874,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 36, 45, 939961),
 'httpcompression/response_bytes': 684133,
 'httpcompression/response_count': 11,
 'item_scraped_count': 2,
 'log_count/DEBUG': 32,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 15,
 'robotstxt/forbidden': 2,
 'robotstxt/request_count': 8,
 'robotstxt/response_count': 8,
 'robotstxt/response_status_count/200': 8,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2022, 12, 9, 14, 36, 39, 911087)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: cb59e405c47f0534
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 40, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Attempting to acquire lock 2587382875760 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2587382875760 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2587382875760 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2587382875760 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.instagram.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET https://www.instagram.com/thepurpleorchid/>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
ERROR: Spider error processing <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 98, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: #contacts
DEBUG: Crawled (200) <GET https://www.linkedin.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET https://www.linkedin.com/company/south-coast-winery-&-spa/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['jeff.vanparis@silveradoresort.com',
            'spa@silveradoresort.com',
            'resv@silveradoresort.com',
            'golf@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'tennis@silveradoresort.com',
            'info@silveradoresort.com',
            'sales@silveradoresort.com',
            'silveradoreservations@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://instagram.com/robots.txt> from <GET http://instagram.com/robots.txt>
DEBUG: Crawled (200) <GET https://instagram.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET http://instagram.com/laquintaresort>
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 3,
 'downloader/request_bytes': 6603,
 'downloader/request_count': 24,
 'downloader/request_method_count/GET': 24,
 'downloader/response_bytes': 567717,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 18,
 'downloader/response_status_count/301': 6,
 'elapsed_time_seconds': 5.012313,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 37, 47, 857807),
 'httpcompression/response_bytes': 758188,
 'httpcompression/response_count': 14,
 'item_scraped_count': 2,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 18,
 'robotstxt/forbidden': 3,
 'robotstxt/request_count': 10,
 'robotstxt/response_count': 10,
 'robotstxt/response_status_count/200': 10,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2022, 12, 9, 14, 37, 42, 845494)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 7cbd164facfb334f
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 40, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Attempting to acquire lock 2141987481744 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2141987481744 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2141987481744 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2141987481744 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
ERROR: Spider error processing <GET https://www.southcoastwinery.com/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['events@purpleorchid.com',
            'spa@purpleorchid.com',
            'rhiannon@purpleorchid.com',
            'info@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
ERROR: Spider error processing <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: #contacts
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['resv@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'info@silveradoresort.com',
            'spa@silveradoresort.com',
            'sales@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'golf@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'tennis@silveradoresort.com',
            'heather.mckenna@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
ERROR: Spider error processing <GET https://www.laquintaresort.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 97, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /map-and-contact/
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5975,
 'downloader/request_count': 21,
 'downloader/request_method_count/GET': 21,
 'downloader/response_bytes': 581333,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 16,
 'downloader/response_status_count/301': 5,
 'elapsed_time_seconds': 4.807543,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 38, 46, 306157),
 'httpcompression/response_bytes': 752455,
 'httpcompression/response_count': 12,
 'item_scraped_count': 3,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 4,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 16,
 'robotstxt/request_count': 7,
 'robotstxt/response_count': 7,
 'robotstxt/response_status_count/200': 7,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'spider_exceptions/ValueError': 3,
 'start_time': datetime.datetime(2022, 12, 9, 14, 38, 41, 498614)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 7217f78b24f76c7a
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 40, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Attempting to acquire lock 2154098975808 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2154098975808 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2154098975808 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2154098975808 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['events@purpleorchid.com',
            'info@purpleorchid.com',
            'rhiannon@purpleorchid.com',
            'spa@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
ERROR: Spider error processing <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 102, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: #contacts
ERROR: Spider error processing <GET https://www.southcoastwinery.com/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 102, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['sales@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'spa@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'resv@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'tennis@silveradoresort.com',
            'golf@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'info@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
ERROR: Spider error processing <GET https://www.laquintaresort.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 102, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /map-and-contact/
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5975,
 'downloader/request_count': 21,
 'downloader/request_method_count/GET': 21,
 'downloader/response_bytes': 581210,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 16,
 'downloader/response_status_count/301': 5,
 'elapsed_time_seconds': 4.837273,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 43, 9, 796702),
 'httpcompression/response_bytes': 752456,
 'httpcompression/response_count': 12,
 'item_scraped_count': 3,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 4,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 16,
 'robotstxt/request_count': 7,
 'robotstxt/response_count': 7,
 'robotstxt/response_status_count/200': 7,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'spider_exceptions/ValueError': 3,
 'start_time': datetime.datetime(2022, 12, 9, 14, 43, 4, 959429)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 9d6a920c8474964c
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 42, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Attempting to acquire lock 2395669103664 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2395669103664 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2395669103664 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2395669103664 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['events@purpleorchid.com',
            'spa@purpleorchid.com',
            'info@purpleorchid.com',
            'rhiannon@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
ERROR: Spider error processing <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 104, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: #contacts
ERROR: Spider error processing <GET https://www.southcoastwinery.com/spa/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 104, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /contact
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['silveradodining@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'tennis@silveradoresort.com',
            'info@silveradoresort.com',
            'sales@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'golf@silveradoresort.com',
            'spa@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'resv@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
ERROR: Spider error processing <GET https://www.laquintaresort.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\defer.py", line 240, in iter_errback
    yield next(it)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\utils\python.py", line 338, in __next__
    return next(self.data)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 336, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 32, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\spidermw.py", line 79, in process_sync
    for r in iterable:
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 104, in parse_website
    yield scrapy.Request(url=contact_link, callback=self.parse_contact,
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: /map-and-contact/
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5975,
 'downloader/request_count': 21,
 'downloader/request_method_count/GET': 21,
 'downloader/response_bytes': 570061,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 16,
 'downloader/response_status_count/301': 5,
 'elapsed_time_seconds': 5.990311,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 43, 54, 129568),
 'httpcompression/response_bytes': 711580,
 'httpcompression/response_count': 12,
 'item_scraped_count': 3,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 4,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 16,
 'robotstxt/request_count': 7,
 'robotstxt/response_count': 7,
 'robotstxt/response_status_count/200': 7,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'spider_exceptions/ValueError': 3,
 'start_time': datetime.datetime(2022, 12, 9, 14, 43, 48, 139257)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 4626c11e61fe599e
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 42, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Attempting to acquire lock 1642486924048 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1642486924048 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1642486924048 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1642486924048 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['spa@purpleorchid.com',
            'rhiannon@purpleorchid.com',
            'info@purpleorchid.com',
            'events@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['jeff.vanparis@silveradoresort.com',
            'info@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'tennis@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'sales@silveradoresort.com',
            'resv@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'spa@silveradoresort.com',
            'golf@silveradoresort.com',
            'silveradoreservations@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['weddings@laquintaresort.com',
            'information@laquintaresort.com',
            'resinquiry@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': '',
 'twitter': 'https://twitter.com/laquintaresort'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6586,
 'downloader/request_count': 23,
 'downloader/request_method_count/GET': 23,
 'downloader/response_bytes': 853317,
 'downloader/response_count': 23,
 'downloader/response_status_count/200': 18,
 'downloader/response_status_count/301': 5,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 8.952848,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 45, 27, 346256),
 'httpcompression/response_bytes': 886899,
 'httpcompression/response_count': 13,
 'item_scraped_count': 5,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 18,
 'robotstxt/request_count': 7,
 'robotstxt/response_count': 7,
 'robotstxt/response_status_count/200': 7,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2022, 12, 9, 14, 45, 18, 393408)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: c7799e1d938e3591
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 42, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Attempting to acquire lock 2795385720352 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2795385720352 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2795385720352 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2795385720352 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['rhiannon@purpleorchid.com',
            'events@purpleorchid.com',
            'spa@purpleorchid.com',
            'info@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['resv@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'tennis@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'sales@silveradoresort.com',
            'golf@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'info@silveradoresort.com',
            'spa@silveradoresort.com',
            'loren.bates@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['information@laquintaresort.com',
            'weddings@laquintaresort.com',
            'resinquiry@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': '',
 'twitter': 'https://twitter.com/laquintaresort'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6586,
 'downloader/request_count': 23,
 'downloader/request_method_count/GET': 23,
 'downloader/response_bytes': 853819,
 'downloader/response_count': 23,
 'downloader/response_status_count/200': 18,
 'downloader/response_status_count/301': 5,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 8.136542,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 45, 57, 383576),
 'httpcompression/response_bytes': 886894,
 'httpcompression/response_count': 13,
 'item_scraped_count': 5,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 18,
 'robotstxt/request_count': 7,
 'robotstxt/response_count': 7,
 'robotstxt/response_status_count/200': 7,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2022, 12, 9, 14, 45, 49, 247034)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 8eae1c4b333d92ee
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 42, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Attempting to acquire lock 2225021312864 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2225021312864 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2225021312864 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2225021312864 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['rhiannon@purpleorchid.com',
            'info@purpleorchid.com',
            'spa@purpleorchid.com',
            'events@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['resv@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'spa@silveradoresort.com',
            'sales@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'golf@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'tennis@silveradoresort.com',
            'info@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'silveradoreservations@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['resinquiry@laquintaresort.com',
            'information@laquintaresort.com',
            'weddings@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': '',
 'twitter': 'https://twitter.com/laquintaresort'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6586,
 'downloader/request_count': 23,
 'downloader/request_method_count/GET': 23,
 'downloader/response_bytes': 853533,
 'downloader/response_count': 23,
 'downloader/response_status_count/200': 18,
 'downloader/response_status_count/301': 5,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 7.652571,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 48, 50, 31416),
 'httpcompression/response_bytes': 886901,
 'httpcompression/response_count': 13,
 'item_scraped_count': 5,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 18,
 'robotstxt/request_count': 7,
 'robotstxt/response_count': 7,
 'robotstxt/response_status_count/200': 7,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2022, 12, 9, 14, 48, 42, 378845)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 53e2c5d07d75c4ad
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 41, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Attempting to acquire lock 2011968514576 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2011968514576 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2011968514576 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2011968514576 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['info@purpleorchid.com',
            'spa@purpleorchid.com',
            'events@purpleorchid.com',
            'rhiannon@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['spa@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'golf@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'sales@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'tennis@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'resv@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'info@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['weddings@laquintaresort.com',
            'information@laquintaresort.com',
            'resinquiry@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': '',
 'twitter': 'https://twitter.com/laquintaresort'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6586,
 'downloader/request_count': 23,
 'downloader/request_method_count/GET': 23,
 'downloader/response_bytes': 853546,
 'downloader/response_count': 23,
 'downloader/response_status_count/200': 18,
 'downloader/response_status_count/301': 5,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 7.743058,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 50, 47, 354361),
 'httpcompression/response_bytes': 886897,
 'httpcompression/response_count': 13,
 'item_scraped_count': 5,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 18,
 'robotstxt/request_count': 7,
 'robotstxt/response_count': 7,
 'robotstxt/response_status_count/200': 7,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2022, 12, 9, 14, 50, 39, 611303)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: ab55f40d112609fb
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 41, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Attempting to acquire lock 1749342551632 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1749342551632 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1749342551632 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1749342551632 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['events@purpleorchid.com',
            'spa@purpleorchid.com',
            'info@purpleorchid.com',
            'rhiannon@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['loren.bates@silveradoresort.com',
            'resv@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'tennis@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'spa@silveradoresort.com',
            'sales@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'golf@silveradoresort.com',
            'info@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['resinquiry@laquintaresort.com',
            'weddings@laquintaresort.com',
            'information@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': '',
 'twitter': 'https://twitter.com/laquintaresort'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6586,
 'downloader/request_count': 23,
 'downloader/request_method_count/GET': 23,
 'downloader/response_bytes': 841905,
 'downloader/response_count': 23,
 'downloader/response_status_count/200': 18,
 'downloader/response_status_count/301': 5,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 7.066642,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 51, 31, 56362),
 'httpcompression/response_bytes': 846025,
 'httpcompression/response_count': 13,
 'item_scraped_count': 5,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 18,
 'robotstxt/request_count': 7,
 'robotstxt/response_count': 7,
 'robotstxt/response_status_count/200': 7,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2022, 12, 9, 14, 51, 23, 989720)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: f0f71581db3e1c1e
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 41, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Attempting to acquire lock 1905514178080 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1905514178080 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1905514178080 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1905514178080 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.instagram.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET https://www.instagram.com/thepurpleorchid/>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['golf@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'tennis@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'sales@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'resv@silveradoresort.com',
            'spa@silveradoresort.com',
            'info@silveradoresort.com',
            'loren.bates@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.linkedin.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET https://www.linkedin.com/company/south-coast-winery-&-spa/>
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://instagram.com/robots.txt> from <GET http://instagram.com/robots.txt>
DEBUG: Crawled (200) <GET https://instagram.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET http://instagram.com/laquintaresort>
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 3,
 'downloader/request_bytes': 6603,
 'downloader/request_count': 24,
 'downloader/request_method_count/GET': 24,
 'downloader/response_bytes': 579322,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 18,
 'downloader/response_status_count/301': 6,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 5.517567,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 55, 25, 902172),
 'httpcompression/response_bytes': 798570,
 'httpcompression/response_count': 14,
 'item_scraped_count': 2,
 'log_count/DEBUG': 37,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 18,
 'robotstxt/forbidden': 3,
 'robotstxt/request_count': 10,
 'robotstxt/response_count': 10,
 'robotstxt/response_status_count/200': 10,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2022, 12, 9, 14, 55, 20, 384605)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 8f397005334ef673
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 41, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Attempting to acquire lock 2521591809024 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2521591809024 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2521591809024 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2521591809024 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.instagram.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET https://www.instagram.com/thepurpleorchid/>
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.linkedin.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET https://www.linkedin.com/company/south-coast-winery-&-spa/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['silveradodining@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'tennis@silveradoresort.com',
            'sales@silveradoresort.com',
            'golf@silveradoresort.com',
            'info@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'resv@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'spa@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://instagram.com/robots.txt> from <GET http://instagram.com/robots.txt>
DEBUG: Crawled (200) <GET https://instagram.com/robots.txt> (referer: None)
DEBUG: Forbidden by robots.txt: <GET http://instagram.com/laquintaresort>
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 3,
 'downloader/request_bytes': 6603,
 'downloader/request_count': 24,
 'downloader/request_method_count/GET': 24,
 'downloader/response_bytes': 579506,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 18,
 'downloader/response_status_count/301': 6,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 4.843775,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 56, 19, 434728),
 'httpcompression/response_bytes': 799057,
 'httpcompression/response_count': 14,
 'item_scraped_count': 2,
 'log_count/DEBUG': 37,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 18,
 'robotstxt/forbidden': 3,
 'robotstxt/request_count': 10,
 'robotstxt/response_count': 10,
 'robotstxt/response_status_count/200': 10,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2022, 12, 9, 14, 56, 14, 590953)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: b5a4de603b2e6ada
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 41, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Attempting to acquire lock 1361101000128 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1361101000128 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1361101000128 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1361101000128 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['events@purpleorchid.com',
            'info@purpleorchid.com',
            'rhiannon@purpleorchid.com',
            'spa@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['sales@silveradoresort.com',
            'resv@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'golf@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'info@silveradoresort.com',
            'tennis@silveradoresort.com',
            'spa@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'silverado.concierge@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['resinquiry@laquintaresort.com',
            'weddings@laquintaresort.com',
            'information@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': '',
 'twitter': 'https://twitter.com/laquintaresort'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6586,
 'downloader/request_count': 23,
 'downloader/request_method_count/GET': 23,
 'downloader/response_bytes': 841986,
 'downloader/response_count': 23,
 'downloader/response_status_count/200': 18,
 'downloader/response_status_count/301': 5,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 6.800688,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 57, 1, 412028),
 'httpcompression/response_bytes': 846025,
 'httpcompression/response_count': 13,
 'item_scraped_count': 5,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 18,
 'robotstxt/request_count': 7,
 'robotstxt/response_count': 7,
 'robotstxt/response_status_count/200': 7,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2022, 12, 9, 14, 56, 54, 611340)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 7dd9934b8dc5d809
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 41, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Attempting to acquire lock 2386261882864 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2386261882864 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2386261882864 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2386261882864 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6586,
 'downloader/request_count': 23,
 'downloader/request_method_count/GET': 23,
 'downloader/response_bytes': 853248,
 'downloader/response_count': 23,
 'downloader/response_status_count/200': 18,
 'downloader/response_status_count/301': 5,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 7.309883,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 58, 38, 783124),
 'httpcompression/response_bytes': 886898,
 'httpcompression/response_count': 13,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 18,
 'robotstxt/request_count': 7,
 'robotstxt/response_count': 7,
 'robotstxt/response_status_count/200': 7,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2022, 12, 9, 14, 58, 31, 473241)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 774d7f2a525c9b58
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 41, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/robots.txt> from <GET http://www.mytrilogylife.com/robots.txt>
DEBUG: Attempting to acquire lock 1644023874224 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1644023874224 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1644023874224 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1644023874224 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/robots.txt> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/robots.txt> from <GET http://www.laquintaresort.com/robots.txt>
DEBUG: Crawled (200) <GET https://www.chaminade.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/robots.txt> (referer: None)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['events@purpleorchid.com',
            'rhiannon@purpleorchid.com',
            'info@purpleorchid.com',
            'spa@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['spa@silveradoresort.com',
            'sales@silveradoresort.com',
            'golf@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'info@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'resv@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'tennis@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['weddings@laquintaresort.com',
            'information@laquintaresort.com',
            'resinquiry@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': '',
 'twitter': 'https://twitter.com/laquintaresort'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6586,
 'downloader/request_count': 23,
 'downloader/request_method_count/GET': 23,
 'downloader/response_bytes': 853352,
 'downloader/response_count': 23,
 'downloader/response_status_count/200': 18,
 'downloader/response_status_count/301': 5,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 8.483673,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 14, 58, 59, 497704),
 'httpcompression/response_bytes': 886900,
 'httpcompression/response_count': 13,
 'item_scraped_count': 5,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 18,
 'robotstxt/request_count': 7,
 'robotstxt/response_count': 7,
 'robotstxt/response_status_count/200': 7,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2022, 12, 9, 14, 58, 51, 14031)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: f8152112aba2c9be
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 41, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Attempting to acquire lock 1404676932368 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1404676932368 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1404676932368 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1404676932368 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['spa@purpleorchid.com',
            'info@purpleorchid.com',
            'events@purpleorchid.com',
            'rhiannon@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['info@silveradoresort.com',
            'tennis@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'sales@silveradoresort.com',
            'spa@silveradoresort.com',
            'golf@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'resv@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['information@laquintaresort.com',
            'resinquiry@laquintaresort.com',
            'weddings@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': '',
 'twitter': 'https://twitter.com/laquintaresort'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4115,
 'downloader/request_count': 14,
 'downloader/request_method_count/GET': 14,
 'downloader/response_bytes': 836945,
 'downloader/response_count': 14,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/301': 3,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 7.44103,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 4, 57, 953747),
 'httpcompression/response_bytes': 842495,
 'httpcompression/response_count': 8,
 'item_scraped_count': 5,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 11,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2022, 12, 9, 15, 4, 50, 512717)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 116639ab5c4798a5
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Attempting to acquire lock 2466676553568 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2466676553568 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2466676553568 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2466676553568 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['info@purpleorchid.com',
            'events@purpleorchid.com',
            'rhiannon@purpleorchid.com',
            'spa@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['resv@silveradoresort.com',
            'sales@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'spa@silveradoresort.com',
            'info@silveradoresort.com',
            'tennis@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'golf@silveradoresort.com',
            'loren.bates@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['resinquiry@laquintaresort.com',
            'weddings@laquintaresort.com',
            'information@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': '',
 'twitter': 'https://twitter.com/laquintaresort'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4115,
 'downloader/request_count': 14,
 'downloader/request_method_count/GET': 14,
 'downloader/response_bytes': 848149,
 'downloader/response_count': 14,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/301': 3,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 7.518981,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 6, 14, 579743),
 'httpcompression/response_bytes': 883369,
 'httpcompression/response_count': 8,
 'item_scraped_count': 5,
 'log_count/DEBUG': 27,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 11,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2022, 12, 9, 15, 6, 7, 60762)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 61dcec925da661a8
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Attempting to acquire lock 2512976784800 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2512976784800 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2512976784800 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2512976784800 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['spa@purpleorchid.com',
            'rhiannon@purpleorchid.com',
            'events@purpleorchid.com',
            'info@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['golf@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'sales@silveradoresort.com',
            'tennis@silveradoresort.com',
            'spa@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'info@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'resv@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['information@laquintaresort.com',
            'resinquiry@laquintaresort.com',
            'weddings@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': '',
 'twitter': 'https://twitter.com/laquintaresort'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4115,
 'downloader/request_count': 14,
 'downloader/request_method_count/GET': 14,
 'downloader/response_bytes': 848128,
 'downloader/response_count': 14,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/301': 3,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 7.414713,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 9, 32, 767763),
 'httpcompression/response_bytes': 883368,
 'httpcompression/response_count': 8,
 'item_scraped_count': 5,
 'log_count/DEBUG': 27,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 11,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2022, 12, 9, 15, 9, 25, 353050)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 74619afcb7b20916
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Attempting to acquire lock 1846033258080 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1846033258080 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1846033258080 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1846033258080 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['rhiannon@purpleorchid.com',
            'spa@purpleorchid.com',
            'info@purpleorchid.com',
            'events@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': '',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['loren.bates@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'resv@silveradoresort.com',
            'info@silveradoresort.com',
            'sales@silveradoresort.com',
            'spa@silveradoresort.com',
            'tennis@silveradoresort.com',
            'golf@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'silveradodining@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['information@laquintaresort.com',
            'weddings@laquintaresort.com',
            'resinquiry@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': '',
 'twitter': 'https://twitter.com/laquintaresort'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4115,
 'downloader/request_count': 14,
 'downloader/request_method_count/GET': 14,
 'downloader/response_bytes': 848475,
 'downloader/response_count': 14,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/301': 3,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 7.294879,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 12, 34, 67383),
 'httpcompression/response_bytes': 883365,
 'httpcompression/response_count': 8,
 'item_scraped_count': 5,
 'log_count/DEBUG': 27,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 11,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2022, 12, 9, 15, 12, 26, 772504)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 8bc9486fac55f164
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Attempting to acquire lock 2035275309040 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2035275309040 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2035275309040 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2035275309040 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [], 'facebook': '', 'instagram': '', 'linkedin': '', 'twitter': ''}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1079,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 181261,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 4.242489,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 14, 12, 227297),
 'httpcompression/response_bytes': 194226,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 3,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2022, 12, 9, 15, 14, 7, 984808)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 3cb85cb9756839ad
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Attempting to acquire lock 2479189527280 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2479189527280 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2479189527280 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2479189527280 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1079,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 181262,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 2.721396,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 16, 52, 361382),
 'httpcompression/response_bytes': 194226,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 3,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2022, 12, 9, 15, 16, 49, 639986)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 1e3de48d5aec208b
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Attempting to acquire lock 2100234892240 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2100234892240 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2100234892240 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2100234892240 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1079,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 181263,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 2.824168,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 20, 55, 732810),
 'httpcompression/response_bytes': 194226,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 3,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2022, 12, 9, 15, 20, 52, 908642)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: f0eb77858d72835a
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Filtered duplicate request: <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Attempting to acquire lock 2918977319696 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2918977319696 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2918977319696 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2918977319696 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1079,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 181261,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 2.926929,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 21, 18, 619994),
 'httpcompression/response_bytes': 194226,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 3,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2022, 12, 9, 15, 21, 15, 693065)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 4d3f04d085734dae
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Attempting to acquire lock 1911366013984 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1911366013984 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1911366013984 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1911366013984 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1375,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 209702,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 4,
 'downloader/response_status_count/301': 1,
 'elapsed_time_seconds': 3.094878,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 24, 27, 401368),
 'httpcompression/response_bytes': 313199,
 'httpcompression/response_count': 3,
 'item_scraped_count': 2,
 'log_count/DEBUG': 14,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 4,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2022, 12, 9, 15, 24, 24, 306490)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 5ca57227e8e38cfc
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2342368575104 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2342368575104 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2342368575104 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2342368575104 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Scraped from <200 https://cadayspa.com/contact-us>
{'emails': ['impallari@gmail.com',
            'ron@cadayspa.com',
            'team@latofonts.com',
            'filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/californiadayspa',
 'instagram': 'https://www.instagram.com/cadayspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/califadayspa'}
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Scraped from <200 https://www.fourseasons.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/FourSeasons',
 'instagram': 'https://www.instagram.com/fourseasons/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FourSeasons'}
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Scraped from <200 https://www.kellysspa.com/contact-location>
{'emails': ['SpaDirector@Missioninn.com', 'spadirector@missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn',
 'instagram': 'https://www.instagram.com/kellys_spa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': ['cavinfo@cal-a-vie.com'],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/calaviespa'}
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Scraped from <200 https://www.osmosis.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/OsmosisDaySpaSanctuary',
 'instagram': 'https://www.instagram.com/osmosisdayspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/osmosisspa'}
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': ['reservations@goldendoor.com',
            'guestservices@goldendoor.com',
            'guestservices@goldendoor.com.',
            'shop@goldendoor.com',
            'molly@thestoriedgroup.com'],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Scraped from <200 https://montereyplazahotel.com/hotel/contact>
{'emails': ['sales@montereyplazahotel.com',
            'weddings@montereyplazahotel.com',
            'reservations@montereyplazahotel.com',
            'forms@tambourine.com',
            'housekeeping@montereyplazahotel.com',
            'coastalcurator@montereyplazahotel.com'],
 'facebook': 'https://www.facebook.com/montereyplazahotel',
 'instagram': 'https://www.instagram.com/montereyplaza/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['events@purpleorchid.com',
            'spa@purpleorchid.com',
            'rhiannon@purpleorchid.com',
            'info@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Scraped from <200 https://www.aubergeresorts.com/solage/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SolageResort/',
 'instagram': 'https://www.instagram.com/solageauberge/?hl=en',
 'linkedin': 'https://www.linkedin.com/company/auberge-resorts/',
 'twitter': 'https://twitter.com/solageauberge'}
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Scraped from <200 https://www.urbanretreatspa.com/contact>
{'emails': ['contact@urbanretreatspa.com', 'careers@urbanretreatspa.com'],
 'facebook': 'https://www.facebook.com/pages/Urban-Retreat-Day-Spa/69993009232?ref=hl',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/URDaySpa'}
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['heather.mckenna@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'info@silveradoresort.com',
            'spa@silveradoresort.com',
            'golf@silveradoresort.com',
            'resv@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'sales@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'tennis@silveradoresort.com',
            'silveradodining@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Scraped from <200 https://www.terranea.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/Terranea',
 'instagram': 'http://instagram.com/terranearesort',
 'linkedin': 'https://www.linkedin.com/company/terranea-resort',
 'twitter': 'https://twitter.com/TerraneaResort'}
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
DEBUG: Scraped from <200 https://boonhotels.com/contact/>
{'emails': ['info@boonhotels.com', 'events@boonbrand.com'],
 'facebook': 'http://www.facebook.com/boonhotelspa',
 'instagram': 'https://www.instagram.com/boonhotelspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/boonhotelspa'}
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Scraped from <200 https://www.urbanretreatspa.com/contact>
{'emails': ['contact@urbanretreatspa.com', 'careers@urbanretreatspa.com'],
 'facebook': 'https://www.facebook.com/pages/Urban-Retreat-Day-Spa/69993009232?ref=hl',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/URDaySpa'}
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['concierge@ranchovalencia.com',
            'spareservations@ranchovalencia.com',
            'reservations@ranchovalencia.com',
            'tennis@ranchovalencia.com',
            'groupevents@ranchovalencia.com',
            'villas@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'donations@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': ['info@wispausa.com'],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Scraped from <200 https://glenivy.com/contact-info/>
{'emails': ['donations@glenivy.com.', 'donations@glenivy.com'],
 'facebook': 'https://www.facebook.com/GlenIvyHotSprings',
 'instagram': 'https://instagram.com/glenivy_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/GlenIvySpas'}
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Scraped from <200 https://www.lapeauspafresno.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/lapeauspa/?fref=ts',
 'instagram': 'https://www.instagram.com/lapeauspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Scraped from <200 https://www.canyonranch.com/contact-us/>
{'emails': ['Woodside-Sales@canyonranch.com',
            'Tucson-Sales@canyonranch.com',
            'media@canyonranch.com',
            'jzimmermann@canyonranch.com',
            'reservations@canyonranch.com',
            'nikki.field@sothebyshomes.com',
            'gmontgomery@williampitt.com',
            'Las-Vegas-Sales@canyonranch.com',
            'Lenox-Sales@canyonranch.com',
            'lchesloff@williampitt.com'],
 'facebook': 'https://www.facebook.com/CanyonRanch',
 'instagram': 'https://www.instagram.com/canyonranch/',
 'linkedin': 'https://www.linkedin.com/company/canyon-ranch',
 'twitter': 'https://twitter.com/CanyonRanch'}
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Scraped from <200 https://lagunacanyonspa.com/contact-us>
{'emails': ['impallari@gmail.com',
            'info@ndiscovered.com',
            'hello@rfuenzalida.com',
            'filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/103690430994',
 'instagram': 'https://www.instagram.com/lagunacanyonspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/lagunacanyonspa/'}
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['sales@paradisepoint.com',
            'marketing@paradisepoint.com',
            'weddings@paradisepoint.com',
            'reservations@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Scraped from <200 https://www.indianspringscalistoga.com/contact-us>
{'emails': ['forms@tambourine.com',
            'reservations@indianspringscalistoga.com',
            'inquiries@indianspringscalistoga.com'],
 'facebook': 'https://www.facebook.com/ISRNAPA/',
 'instagram': 'https://www.instagram.com/indianspringscalistoga/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Scraped from <200 https://thesisleyspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SisleySpaUSA/',
 'instagram': 'https://www.instagram.com/sisleyspausa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://thesisleyspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SisleySpaUSA/',
 'instagram': 'https://www.instagram.com/sisleyspausa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': ['info@wecarespa.com'],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Scraped from <200 https://carmelvalleyranch.com/contact/>
{'emails': ['cvrriverranch@carmelvalleyranch.com',
            'cvrevents@carmelvalleyranch.com',
            'cvrreservations@carmelvalleyranch.com',
            'cvrwedding@carmelvalleyranch.com',
            'guestservices@carmelvalleyranch.com',
            'cvrgolf@carmelvalleyranch.com',
            'tennis@carmelvalleyranch.com',
            'cvrclubhouse@carmelvalleyranch.com',
            'cvrmembership@carmelvalleyranch.com',
            'activities@carmelvalleyranch.com',
            'spa@carmelvalleyranch.com',
            'cvrvalleykitchen@carmelvalleyranch.com'],
 'facebook': 'https://www.facebook.com/carmelvalleyranch/',
 'instagram': 'https://www.instagram.com/carmelvranch',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://theravenspa.com/contact/> (referer: https://theravenspa.com/)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/contact-us> (referer: https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 43, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: %20CA%2090039
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Scraped from <200 https://theravenspa.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['weddings@laquintaresort.com',
            'information@laquintaresort.com',
            'resinquiry@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/laquintaresort'}
DEBUG: Scraped from <200 https://www.cavallopoint.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/CavalloPoint',
 'instagram': 'https://www.instagram.com/cavallopoint/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/CavalloPoint'}
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Redirecting (301) to <GET https://www.ranchobernardoinn.com/contact-us/> from <GET https://www.ranchobernardoinn.com/contact-us>
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.missioninn.com/contact>
{'emails': ['reservations@missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/missioninnhotel?lang=en'}
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/contact-us/> (referer: https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext)
DEBUG: Scraped from <200 https://www.ranchobernardoinn.com/contact-us/>
{'emails': ['ranchobernardoinn@jcresorts.com',
            'rbiweddings@jcresorts.com',
            'rbibilling@jcresorts.com',
            'rbijobs@jcresorts.com'],
 'facebook': 'https://www.facebook.com/RBInn',
 'instagram': 'https://instagram.com/ranchobernardoinn/',
 'linkedin': 'https://www.linkedin.com/company/rancho-bernardo-inn?trk=biz-brand-tree-co-logo',
 'twitter': 'https://twitter.com/rbernardoinn'}
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['concierge@ranchovalencia.com',
            'spareservations@ranchovalencia.com',
            'reservations@ranchovalencia.com',
            'tennis@ranchovalencia.com',
            'groupevents@ranchovalencia.com',
            'villas@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'donations@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Scraped from <200 https://www.teahousespa.com/contact-join-our-team>
{'emails': ['TeaHouseSpaManagement@gmail.com', 'reception@teahousespa.com'],
 'facebook': 'https://www.facebook.com/theteahousespa',
 'instagram': 'https://www.instagram.com/theteahousespa/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.paseahotel.com/contact/press-room>
{'emails': ['forms@tambourine.com',
            'marketing@paseahotel.com',
            'frontdesk@paseahotel.com'],
 'facebook': 'https://www.facebook.com/PaseaHotel/',
 'instagram': 'https://www.instagram.com/paseahotel/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://www.estancialajolla.com/contact/>
{'emails': ['sales@estancialajolla.com',
            'events@estancialajolla.com',
            'bookzoe@noblehousehotels.com',
            'elj@20twostudio.com',
            'spa@estancialajolla.com',
            'rsv@estancialajolla.com',
            'EstanciaConcierge@EstanciaLaJolla.com'],
 'facebook': 'https://www.facebook.com/EstanciaLaJolla/',
 'instagram': 'https://www.instagram.com/estancialajolla/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Scraped from <200 https://harbin.org/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/harbinhotsprings',
 'instagram': 'https://www.instagram.com/harbin_hot_springs/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Scraped from <200 https://www.bardessono.com/contact.htm>
{'emails': [],
 'facebook': 'https://www.facebook.com/bardessonohotelspa/',
 'instagram': 'https://www.instagram.com/bardessonoyountville/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BardessonoHotel'}
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': ['catering@miraclesprings.com',
            'spa@miraclesprings.com',
            'events@miraclesprings.com',
            'reservations@miraclesprings.com'],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 48674,
 'downloader/request_count': 171,
 'downloader/request_method_count/GET': 171,
 'downloader/response_bytes': 5924206,
 'downloader/response_count': 171,
 'downloader/response_status_count/200': 116,
 'downloader/response_status_count/301': 49,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 3,
 'elapsed_time_seconds': 14.649945,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 25, 54, 160396),
 'httpcompression/response_bytes': 20893636,
 'httpcompression/response_count': 116,
 'httperror/response_ignored_count': 4,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'item_scraped_count': 49,
 'log_count/DEBUG': 227,
 'log_count/ERROR': 2,
 'log_count/INFO': 14,
 'request_depth_max': 1,
 'response_received_count': 120,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/429 Unknown Status': 2,
 'scheduler/dequeued': 171,
 'scheduler/dequeued/memory': 171,
 'scheduler/enqueued': 171,
 'scheduler/enqueued/memory': 171,
 'start_time': datetime.datetime(2022, 12, 9, 15, 25, 39, 510451)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 75e97e0e910b5031
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Attempting to acquire lock 2043498992240 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2043498992240 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2043498992240 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2043498992240 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Scraped from <200 https://www.kellysspa.com/contact-location>
{'emails': ['SpaDirector@Missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn',
 'instagram': 'https://www.instagram.com/kellys_spa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Scraped from <200 https://cadayspa.com/contact-us>
{'emails': ['ron@cadayspa.com', 'filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/californiadayspa',
 'instagram': 'https://www.instagram.com/cadayspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/califadayspa'}
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': ['guestservices@goldendoor.com.',
            'Bonding@Golden',
            'reservations@goldendoor.com'],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['info@purpleorchid.com', 'rhiannon@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Scraped from <200 https://www.osmosis.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/OsmosisDaySpaSanctuary',
 'instagram': 'https://www.instagram.com/osmosisdayspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/osmosisspa'}
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Scraped from <200 https://www.fourseasons.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/FourSeasons',
 'instagram': 'https://www.instagram.com/fourseasons/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FourSeasons'}
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Scraped from <200 https://www.aubergeresorts.com/solage/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SolageResort/',
 'instagram': 'https://www.instagram.com/solageauberge/?hl=en',
 'linkedin': 'https://www.linkedin.com/company/auberge-resorts/',
 'twitter': 'https://twitter.com/solageauberge'}
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Scraped from <200 https://www.terranea.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/Terranea',
 'instagram': 'http://instagram.com/terranearesort',
 'linkedin': 'https://www.linkedin.com/company/terranea-resort',
 'twitter': 'https://twitter.com/TerraneaResort'}
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Scraped from <200 https://www.urbanretreatspa.com/contact>
{'emails': ['wght@0', 'wght@300'],
 'facebook': 'https://www.facebook.com/pages/Urban-Retreat-Day-Spa/69993009232?ref=hl',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/URDaySpa'}
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://boonhotels.com/contact/>
{'emails': ['events@boonbrand.com'],
 'facebook': 'http://www.facebook.com/boonhotelspa',
 'instagram': 'https://www.instagram.com/boonhotelspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/boonhotelspa'}
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Scraped from <200 https://www.canyonranch.com/contact-us/>
{'emails': ['gmontgomery@williampitt.com',
            'Tucson-Sales@canyonranch.com',
            'jzimmermann@canyonranch.com',
            'Lenox-Sales@canyonranch.com',
            'Woodside-Sales@canyonranch.com'],
 'facebook': 'https://www.facebook.com/CanyonRanch',
 'instagram': 'https://www.instagram.com/canyonranch/',
 'linkedin': 'https://www.linkedin.com/company/canyon-ranch',
 'twitter': 'https://twitter.com/CanyonRanch'}
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Scraped from <200 https://lagunacanyonspa.com/contact-us>
{'emails': ['impallari@gmail.com', 'hello@rfuenzalida.com'],
 'facebook': 'https://www.facebook.com/103690430994',
 'instagram': 'https://www.instagram.com/lagunacanyonspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/lagunacanyonspa/'}
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['spareservations@ranchovalencia.com',
            'reservations@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'tennis@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Scraped from <200 https://carmelvalleyranch.com/contact/>
{'emails': ['cvrclubhouse@carmelvalleyranch.com',
            'cvrwedding@carmelvalleyranch.com',
            'tennis@carmelvalleyranch.com',
            'cvrevents@carmelvalleyranch.com',
            'guestservices@carmelvalleyranch.com',
            'cvrmembership@carmelvalleyranch.com'],
 'facebook': 'https://www.facebook.com/carmelvalleyranch/',
 'instagram': 'https://www.instagram.com/carmelvranch',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Scraped from <200 https://glenivy.com/contact-info/>
{'emails': ['donations@glenivy.com'],
 'facebook': 'https://www.facebook.com/GlenIvyHotSprings',
 'instagram': 'https://instagram.com/glenivy_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/GlenIvySpas'}
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Crawled (200) <GET https://theravenspa.com/contact/> (referer: https://theravenspa.com/)
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Scraped from <200 https://theravenspa.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['reservations@paradisepoint.com', 'sales@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Scraped from <200 https://www.paseahotel.com/contact/press-room>
{'emails': ['nr@context', 'marketing@paseahotel.com'],
 'facebook': 'https://www.facebook.com/PaseaHotel/',
 'instagram': 'https://www.instagram.com/paseahotel/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/contact> (referer: https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Scraped from <200 https://www.teahousespa.com/contact-join-our-team>
{'emails': ['wght@0'],
 'facebook': 'https://www.facebook.com/theteahousespa',
 'instagram': 'https://www.instagram.com/theteahousespa/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Scraped from <200 https://www.romanspahotsprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/romanspahotsprings',
 'instagram': 'https://www.instagram.com/romanspahotspringsresort/?ref=badge',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/romansparesort'}
DEBUG: Crawled (200) <GET https://petitespa.net/> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 4648: character maps to <undefined>
DEBUG: Redirecting (301) to <GET https://oceanohalfmoonbay.com/> from <GET http://www.oceanohalfmoonbay.com/>
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['spareservations@ranchovalencia.com',
            'reservations@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'tennis@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb-listing&utm_content=brentwood> (referer: None)
DEBUG: Scraped from <200 https://www.bardessono.com/contact.htm>
{'emails': [],
 'facebook': 'https://www.facebook.com/bardessonohotelspa/',
 'instagram': 'https://www.instagram.com/bardessonoyountville/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BardessonoHotel'}
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/> (referer: None)
DEBUG: Scraped from <200 https://www.estancialajolla.com/contact/>
{'emails': ['events@estancialajolla.com',
            'EstanciaConcierge@EstanciaLaJolla.com',
            'spa@estancialajolla.com'],
 'facebook': 'https://www.facebook.com/EstanciaLaJolla/',
 'instagram': 'https://www.instagram.com/estancialajolla/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://petitespa.net/contact-us-1> (referer: https://petitespa.net/)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/contact/> (referer: https://oceanohalfmoonbay.com/)
DEBUG: Scraped from <200 https://petitespa.net/contact-us-1>
{'emails': ['impallari@gmail.com'],
 'facebook': 'https://www.facebook.com/116067731773408',
 'instagram': 'https://www.instagram.com/petitespa',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Scraped from <200 https://oceanohalfmoonbay.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/oceanohotelspa/',
 'instagram': 'https://www.instagram.com/oceanohotelspa/?ref=badge',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': ['spa@miraclesprings.com', 'events@miraclesprings.com'],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Redirecting (302) to <GET http://ww1.metropolissalonspa.com> from <GET http://metropolissalonspa.com/>
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ventanabigsur.com/spa/overview> (referer: None)
DEBUG: Crawled (451) <GET https://www.morongocasinoresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
INFO: Ignoring response <451 https://www.morongocasinoresort.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.ventanabigsur.com/contact-us> (referer: https://www.ventanabigsur.com/spa/overview)
DEBUG: Scraped from <200 https://www.ventanabigsur.com/contact-us>
{'emails': ['ventanaconcierge@ventanabigsur.com'],
 'facebook': 'https://www.facebook.com/AlilaVentanaBigSur/',
 'instagram': 'https://www.instagram.com/ventanabigsur/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ventanabigsur'}
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/contact/> (referer: https://www.macarthurplace.com/)
DEBUG: Scraped from <200 https://www.macarthurplace.com/contact/>
{'emails': ['press@macarthurplace.com'],
 'facebook': 'https://www.facebook.com/MacArthurPlaceHotelandSpa/',
 'instagram': 'https://instagram.com/macarthurplace/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/macarthurplace'}
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Scraped from <200 http://www.athenaspa-mv.com/contact-us>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://ww1.metropolissalonspa.com> (referer: None)
INFO: Crawled 124 pages (at 124 pages/min), scraped 39 items (at 39 items/min)
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/WiSpa_USA'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 50582,
 'downloader/request_count': 177,
 'downloader/request_method_count/GET': 177,
 'downloader/response_bytes': 5428443,
 'downloader/response_count': 177,
 'downloader/response_status_count/200': 120,
 'downloader/response_status_count/301': 46,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 3,
 'downloader/response_status_count/451': 1,
 'downloader/response_status_count/502': 3,
 'elapsed_time_seconds': 66.737974,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 32, 13, 994140),
 'httpcompression/response_bytes': 20585321,
 'httpcompression/response_count': 122,
 'httperror/response_ignored_count': 6,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'httperror/response_ignored_status_count/451': 1,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 40,
 'log_count/DEBUG': 224,
 'log_count/ERROR': 3,
 'log_count/INFO': 17,
 'request_depth_max': 1,
 'response_received_count': 126,
 'retry/count': 4,
 'retry/max_reached': 2,
 'retry/reason_count/429 Unknown Status': 2,
 'retry/reason_count/502 Bad Gateway': 2,
 'scheduler/dequeued': 177,
 'scheduler/dequeued/memory': 177,
 'scheduler/enqueued': 177,
 'scheduler/enqueued/memory': 177,
 'start_time': datetime.datetime(2022, 12, 9, 15, 31, 7, 256166)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 51b7dbcfca4f4b6e
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2318181128016 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2318181128016 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2318181128016 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2318181128016 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Scraped from <200 https://cadayspa.com/contact-us>
{'emails': ['ron@cadayspa.com', 'team@latofonts.com'],
 'facebook': 'https://www.facebook.com/californiadayspa',
 'instagram': 'https://www.instagram.com/cadayspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/califadayspa'}
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Scraped from <200 https://www.kellysspa.com/contact-location>
{'emails': ['spadirector@missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn',
 'instagram': 'https://www.instagram.com/kellys_spa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Scraped from <200 https://www.fourseasons.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/FourSeasons',
 'instagram': 'https://www.instagram.com/fourseasons/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FourSeasons'}
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': ['Bonding@Golden',
            'reservations@goldendoor.com',
            'shop@goldendoor.com'],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Scraped from <200 https://www.osmosis.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/OsmosisDaySpaSanctuary',
 'instagram': 'https://www.instagram.com/osmosisdayspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/osmosisspa'}
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['events@purpleorchid.com', 'info@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Scraped from <200 https://www.aubergeresorts.com/solage/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SolageResort/',
 'instagram': 'https://www.instagram.com/solageauberge/?hl=en',
 'linkedin': 'https://www.linkedin.com/company/auberge-resorts/',
 'twitter': 'https://twitter.com/solageauberge'}
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Scraped from <200 https://www.terranea.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/Terranea',
 'instagram': 'http://instagram.com/terranearesort',
 'linkedin': 'https://www.linkedin.com/company/terranea-resort',
 'twitter': 'https://twitter.com/TerraneaResort'}
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Scraped from <200 https://boonhotels.com/contact/>
{'emails': ['info@boonhotels.com'],
 'facebook': 'http://www.facebook.com/boonhotelspa',
 'instagram': 'https://www.instagram.com/boonhotelspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/boonhotelspa'}
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['info@villasranchovalencia.com',
            'tennis@ranchovalencia.com',
            'concierge@ranchovalencia.com',
            'villas@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Scraped from <200 https://www.canyonranch.com/contact-us/>
{'emails': ['Woodside-Sales@canyonranch.com',
            'gmontgomery@williampitt.com',
            'Lenox-Sales@canyonranch.com',
            'lchesloff@williampitt.com',
            'jzimmermann@canyonranch.com'],
 'facebook': 'https://www.facebook.com/CanyonRanch',
 'instagram': 'https://www.instagram.com/canyonranch/',
 'linkedin': 'https://www.linkedin.com/company/canyon-ranch',
 'twitter': 'https://twitter.com/CanyonRanch'}
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Scraped from <200 https://lagunacanyonspa.com/contact-us>
{'emails': ['filler@godaddy.com', 'impallari@gmail.com'],
 'facebook': 'https://www.facebook.com/103690430994',
 'instagram': 'https://www.instagram.com/lagunacanyonspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/lagunacanyonspa/'}
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/contact-us> (referer: https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb)
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Scraped from <200 https://www.cavallopoint.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/CavalloPoint',
 'instagram': 'https://www.instagram.com/cavallopoint/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/CavalloPoint'}
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Scraped from <200 https://glenivy.com/contact-info/>
{'emails': ['donations@glenivy.com'],
 'facebook': 'https://www.facebook.com/GlenIvyHotSprings',
 'instagram': 'https://instagram.com/glenivy_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/GlenIvySpas'}
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['marketing@paradisepoint.com', 'reservations@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Scraped from <200 https://carmelvalleyranch.com/contact/>
{'emails': ['cvrgolf@carmelvalleyranch.com',
            'cvrclubhouse@carmelvalleyranch.com',
            'tennis@carmelvalleyranch.com',
            'cvrevents@carmelvalleyranch.com',
            'cvrmembership@carmelvalleyranch.com',
            'cvrreservations@carmelvalleyranch.com'],
 'facebook': 'https://www.facebook.com/carmelvalleyranch/',
 'instagram': 'https://www.instagram.com/carmelvranch',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Redirecting (301) to <GET https://www.ranchobernardoinn.com/contact-us/> from <GET https://www.ranchobernardoinn.com/contact-us>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['glidejs@2.1.0', 'information@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/laquintaresort'}
DEBUG: Crawled (200) <GET https://theravenspa.com/contact/> (referer: https://theravenspa.com/)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/contact-us/> (referer: https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext)
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
DEBUG: Scraped from <200 https://theravenspa.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Scraped from <200 https://www.ranchobernardoinn.com/contact-us/>
{'emails': ['rbijobs@jcresorts.com', 'ranchobernardoinn@jcresorts.com'],
 'facebook': 'https://www.facebook.com/RBInn',
 'instagram': 'https://instagram.com/ranchobernardoinn/',
 'linkedin': 'https://www.linkedin.com/company/rancho-bernardo-inn?trk=biz-brand-tree-co-logo',
 'twitter': 'https://twitter.com/rbernardoinn'}
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://petitespa.net/> (referer: None)
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/contact> (referer: https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://oceanohalfmoonbay.com/> from <GET http://www.oceanohalfmoonbay.com/>
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Crawled (200) <GET http://metropolissalonspa.com/> (referer: None)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
DEBUG: Scraped from <200 https://www.romanspahotsprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/romanspahotsprings',
 'instagram': 'https://www.instagram.com/romanspahotspringsresort/?ref=badge',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/romansparesort'}
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://petitespa.net/contact-us-1> (referer: https://petitespa.net/)
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['info@villasranchovalencia.com',
            'tennis@ranchovalencia.com',
            'concierge@ranchovalencia.com',
            'villas@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb-listing&utm_content=brentwood> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.rushcreeklodge.com/> from <GET http://www.rushcreeklodge.com/>
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 4073: character maps to <undefined>
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/?utm_source=google-local&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Scraped from <200 https://petitespa.net/contact-us-1>
{'emails': ['impallari@gmail.com'],
 'facebook': 'https://www.facebook.com/116067731773408',
 'instagram': 'https://www.instagram.com/petitespa',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.athenaspa-mv.com/contact-us>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/contact/> (referer: https://oceanohalfmoonbay.com/)
DEBUG: Scraped from <200 https://www.estancialajolla.com/contact/>
{'emails': ['events@estancialajolla.com',
            'rsv@estancialajolla.com',
            'bookzoe@noblehousehotels.com'],
 'facebook': 'https://www.facebook.com/EstanciaLaJolla/',
 'instagram': 'https://www.instagram.com/estancialajolla/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Crawled (451) <GET https://www.morongocasinoresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Scraped from <200 https://oceanohalfmoonbay.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/oceanohotelspa/',
 'instagram': 'https://www.instagram.com/oceanohotelspa/?ref=badge',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
INFO: Ignoring response <451 https://www.morongocasinoresort.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.bardessono.com/contact.htm>
{'emails': [],
 'facebook': 'https://www.facebook.com/bardessonohotelspa/',
 'instagram': 'https://www.instagram.com/bardessonoyountville/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BardessonoHotel'}
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/?utm_source=google-local&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['marketing@paradisepoint.com', 'reservations@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Crawled (200) <GET https://www.rushcreeklodge.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/> (referer: None)
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': ['reservations@miraclesprings.com', 'events@miraclesprings.com'],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Crawled (200) <GET https://www.ventanabigsur.com/spa/overview> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.thespaatfgv.com/> from <GET http://www.thespaatfgv.com/>
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/contact/> (referer: https://www.macarthurplace.com/)
DEBUG: Scraped from <200 https://www.macarthurplace.com/contact/>
{'emails': ['press@macarthurplace.com'],
 'facebook': 'https://www.facebook.com/MacArthurPlaceHotelandSpa/',
 'instagram': 'https://instagram.com/macarthurplace/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/macarthurplace'}
DEBUG: Crawled (200) <GET https://www.rushcreeklodge.com/us/contact-us/> (referer: https://www.rushcreeklodge.com/)
DEBUG: Crawled (200) <GET https://www.ventanabigsur.com/contact-us> (referer: https://www.ventanabigsur.com/spa/overview)
DEBUG: Scraped from <200 https://www.rushcreeklodge.com/us/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/RushCreekLodge/',
 'instagram': 'https://www.instagram.com/yosemite_rushcreek/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.ventanabigsur.com/contact-us>
{'emails': ['ventanaconcierge@ventanabigsur.com'],
 'facebook': 'https://www.facebook.com/AlilaVentanaBigSur/',
 'instagram': 'https://www.instagram.com/ventanabigsur/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ventanabigsur'}
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://thespaatfgv.com/> from <GET https://www.thespaatfgv.com/>
DEBUG: Crawled (200) <GET https://thespaatfgv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thespaatfgv.com/contact/> (referer: https://thespaatfgv.com/)
DEBUG: Scraped from <200 https://thespaatfgv.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SpaHungryHair/',
 'instagram': 'https://www.instagram.com/themedicalspa_hungryhair/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 55142,
 'downloader/request_count': 194,
 'downloader/request_method_count/GET': 194,
 'downloader/response_bytes': 6385491,
 'downloader/response_count': 194,
 'downloader/response_status_count/200': 133,
 'downloader/response_status_count/301': 51,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 3,
 'downloader/response_status_count/451': 1,
 'downloader/response_status_count/502': 3,
 'elapsed_time_seconds': 20.83577,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 33, 48, 348642),
 'httpcompression/response_bytes': 22954418,
 'httpcompression/response_count': 132,
 'httperror/response_ignored_count': 6,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'httperror/response_ignored_status_count/451': 1,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 43,
 'log_count/DEBUG': 244,
 'log_count/ERROR': 3,
 'log_count/INFO': 16,
 'request_depth_max': 1,
 'response_received_count': 139,
 'retry/count': 4,
 'retry/max_reached': 2,
 'retry/reason_count/429 Unknown Status': 2,
 'retry/reason_count/502 Bad Gateway': 2,
 'scheduler/dequeued': 194,
 'scheduler/dequeued/memory': 194,
 'scheduler/enqueued': 194,
 'scheduler/enqueued/memory': 194,
 'start_time': datetime.datetime(2022, 12, 9, 15, 33, 27, 512872)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: ee0bb3fa07695801
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1589407347184 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1589407347184 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1589407347184 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1589407347184 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Scraped from <200 https://www.kellysspa.com/contact-location>
{'emails': [],
 'facebook': 'https://www.facebook.com/TheMissionInn',
 'instagram': 'https://www.instagram.com/kellys_spa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Scraped from <200 https://cadayspa.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/californiadayspa',
 'instagram': 'https://www.instagram.com/cadayspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/califadayspa'}
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/calaviespa'}
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Scraped from <200 https://www.osmosis.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/OsmosisDaySpaSanctuary',
 'instagram': 'https://www.instagram.com/osmosisdayspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/osmosisspa'}
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Scraped from <200 https://www.fourseasons.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/FourSeasons',
 'instagram': 'https://www.instagram.com/fourseasons/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FourSeasons'}
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Scraped from <200 https://www.aubergeresorts.com/solage/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SolageResort/',
 'instagram': 'https://www.instagram.com/solageauberge/?hl=en',
 'linkedin': 'https://www.linkedin.com/company/auberge-resorts/',
 'twitter': 'https://twitter.com/solageauberge'}
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Scraped from <200 https://montereyplazahotel.com/hotel/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/montereyplazahotel',
 'instagram': 'https://www.instagram.com/montereyplaza/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Scraped from <200 https://www.urbanretreatspa.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/Urban-Retreat-Day-Spa/69993009232?ref=hl',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/URDaySpa'}
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Scraped from <200 https://www.terranea.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/Terranea',
 'instagram': 'http://instagram.com/terranearesort',
 'linkedin': 'https://www.linkedin.com/company/terranea-resort',
 'twitter': 'https://twitter.com/TerraneaResort'}
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://thesisleyspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SisleySpaUSA/',
 'instagram': 'https://www.instagram.com/sisleyspausa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Scraped from <200 https://lagunacanyonspa.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/103690430994',
 'instagram': 'https://www.instagram.com/lagunacanyonspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/lagunacanyonspa/'}
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Scraped from <200 https://www.canyonranch.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/CanyonRanch',
 'instagram': 'https://www.instagram.com/canyonranch/',
 'linkedin': 'https://www.linkedin.com/company/canyon-ranch',
 'twitter': 'https://twitter.com/CanyonRanch'}
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/contact-us> (referer: https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/wecarespa'}
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Scraped from <200 https://www.indianspringscalistoga.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/ISRNAPA/',
 'instagram': 'https://www.instagram.com/indianspringscalistoga/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.cavallopoint.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/CavalloPoint',
 'instagram': 'https://www.instagram.com/cavallopoint/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/CavalloPoint'}
DEBUG: Scraped from <200 https://glenivy.com/contact-info/>
{'emails': [],
 'facebook': 'https://www.facebook.com/GlenIvyHotSprings',
 'instagram': 'https://instagram.com/glenivy_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/GlenIvySpas'}
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Scraped from <200 https://carmelvalleyranch.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/carmelvalleyranch/',
 'instagram': 'https://www.instagram.com/carmelvranch',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchobernardoinn.com/contact-us/> from <GET https://www.ranchobernardoinn.com/contact-us>
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Scraped from <200 https://www.lapeauspafresno.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/lapeauspa/?fref=ts',
 'instagram': 'https://www.instagram.com/lapeauspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/contact-us/> (referer: https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext)
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.ranchobernardoinn.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/RBInn',
 'instagram': 'https://instagram.com/ranchobernardoinn/',
 'linkedin': 'https://www.linkedin.com/company/rancho-bernardo-inn?trk=biz-brand-tree-co-logo',
 'twitter': 'https://twitter.com/rbernardoinn'}
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Scraped from <200 https://www.missioninn.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/TheMissionInn/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/missioninnhotel?lang=en'}
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/contact> (referer: https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Scraped from <200 https://www.romanspahotsprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/romanspahotsprings',
 'instagram': 'https://www.instagram.com/romanspahotspringsresort/?ref=badge',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/romansparesort'}
DEBUG: Redirecting (301) to <GET https://oceanohalfmoonbay.com/> from <GET http://www.oceanohalfmoonbay.com/>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Crawled (200) <GET https://petitespa.net/> (referer: None)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Crawled (200) <GET http://metropolissalonspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Scraped from <200 https://www.teahousespa.com/contact-join-our-team>
{'emails': [],
 'facebook': 'https://www.facebook.com/theteahousespa',
 'instagram': 'https://www.instagram.com/theteahousespa/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/laquintaresort'}
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/> (referer: None)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://petitespa.net/contact-us-1> (referer: https://petitespa.net/)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 3383: character maps to <undefined>
DEBUG: Scraped from <200 http://www.athenaspa-mv.com/contact-us>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb-listing&utm_content=brentwood> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://mysheerbliss.com/pages/contact-us-spa-policy>
{'emails': [],
 'facebook': 'https://www.facebook.com/fresnoorganicspa/',
 'instagram': 'https://www.instagram.com/sheerblissspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.rushcreeklodge.com/> from <GET http://www.rushcreeklodge.com/>
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
DEBUG: Scraped from <200 https://petitespa.net/contact-us-1>
{'emails': [],
 'facebook': 'https://www.facebook.com/116067731773408',
 'instagram': 'https://www.instagram.com/petitespa',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Scraped from <200 https://www.estancialajolla.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/EstanciaLaJolla/',
 'instagram': 'https://www.instagram.com/estancialajolla/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/contact/> (referer: https://oceanohalfmoonbay.com/)
DEBUG: Crawled (451) <GET https://www.morongocasinoresort.com/> (referer: None)
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/?utm_source=google-local&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.paseahotel.com/contact/press-room>
{'emails': [],
 'facebook': 'https://www.facebook.com/PaseaHotel/',
 'instagram': 'https://www.instagram.com/paseahotel/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://oceanohalfmoonbay.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/oceanohotelspa/',
 'instagram': 'https://www.instagram.com/oceanohotelspa/?ref=badge',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <451 https://www.morongocasinoresort.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.thespaatfgv.com/> from <GET http://www.thespaatfgv.com/>
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Scraped from <200 https://harbin.org/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/harbinhotsprings',
 'instagram': 'https://www.instagram.com/harbin_hot_springs/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Scraped from <200 https://www.bardessono.com/contact.htm>
{'emails': [],
 'facebook': 'https://www.facebook.com/bardessonohotelspa/',
 'instagram': 'https://www.instagram.com/bardessonoyountville/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BardessonoHotel'}
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/?utm_source=google-local&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Crawled (200) <GET https://www.rushcreeklodge.com/> (referer: None)
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://thespaatfgv.com/> from <GET https://www.thespaatfgv.com/>
DEBUG: Crawled (200) <GET https://www.rushcreeklodge.com/us/contact-us/> (referer: https://www.rushcreeklodge.com/)
DEBUG: Scraped from <200 https://www.rushcreeklodge.com/us/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/RushCreekLodge/',
 'instagram': 'https://www.instagram.com/yosemite_rushcreek/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.ventanabigsur.com/spa/overview> (referer: None)
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/contact/> (referer: https://www.macarthurplace.com/)
DEBUG: Scraped from <200 https://www.macarthurplace.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MacArthurPlaceHotelandSpa/',
 'instagram': 'https://instagram.com/macarthurplace/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/macarthurplace'}
DEBUG: Crawled (200) <GET https://www.ventanabigsur.com/contact-us> (referer: https://www.ventanabigsur.com/spa/overview)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
DEBUG: Scraped from <200 https://www.ventanabigsur.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/AlilaVentanaBigSur/',
 'instagram': 'https://www.instagram.com/ventanabigsur/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ventanabigsur'}
DEBUG: Crawled (200) <GET https://thespaatfgv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thespaatfgv.com/contact/> (referer: https://thespaatfgv.com/)
DEBUG: Scraped from <200 https://thespaatfgv.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SpaHungryHair/',
 'instagram': 'https://www.instagram.com/themedicalspa_hungryhair/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 53108,
 'downloader/request_count': 186,
 'downloader/request_method_count/GET': 186,
 'downloader/response_bytes': 6241588,
 'downloader/response_count': 186,
 'downloader/response_status_count/200': 127,
 'downloader/response_status_count/301': 49,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 3,
 'downloader/response_status_count/451': 1,
 'downloader/response_status_count/502': 3,
 'elapsed_time_seconds': 14.580574,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 35, 14, 302369),
 'httpcompression/response_bytes': 22241924,
 'httpcompression/response_count': 126,
 'httperror/response_ignored_count': 6,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'httperror/response_ignored_status_count/451': 1,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 54,
 'log_count/DEBUG': 247,
 'log_count/ERROR': 3,
 'log_count/INFO': 16,
 'request_depth_max': 1,
 'response_received_count': 133,
 'retry/count': 4,
 'retry/max_reached': 2,
 'retry/reason_count/429 Unknown Status': 2,
 'retry/reason_count/502 Bad Gateway': 2,
 'scheduler/dequeued': 186,
 'scheduler/dequeued/memory': 186,
 'scheduler/enqueued': 186,
 'scheduler/enqueued/memory': 186,
 'start_time': datetime.datetime(2022, 12, 9, 15, 34, 59, 721795)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: cf48fee9dfd784c8
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2711078785216 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2711078785216 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2711078785216 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2711078785216 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Scraped from <200 https://cadayspa.com/contact-us>
{'emails': ['filler@godaddy.com',
            'team@latofonts.com',
            'impallari@gmail.com',
            'ron@cadayspa.com'],
 'facebook': 'https://www.facebook.com/californiadayspa',
 'instagram': 'https://www.instagram.com/cadayspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/califadayspa'}
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Scraped from <200 https://www.kellysspa.com/contact-location>
{'emails': ['SpaDirector@Missioninn.com', 'spadirector@missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn',
 'instagram': 'https://www.instagram.com/kellys_spa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Scraped from <200 https://www.fourseasons.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/FourSeasons',
 'instagram': 'https://www.instagram.com/fourseasons/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FourSeasons'}
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': ['shop@goldendoor.com',
            'reservations@goldendoor.com',
            'guestservices@goldendoor.com.',
            'guestservices@goldendoor.com',
            'molly@thestoriedgroup.com'],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': ['cavinfo@cal-a-vie.com'],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/calaviespa'}
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Scraped from <200 https://www.osmosis.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/OsmosisDaySpaSanctuary',
 'instagram': 'https://www.instagram.com/osmosisdayspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/osmosisspa'}
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['info@purpleorchid.com',
            'spa@purpleorchid.com',
            'rhiannon@purpleorchid.com',
            'events@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['tennis@silveradoresort.com',
            'sales@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'info@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'resv@silveradoresort.com',
            'golf@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'spa@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Scraped from <200 https://www.aubergeresorts.com/solage/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SolageResort/',
 'instagram': 'https://www.instagram.com/solageauberge/?hl=en',
 'linkedin': 'https://www.linkedin.com/company/auberge-resorts/',
 'twitter': 'https://twitter.com/solageauberge'}
DEBUG: Scraped from <200 https://www.urbanretreatspa.com/contact>
{'emails': ['contact@urbanretreatspa.com', 'careers@urbanretreatspa.com'],
 'facebook': 'https://www.facebook.com/pages/Urban-Retreat-Day-Spa/69993009232?ref=hl',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/URDaySpa'}
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Scraped from <200 https://www.terranea.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/Terranea',
 'instagram': 'http://instagram.com/terranearesort',
 'linkedin': 'https://www.linkedin.com/company/terranea-resort',
 'twitter': 'https://twitter.com/TerraneaResort'}
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Scraped from <200 https://boonhotels.com/contact/>
{'emails': ['info@boonhotels.com', 'events@boonbrand.com'],
 'facebook': 'http://www.facebook.com/boonhotelspa',
 'instagram': 'https://www.instagram.com/boonhotelspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/boonhotelspa'}
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Scraped from <200 https://montereyplazahotel.com/hotel/contact>
{'emails': ['coastalcurator@montereyplazahotel.com',
            'sales@montereyplazahotel.com',
            'reservations@montereyplazahotel.com',
            'housekeeping@montereyplazahotel.com',
            'forms@tambourine.com',
            'weddings@montereyplazahotel.com'],
 'facebook': 'https://www.facebook.com/montereyplazahotel',
 'instagram': 'https://www.instagram.com/montereyplaza/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Scraped from <200 https://thesisleyspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SisleySpaUSA/',
 'instagram': 'https://www.instagram.com/sisleyspausa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.canyonranch.com/contact-us/>
{'emails': ['media@canyonranch.com',
            'Las-Vegas-Sales@canyonranch.com',
            'Tucson-Sales@canyonranch.com',
            'jzimmermann@canyonranch.com',
            'Woodside-Sales@canyonranch.com',
            'reservations@canyonranch.com',
            'gmontgomery@williampitt.com',
            'lchesloff@williampitt.com',
            'Lenox-Sales@canyonranch.com',
            'nikki.field@sothebyshomes.com'],
 'facebook': 'https://www.facebook.com/CanyonRanch',
 'instagram': 'https://www.instagram.com/canyonranch/',
 'linkedin': 'https://www.linkedin.com/company/canyon-ranch',
 'twitter': 'https://twitter.com/CanyonRanch'}
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/contact-us> (referer: https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Scraped from <200 https://lagunacanyonspa.com/contact-us>
{'emails': ['hello@rfuenzalida.com',
            'impallari@gmail.com',
            'filler@godaddy.com',
            'info@ndiscovered.com'],
 'facebook': 'https://www.facebook.com/103690430994',
 'instagram': 'https://www.instagram.com/lagunacanyonspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/lagunacanyonspa/'}
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['donations@ranchovalencia.com',
            'reservations@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'groupevents@ranchovalencia.com',
            'spareservations@ranchovalencia.com',
            'villas@ranchovalencia.com',
            'tennis@ranchovalencia.com',
            'concierge@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Scraped from <200 https://www.cavallopoint.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/CavalloPoint',
 'instagram': 'https://www.instagram.com/cavallopoint/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/CavalloPoint'}
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.indianspringscalistoga.com/contact-us>
{'emails': ['reservations@indianspringscalistoga.com',
            'forms@tambourine.com',
            'inquiries@indianspringscalistoga.com'],
 'facebook': 'https://www.facebook.com/ISRNAPA/',
 'instagram': 'https://www.instagram.com/indianspringscalistoga/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Scraped from <200 https://www.lapeauspafresno.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/lapeauspa/?fref=ts',
 'instagram': 'https://www.instagram.com/lapeauspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://glenivy.com/contact-info/>
{'emails': ['donations@glenivy.com.', 'donations@glenivy.com'],
 'facebook': 'https://www.facebook.com/GlenIvyHotSprings',
 'instagram': 'https://instagram.com/glenivy_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/GlenIvySpas'}
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Scraped from <200 https://carmelvalleyranch.com/contact/>
{'emails': ['activities@carmelvalleyranch.com',
            'guestservices@carmelvalleyranch.com',
            'cvrgolf@carmelvalleyranch.com',
            'cvrriverranch@carmelvalleyranch.com',
            'cvrvalleykitchen@carmelvalleyranch.com',
            'cvrreservations@carmelvalleyranch.com',
            'cvrclubhouse@carmelvalleyranch.com',
            'cvrwedding@carmelvalleyranch.com',
            'spa@carmelvalleyranch.com',
            'cvrmembership@carmelvalleyranch.com',
            'tennis@carmelvalleyranch.com',
            'cvrevents@carmelvalleyranch.com'],
 'facebook': 'https://www.facebook.com/carmelvalleyranch/',
 'instagram': 'https://www.instagram.com/carmelvranch',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['reservations@paradisepoint.com',
            'marketing@paradisepoint.com',
            'weddings@paradisepoint.com',
            'sales@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchobernardoinn.com/contact-us/> from <GET https://www.ranchobernardoinn.com/contact-us>
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://theravenspa.com/contact/> (referer: https://theravenspa.com/)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': ['info@wispausa.com'],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Scraped from <200 https://theravenspa.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['donations@ranchovalencia.com',
            'reservations@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'groupevents@ranchovalencia.com',
            'spareservations@ranchovalencia.com',
            'villas@ranchovalencia.com',
            'tennis@ranchovalencia.com',
            'concierge@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/contact-us/> (referer: https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.ranchobernardoinn.com/contact-us/>
{'emails': ['ranchobernardoinn@jcresorts.com',
            'rbiweddings@jcresorts.com',
            'rbibilling@jcresorts.com',
            'rbijobs@jcresorts.com'],
 'facebook': 'https://www.facebook.com/RBInn',
 'instagram': 'https://instagram.com/ranchobernardoinn/',
 'linkedin': 'https://www.linkedin.com/company/rancho-bernardo-inn?trk=biz-brand-tree-co-logo',
 'twitter': 'https://twitter.com/rbernardoinn'}
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['weddings@laquintaresort.com',
            'resinquiry@laquintaresort.com',
            'information@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/laquintaresort'}
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': ['info@wecarespa.com'],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Scraped from <200 https://www.missioninn.com/contact>
{'emails': ['reservations@missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/missioninnhotel?lang=en'}
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/contact> (referer: https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Scraped from <200 http://www.athenaspa-mv.com/contact-us>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.romanspahotsprings.com/contact>
{'emails': ['Reservations75@Romanspahotsprings.com'],
 'facebook': 'https://www.facebook.com/romanspahotsprings',
 'instagram': 'https://www.instagram.com/romanspahotspringsresort/?ref=badge',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/romansparesort'}
DEBUG: Scraped from <200 https://www.teahousespa.com/contact-join-our-team>
{'emails': ['reception@teahousespa.com', 'TeaHouseSpaManagement@gmail.com'],
 'facebook': 'https://www.facebook.com/theteahousespa',
 'instagram': 'https://www.instagram.com/theteahousespa/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Scraped from <200 https://mysheerbliss.com/pages/contact-us-spa-policy>
{'emails': ['glow@mysheerbliss.com', 'info@mysheerbliss.com'],
 'facebook': 'https://www.facebook.com/fresnoorganicspa/',
 'instagram': 'https://www.instagram.com/sheerblissspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': ['events@miraclesprings.com',
            'reservations@miraclesprings.com',
            'catering@miraclesprings.com',
            'spa@miraclesprings.com'],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://petitespa.net/> (referer: None)
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
DEBUG: Scraped from <200 https://www.estancialajolla.com/contact/>
{'emails': ['spa@estancialajolla.com',
            'sales@estancialajolla.com',
            'EstanciaConcierge@EstanciaLaJolla.com',
            'bookzoe@noblehousehotels.com',
            'rsv@estancialajolla.com',
            'elj@20twostudio.com',
            'events@estancialajolla.com'],
 'facebook': 'https://www.facebook.com/EstanciaLaJolla/',
 'instagram': 'https://www.instagram.com/estancialajolla/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://oceanohalfmoonbay.com/> from <GET http://www.oceanohalfmoonbay.com/>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 6098: character maps to <undefined>
DEBUG: Crawled (200) <GET http://metropolissalonspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://petitespa.net/contact-us-1> (referer: https://petitespa.net/)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['tennis@silveradoresort.com',
            'sales@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'info@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'resv@silveradoresort.com',
            'golf@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'spa@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Scraped from <200 https://petitespa.net/contact-us-1>
{'emails': ['impallari@gmail.com', '723petitespa@gmail.com'],
 'facebook': 'https://www.facebook.com/116067731773408',
 'instagram': 'https://www.instagram.com/petitespa',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb-listing&utm_content=brentwood> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Scraped from <200 https://harbin.org/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/harbinhotsprings',
 'instagram': 'https://www.instagram.com/harbin_hot_springs/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': ['events@miraclesprings.com',
            'reservations@miraclesprings.com',
            'catering@miraclesprings.com',
            'spa@miraclesprings.com'],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/?utm_source=google-local&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Scraped from <200 https://www.bardessono.com/contact.htm>
{'emails': [],
 'facebook': 'https://www.facebook.com/bardessonohotelspa/',
 'instagram': 'https://www.instagram.com/bardessonoyountville/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BardessonoHotel'}
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/contact/> (referer: https://oceanohalfmoonbay.com/)
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': ['reception@senspa.com'],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Scraped from <200 https://oceanohalfmoonbay.com/contact/>
{'emails': ['admin@oceanohalfmoonbay.com'],
 'facebook': 'https://www.facebook.com/oceanohotelspa/',
 'instagram': 'https://www.instagram.com/oceanohotelspa/?ref=badge',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Crawled (451) <GET https://www.morongocasinoresort.com/> (referer: None)
INFO: Ignoring response <451 https://www.morongocasinoresort.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': ['reception@senspa.com'],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/?utm_source=google-local&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/> (referer: None)
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['reservations@paradisepoint.com',
            'marketing@paradisepoint.com',
            'weddings@paradisepoint.com',
            'sales@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://www.paseahotel.com/contact/press-room>
{'emails': ['marketing@paseahotel.com',
            'frontdesk@paseahotel.com',
            'forms@tambourine.com'],
 'facebook': 'https://www.facebook.com/PaseaHotel/',
 'instagram': 'https://www.instagram.com/paseahotel/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.ventanabigsur.com/spa/overview> (referer: None)
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/contact/> (referer: https://www.macarthurplace.com/)
DEBUG: Scraped from <200 https://www.macarthurplace.com/contact/>
{'emails': ['info@macarthurplace.com', 'press@macarthurplace.com'],
 'facebook': 'https://www.facebook.com/MacArthurPlaceHotelandSpa/',
 'instagram': 'https://instagram.com/macarthurplace/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/macarthurplace'}
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ventanabigsur.com/contact-us> (referer: https://www.ventanabigsur.com/spa/overview)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
DEBUG: Scraped from <200 https://www.ventanabigsur.com/contact-us>
{'emails': ['reservations@ventanabigsur.com',
            'ventanaconcierge@ventanabigsur.com'],
 'facebook': 'https://www.facebook.com/AlilaVentanaBigSur/',
 'instagram': 'https://www.instagram.com/ventanabigsur/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ventanabigsur'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 57792,
 'downloader/request_count': 201,
 'downloader/request_method_count/GET': 201,
 'downloader/response_bytes': 6386719,
 'downloader/response_count': 201,
 'downloader/response_status_count/200': 136,
 'downloader/response_status_count/301': 52,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 6,
 'downloader/response_status_count/451': 1,
 'downloader/response_status_count/502': 3,
 'elapsed_time_seconds': 14.074057,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 36, 8, 974840),
 'httpcompression/response_bytes': 23004206,
 'httpcompression/response_count': 138,
 'httperror/response_ignored_count': 7,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 2,
 'httperror/response_ignored_status_count/451': 1,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 57,
 'log_count/DEBUG': 265,
 'log_count/ERROR': 4,
 'log_count/INFO': 17,
 'request_depth_max': 1,
 'response_received_count': 143,
 'retry/count': 6,
 'retry/max_reached': 3,
 'retry/reason_count/429 Unknown Status': 4,
 'retry/reason_count/502 Bad Gateway': 2,
 'scheduler/dequeued': 201,
 'scheduler/dequeued/memory': 201,
 'scheduler/enqueued': 201,
 'scheduler/enqueued/memory': 201,
 'start_time': datetime.datetime(2022, 12, 9, 15, 35, 54, 900783)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: c7a2b790fa64a35b
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Attempting to acquire lock 2155116393952 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2155116393952 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2155116393952 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2155116393952 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Scraped from <200 https://cadayspa.com/contact-us>
{'emails': ['filler@godaddy.com',
            'impallari@gmail.com',
            'ron@cadayspa.com',
            'team@latofonts.com'],
 'facebook': 'https://www.facebook.com/californiadayspa',
 'instagram': 'https://www.instagram.com/cadayspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/califadayspa'}
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Scraped from <200 https://www.kellysspa.com/contact-location>
{'emails': ['spadirector@missioninn.com', 'SpaDirector@Missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn',
 'instagram': 'https://www.instagram.com/kellys_spa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': ['guestservices@goldendoor.com',
            'guestservices@goldendoor.com.',
            'shop@goldendoor.com',
            'reservations@goldendoor.com',
            'molly@thestoriedgroup.com'],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Scraped from <200 https://www.fourseasons.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/FourSeasons',
 'instagram': 'https://www.instagram.com/fourseasons/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FourSeasons'}
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': ['cavinfo@cal-a-vie.com'],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/calaviespa'}
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['events@purpleorchid.com',
            'info@purpleorchid.com',
            'rhiannon@purpleorchid.com',
            'spa@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Scraped from <200 https://www.osmosis.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/OsmosisDaySpaSanctuary',
 'instagram': 'https://www.instagram.com/osmosisdayspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/osmosisspa'}
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Scraped from <200 https://www.aubergeresorts.com/solage/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SolageResort/',
 'instagram': 'https://www.instagram.com/solageauberge/?hl=en',
 'linkedin': 'https://www.linkedin.com/company/auberge-resorts/',
 'twitter': 'https://twitter.com/solageauberge'}
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Scraped from <200 https://www.urbanretreatspa.com/contact>
{'emails': ['careers@urbanretreatspa.com', 'contact@urbanretreatspa.com'],
 'facebook': 'https://www.facebook.com/pages/Urban-Retreat-Day-Spa/69993009232?ref=hl',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/URDaySpa'}
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Scraped from <200 https://www.terranea.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/Terranea',
 'instagram': 'http://instagram.com/terranearesort',
 'linkedin': 'https://www.linkedin.com/company/terranea-resort',
 'twitter': 'https://twitter.com/TerraneaResort'}
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Scraped from <200 https://boonhotels.com/contact/>
{'emails': ['events@boonbrand.com', 'info@boonhotels.com'],
 'facebook': 'http://www.facebook.com/boonhotelspa',
 'instagram': 'https://www.instagram.com/boonhotelspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/boonhotelspa'}
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Scraped from <200 https://thesisleyspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SisleySpaUSA/',
 'instagram': 'https://www.instagram.com/sisleyspausa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['info@villasranchovalencia.com',
            'tennis@ranchovalencia.com',
            'donations@ranchovalencia.com',
            'reservations@ranchovalencia.com',
            'spareservations@ranchovalencia.com',
            'groupevents@ranchovalencia.com',
            'villas@ranchovalencia.com',
            'concierge@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Scraped from <200 https://www.canyonranch.com/contact-us/>
{'emails': ['jzimmermann@canyonranch.com',
            'media@canyonranch.com',
            'reservations@canyonranch.com',
            'lchesloff@williampitt.com',
            'gmontgomery@williampitt.com',
            'Las-Vegas-Sales@canyonranch.com',
            'Lenox-Sales@canyonranch.com',
            'Tucson-Sales@canyonranch.com',
            'nikki.field@sothebyshomes.com',
            'Woodside-Sales@canyonranch.com'],
 'facebook': 'https://www.facebook.com/CanyonRanch',
 'instagram': 'https://www.instagram.com/canyonranch/',
 'linkedin': 'https://www.linkedin.com/company/canyon-ranch',
 'twitter': 'https://twitter.com/CanyonRanch'}
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/contact-us> (referer: https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Scraped from <200 https://www.cavallopoint.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/CavalloPoint',
 'instagram': 'https://www.instagram.com/cavallopoint/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/CavalloPoint'}
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Scraped from <200 https://lagunacanyonspa.com/contact-us>
{'emails': ['filler@godaddy.com',
            'impallari@gmail.com',
            'info@ndiscovered.com',
            'hello@rfuenzalida.com'],
 'facebook': 'https://www.facebook.com/103690430994',
 'instagram': 'https://www.instagram.com/lagunacanyonspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/lagunacanyonspa/'}
DEBUG: Scraped from <200 https://www.lapeauspafresno.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/lapeauspa/?fref=ts',
 'instagram': 'https://www.instagram.com/lapeauspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': ['info@wispausa.com'],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['marketing@paradisepoint.com',
            'weddings@paradisepoint.com',
            'reservations@paradisepoint.com',
            'sales@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Scraped from <200 https://glenivy.com/contact-info/>
{'emails': ['donations@glenivy.com', 'donations@glenivy.com.'],
 'facebook': 'https://www.facebook.com/GlenIvyHotSprings',
 'instagram': 'https://instagram.com/glenivy_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/GlenIvySpas'}
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': ['info@wecarespa.com'],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Crawled (200) <GET https://theravenspa.com/contact/> (referer: https://theravenspa.com/)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['weddings@laquintaresort.com',
            'resinquiry@laquintaresort.com',
            'information@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/laquintaresort'}
DEBUG: Scraped from <200 https://theravenspa.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Scraped from <200 https://carmelvalleyranch.com/contact/>
{'emails': ['cvrmembership@carmelvalleyranch.com',
            'cvrgolf@carmelvalleyranch.com',
            'cvrreservations@carmelvalleyranch.com',
            'tennis@carmelvalleyranch.com',
            'cvrriverranch@carmelvalleyranch.com',
            'activities@carmelvalleyranch.com',
            'guestservices@carmelvalleyranch.com',
            'spa@carmelvalleyranch.com',
            'cvrclubhouse@carmelvalleyranch.com',
            'cvrevents@carmelvalleyranch.com',
            'cvrvalleykitchen@carmelvalleyranch.com',
            'cvrwedding@carmelvalleyranch.com'],
 'facebook': 'https://www.facebook.com/carmelvalleyranch/',
 'instagram': 'https://www.instagram.com/carmelvranch',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 6579: character maps to <undefined>
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['golf@silveradoresort.com',
            'info@silveradoresort.com',
            'resv@silveradoresort.com',
            'tennis@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'spa@silveradoresort.com',
            'sales@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silveradoreservations@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['info@villasranchovalencia.com',
            'tennis@ranchovalencia.com',
            'donations@ranchovalencia.com',
            'reservations@ranchovalencia.com',
            'spareservations@ranchovalencia.com',
            'groupevents@ranchovalencia.com',
            'villas@ranchovalencia.com',
            'concierge@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.missioninn.com/contact>
{'emails': ['reservations@missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/missioninnhotel?lang=en'}
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/contact> (referer: https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Scraped from <200 https://www.estancialajolla.com/contact/>
{'emails': ['EstanciaConcierge@EstanciaLaJolla.com',
            'bookzoe@noblehousehotels.com',
            'spa@estancialajolla.com',
            'events@estancialajolla.com',
            'elj@20twostudio.com',
            'sales@estancialajolla.com',
            'rsv@estancialajolla.com'],
 'facebook': 'https://www.facebook.com/EstanciaLaJolla/',
 'instagram': 'https://www.instagram.com/estancialajolla/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.romanspahotsprings.com/contact>
{'emails': ['Reservations75@Romanspahotsprings.com'],
 'facebook': 'https://www.facebook.com/romanspahotsprings',
 'instagram': 'https://www.instagram.com/romanspahotspringsresort/?ref=badge',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/romansparesort'}
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Scraped from <200 https://www.teahousespa.com/contact-join-our-team>
{'emails': ['TeaHouseSpaManagement@gmail.com', 'reception@teahousespa.com'],
 'facebook': 'https://www.facebook.com/theteahousespa',
 'instagram': 'https://www.instagram.com/theteahousespa/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Scraped from <200 https://harbin.org/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/harbinhotsprings',
 'instagram': 'https://www.instagram.com/harbin_hot_springs/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://mysheerbliss.com/pages/contact-us-spa-policy>
{'emails': ['info@mysheerbliss.com', 'glow@mysheerbliss.com'],
 'facebook': 'https://www.facebook.com/fresnoorganicspa/',
 'instagram': 'https://www.instagram.com/sheerblissspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
DEBUG: Scraped from <200 http://www.athenaspa-mv.com/contact-us>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': ['events@miraclesprings.com',
            'catering@miraclesprings.com',
            'spa@miraclesprings.com',
            'reservations@miraclesprings.com'],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': ['reception@senspa.com'],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': ['reception@senspa.com'],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Scraped from <200 https://www.bardessono.com/contact.htm>
{'emails': [],
 'facebook': 'https://www.facebook.com/bardessonohotelspa/',
 'instagram': 'https://www.instagram.com/bardessonoyountville/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BardessonoHotel'}
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://www.indianspringscalistoga.com/contact-us>
{'emails': ['forms@tambourine.com',
            'inquiries@indianspringscalistoga.com',
            'reservations@indianspringscalistoga.com'],
 'facebook': 'https://www.facebook.com/ISRNAPA/',
 'instagram': 'https://www.instagram.com/indianspringscalistoga/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Scraped from <200 https://montereyplazahotel.com/hotel/contact>
{'emails': ['coastalcurator@montereyplazahotel.com',
            'forms@tambourine.com',
            'reservations@montereyplazahotel.com',
            'housekeeping@montereyplazahotel.com',
            'weddings@montereyplazahotel.com',
            'sales@montereyplazahotel.com'],
 'facebook': 'https://www.facebook.com/montereyplazahotel',
 'instagram': 'https://www.instagram.com/montereyplaza/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['golf@silveradoresort.com',
            'info@silveradoresort.com',
            'resv@silveradoresort.com',
            'tennis@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'spa@silveradoresort.com',
            'sales@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silveradoreservations@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://www.paseahotel.com/contact/press-room>
{'emails': ['frontdesk@paseahotel.com',
            'forms@tambourine.com',
            'marketing@paseahotel.com'],
 'facebook': 'https://www.facebook.com/PaseaHotel/',
 'instagram': 'https://www.instagram.com/paseahotel/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Received SIGINT, shutting down gracefully. Send again to force 
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
INFO: Closing spider (shutdown)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 48688,
 'downloader/request_count': 169,
 'downloader/request_method_count/GET': 169,
 'downloader/response_bytes': 5681491,
 'downloader/response_count': 169,
 'downloader/response_status_count/200': 114,
 'downloader/response_status_count/301': 46,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 3,
 'downloader/response_status_count/502': 3,
 'elapsed_time_seconds': 14.902527,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 37, 4, 985265),
 'httpcompression/response_bytes': 19290708,
 'httpcompression/response_count': 114,
 'httperror/response_ignored_count': 5,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 49,
 'log_count/DEBUG': 225,
 'log_count/ERROR': 3,
 'log_count/INFO': 16,
 'request_depth_max': 1,
 'response_received_count': 119,
 'retry/count': 4,
 'retry/max_reached': 2,
 'retry/reason_count/429 Unknown Status': 2,
 'retry/reason_count/502 Bad Gateway': 2,
 'scheduler/dequeued': 169,
 'scheduler/dequeued/memory': 169,
 'scheduler/enqueued': 169,
 'scheduler/enqueued/memory': 169,
 'start_time': datetime.datetime(2022, 12, 9, 15, 36, 50, 82738)}
INFO: Spider closed (shutdown)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 759a60e3f61b9ebf
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Attempting to acquire lock 2270865006192 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2270865006192 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2270865006192 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2270865006192 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Scraped from <200 https://cadayspa.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/californiadayspa',
 'instagram': 'https://www.instagram.com/cadayspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/califadayspa'}
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Scraped from <200 https://www.kellysspa.com/contact-location>
{'emails': [],
 'facebook': 'https://www.facebook.com/TheMissionInn',
 'instagram': 'https://www.instagram.com/kellys_spa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/calaviespa'}
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Scraped from <200 https://www.osmosis.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/OsmosisDaySpaSanctuary',
 'instagram': 'https://www.instagram.com/osmosisdayspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/osmosisspa'}
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
DEBUG: Scraped from <200 https://www.urbanretreatspa.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/Urban-Retreat-Day-Spa/69993009232?ref=hl',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/URDaySpa'}
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Scraped from <200 https://www.aubergeresorts.com/solage/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SolageResort/',
 'instagram': 'https://www.instagram.com/solageauberge/?hl=en',
 'linkedin': 'https://www.linkedin.com/company/auberge-resorts/',
 'twitter': 'https://twitter.com/solageauberge'}
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Scraped from <200 https://montereyplazahotel.com/hotel/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/montereyplazahotel',
 'instagram': 'https://www.instagram.com/montereyplaza/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.terranea.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/Terranea',
 'instagram': 'http://instagram.com/terranearesort',
 'linkedin': 'https://www.linkedin.com/company/terranea-resort',
 'twitter': 'https://twitter.com/TerraneaResort'}
DEBUG: Scraped from <200 https://www.fourseasons.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/FourSeasons',
 'instagram': 'https://www.instagram.com/fourseasons/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FourSeasons'}
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Scraped from <200 https://boonhotels.com/contact/>
{'emails': [],
 'facebook': 'http://www.facebook.com/boonhotelspa',
 'instagram': 'https://www.instagram.com/boonhotelspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/boonhotelspa'}
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Scraped from <200 https://www.canyonranch.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/CanyonRanch',
 'instagram': 'https://www.instagram.com/canyonranch/',
 'linkedin': 'https://www.linkedin.com/company/canyon-ranch',
 'twitter': 'https://twitter.com/CanyonRanch'}
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Scraped from <200 https://thesisleyspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SisleySpaUSA/',
 'instagram': 'https://www.instagram.com/sisleyspausa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Scraped from <200 https://lagunacanyonspa.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/103690430994',
 'instagram': 'https://www.instagram.com/lagunacanyonspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/lagunacanyonspa/'}
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Scraped from <200 https://www.lapeauspafresno.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/lapeauspa/?fref=ts',
 'instagram': 'https://www.instagram.com/lapeauspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Scraped from <200 https://www.indianspringscalistoga.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/ISRNAPA/',
 'instagram': 'https://www.instagram.com/indianspringscalistoga/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Crawled (200) <GET https://theravenspa.com/contact/> (referer: https://theravenspa.com/)
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Scraped from <200 https://theravenspa.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.ranchobernardoinn.com/contact-us/> from <GET https://www.ranchobernardoinn.com/contact-us>
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Scraped from <200 https://www.missioninn.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/TheMissionInn/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/missioninnhotel?lang=en'}
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Scraped from <200 https://glenivy.com/contact-info/>
{'emails': [],
 'facebook': 'https://www.facebook.com/GlenIvyHotSprings',
 'instagram': 'https://instagram.com/glenivy_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/GlenIvySpas'}
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/contact-us/> (referer: https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 4126: character maps to <undefined>
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/contact> (referer: https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Scraped from <200 https://www.ranchobernardoinn.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/RBInn',
 'instagram': 'https://instagram.com/ranchobernardoinn/',
 'linkedin': 'https://www.linkedin.com/company/rancho-bernardo-inn?trk=biz-brand-tree-co-logo',
 'twitter': 'https://twitter.com/rbernardoinn'}
DEBUG: Scraped from <200 https://www.teahousespa.com/contact-join-our-team>
{'emails': [],
 'facebook': 'https://www.facebook.com/theteahousespa',
 'instagram': 'https://www.instagram.com/theteahousespa/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Scraped from <200 https://www.romanspahotsprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/romanspahotsprings',
 'instagram': 'https://www.instagram.com/romanspahotspringsresort/?ref=badge',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/romansparesort'}
DEBUG: Crawled (200) <GET https://petitespa.net/> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Crawled (200) <GET http://metropolissalonspa.com/> (referer: None)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Scraped from <200 http://www.athenaspa-mv.com/contact-us>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Crawled (200) <GET https://petitespa.net/contact-us-1> (referer: https://petitespa.net/)
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
DEBUG: Scraped from <200 https://mysheerbliss.com/pages/contact-us-spa-policy>
{'emails': [],
 'facebook': 'https://www.facebook.com/fresnoorganicspa/',
 'instagram': 'https://www.instagram.com/sheerblissspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/laquintaresort'}
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
DEBUG: Scraped from <200 https://petitespa.net/contact-us-1>
{'emails': [],
 'facebook': 'https://www.facebook.com/116067731773408',
 'instagram': 'https://www.instagram.com/petitespa',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Crawled (451) <GET https://www.morongocasinoresort.com/> (referer: None)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Scraped from <200 https://www.estancialajolla.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/EstanciaLaJolla/',
 'instagram': 'https://www.instagram.com/estancialajolla/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb-listing&utm_content=brentwood> (referer: None)
INFO: Ignoring response <451 https://www.morongocasinoresort.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://harbin.org/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/harbinhotsprings',
 'instagram': 'https://www.instagram.com/harbin_hot_springs/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Scraped from <200 https://www.bardessono.com/contact.htm>
{'emails': [],
 'facebook': 'https://www.facebook.com/bardessonohotelspa/',
 'instagram': 'https://www.instagram.com/bardessonoyountville/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BardessonoHotel'}
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://www.paseahotel.com/contact/press-room>
{'emails': [],
 'facebook': 'https://www.facebook.com/PaseaHotel/',
 'instagram': 'https://www.instagram.com/paseahotel/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 49435,
 'downloader/request_count': 172,
 'downloader/request_method_count/GET': 172,
 'downloader/response_bytes': 4017345,
 'downloader/response_count': 172,
 'downloader/response_status_count/200': 116,
 'downloader/response_status_count/301': 46,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 3,
 'downloader/response_status_count/451': 1,
 'downloader/response_status_count/502': 3,
 'elapsed_time_seconds': 16.738393,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 37, 49, 822990),
 'httpcompression/response_bytes': 16002241,
 'httpcompression/response_count': 115,
 'httperror/response_ignored_count': 6,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'httperror/response_ignored_status_count/451': 1,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 49,
 'log_count/DEBUG': 228,
 'log_count/ERROR': 3,
 'log_count/INFO': 16,
 'request_depth_max': 1,
 'response_received_count': 122,
 'retry/count': 4,
 'retry/max_reached': 2,
 'retry/reason_count/429 Unknown Status': 2,
 'retry/reason_count/502 Bad Gateway': 2,
 'scheduler/dequeued': 172,
 'scheduler/dequeued/memory': 172,
 'scheduler/enqueued': 172,
 'scheduler/enqueued/memory': 172,
 'start_time': datetime.datetime(2022, 12, 9, 15, 37, 33, 84597)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: bf53d5100b1e24eb
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2808529542768 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2808529542768 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2808529542768 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2808529542768 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Scraped from <200 https://cadayspa.com/contact-us>
{'emails': ['team@latofonts.com',
            'ron@cadayspa.com',
            'impallari@gmail.com',
            'filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/californiadayspa',
 'instagram': 'https://www.instagram.com/cadayspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/califadayspa'}
DEBUG: Scraped from <200 https://www.kellysspa.com/contact-location>
{'emails': ['SpaDirector@Missioninn.com', 'spadirector@missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn',
 'instagram': 'https://www.instagram.com/kellys_spa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': ['reservations@goldendoor.com',
            'molly@thestoriedgroup.com',
            'guestservices@goldendoor.com',
            'shop@goldendoor.com',
            'guestservices@goldendoor.com.'],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': ['cavinfo@cal-a-vie.com'],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/calaviespa'}
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Scraped from <200 https://www.osmosis.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/OsmosisDaySpaSanctuary',
 'instagram': 'https://www.instagram.com/osmosisdayspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/osmosisspa'}
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Scraped from <200 https://www.fourseasons.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/FourSeasons',
 'instagram': 'https://www.instagram.com/fourseasons/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FourSeasons'}
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['events@purpleorchid.com',
            'info@purpleorchid.com',
            'rhiannon@purpleorchid.com',
            'spa@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Scraped from <200 https://www.aubergeresorts.com/solage/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SolageResort/',
 'instagram': 'https://www.instagram.com/solageauberge/?hl=en',
 'linkedin': 'https://www.linkedin.com/company/auberge-resorts/',
 'twitter': 'https://twitter.com/solageauberge'}
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Scraped from <200 https://montereyplazahotel.com/hotel/contact>
{'emails': ['coastalcurator@montereyplazahotel.com',
            'weddings@montereyplazahotel.com',
            'reservations@montereyplazahotel.com',
            'sales@montereyplazahotel.com',
            'housekeeping@montereyplazahotel.com',
            'forms@tambourine.com'],
 'facebook': 'https://www.facebook.com/montereyplazahotel',
 'instagram': 'https://www.instagram.com/montereyplaza/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.urbanretreatspa.com/contact>
{'emails': ['contact@urbanretreatspa.com'],
 'facebook': 'https://www.facebook.com/pages/Urban-Retreat-Day-Spa/69993009232?ref=hl',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/URDaySpa'}
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['golf@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'sales@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'tennis@silveradoresort.com',
            'spa@silveradoresort.com',
            'resv@silveradoresort.com',
            'info@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'loren.bates@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Scraped from <200 https://www.terranea.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/Terranea',
 'instagram': 'http://instagram.com/terranearesort',
 'linkedin': 'https://www.linkedin.com/company/terranea-resort',
 'twitter': 'https://twitter.com/TerraneaResort'}
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Scraped from <200 https://thesisleyspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SisleySpaUSA/',
 'instagram': 'https://www.instagram.com/sisleyspausa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Scraped from <200 https://boonhotels.com/contact/>
{'emails': ['info@boonhotels.com', 'events@boonbrand.com'],
 'facebook': 'http://www.facebook.com/boonhotelspa',
 'instagram': 'https://www.instagram.com/boonhotelspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/boonhotelspa'}
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['tennis@ranchovalencia.com',
            'groupevents@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'spareservations@ranchovalencia.com',
            'villas@ranchovalencia.com',
            'donations@ranchovalencia.com',
            'concierge@ranchovalencia.com',
            'reservations@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Scraped from <200 https://www.canyonranch.com/contact-us/>
{'emails': ['gmontgomery@williampitt.com',
            'nikki.field@sothebyshomes.com',
            'reservations@canyonranch.com',
            'Lenox-Sales@canyonranch.com',
            'Las-Vegas-Sales@canyonranch.com',
            'Tucson-Sales@canyonranch.com',
            'media@canyonranch.com',
            'jzimmermann@canyonranch.com',
            'Woodside-Sales@canyonranch.com',
            'lchesloff@williampitt.com'],
 'facebook': 'https://www.facebook.com/CanyonRanch',
 'instagram': 'https://www.instagram.com/canyonranch/',
 'linkedin': 'https://www.linkedin.com/company/canyon-ranch',
 'twitter': 'https://twitter.com/CanyonRanch'}
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Scraped from <200 https://lagunacanyonspa.com/contact-us>
{'emails': ['info@ndiscovered.com',
            'hello@rfuenzalida.com',
            'impallari@gmail.com',
            'filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/103690430994',
 'instagram': 'https://www.instagram.com/lagunacanyonspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/lagunacanyonspa/'}
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/contact-us> (referer: https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Scraped from <200 https://www.lapeauspafresno.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/lapeauspa/?fref=ts',
 'instagram': 'https://www.instagram.com/lapeauspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.cavallopoint.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/CavalloPoint',
 'instagram': 'https://www.instagram.com/cavallopoint/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/CavalloPoint'}
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['reservations@paradisepoint.com',
            'marketing@paradisepoint.com',
            'sales@paradisepoint.com',
            'weddings@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Scraped from <200 https://www.indianspringscalistoga.com/contact-us>
{'emails': ['inquiries@indianspringscalistoga.com',
            'reservations@indianspringscalistoga.com',
            'forms@tambourine.com'],
 'facebook': 'https://www.facebook.com/ISRNAPA/',
 'instagram': 'https://www.instagram.com/indianspringscalistoga/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Scraped from <200 https://glenivy.com/contact-info/>
{'emails': ['donations@glenivy.com', 'donations@glenivy.com.'],
 'facebook': 'https://www.facebook.com/GlenIvyHotSprings',
 'instagram': 'https://instagram.com/glenivy_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/GlenIvySpas'}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Crawled (200) <GET https://theravenspa.com/contact/> (referer: https://theravenspa.com/)
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['weddings@laquintaresort.com',
            'resinquiry@laquintaresort.com',
            'information@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/laquintaresort'}
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Scraped from <200 https://theravenspa.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://carmelvalleyranch.com/contact/>
{'emails': ['guestservices@carmelvalleyranch.com',
            'cvrevents@carmelvalleyranch.com',
            'cvrmembership@carmelvalleyranch.com',
            'cvrreservations@carmelvalleyranch.com',
            'cvrvalleykitchen@carmelvalleyranch.com',
            'cvrgolf@carmelvalleyranch.com',
            'cvrwedding@carmelvalleyranch.com',
            'activities@carmelvalleyranch.com',
            'cvrriverranch@carmelvalleyranch.com',
            'spa@carmelvalleyranch.com',
            'cvrclubhouse@carmelvalleyranch.com',
            'tennis@carmelvalleyranch.com'],
 'facebook': 'https://www.facebook.com/carmelvalleyranch/',
 'instagram': 'https://www.instagram.com/carmelvranch',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['tennis@ranchovalencia.com',
            'groupevents@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'spareservations@ranchovalencia.com',
            'villas@ranchovalencia.com',
            'donations@ranchovalencia.com',
            'concierge@ranchovalencia.com',
            'reservations@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Redirecting (301) to <GET https://www.ranchobernardoinn.com/contact-us/> from <GET https://www.ranchobernardoinn.com/contact-us>
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/contact-us/> (referer: https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext)
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.ranchobernardoinn.com/contact-us/>
{'emails': ['ranchobernardoinn@jcresorts.com',
            'rbiweddings@jcresorts.com',
            'rbijobs@jcresorts.com',
            'rbibilling@jcresorts.com'],
 'facebook': 'https://www.facebook.com/RBInn',
 'instagram': 'https://instagram.com/ranchobernardoinn/',
 'linkedin': 'https://www.linkedin.com/company/rancho-bernardo-inn?trk=biz-brand-tree-co-logo',
 'twitter': 'https://twitter.com/rbernardoinn'}
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': ['info@wecarespa.com'],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
DEBUG: Scraped from <200 https://www.paseahotel.com/contact/press-room>
{'emails': ['marketing@paseahotel.com',
            'frontdesk@paseahotel.com',
            'forms@tambourine.com'],
 'facebook': 'https://www.facebook.com/PaseaHotel/',
 'instagram': 'https://www.instagram.com/paseahotel/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Scraped from <200 http://www.athenaspa-mv.com/contact-us>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET https://petitespa.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/contact> (referer: https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Scraped from <200 https://www.missioninn.com/contact>
{'emails': ['reservations@missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/missioninnhotel?lang=en'}
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Scraped from <200 https://www.teahousespa.com/contact-join-our-team>
{'emails': ['reception@teahousespa.com', 'TeaHouseSpaManagement@gmail.com'],
 'facebook': 'https://www.facebook.com/theteahousespa',
 'instagram': 'https://www.instagram.com/theteahousespa/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Redirecting (301) to <GET https://oceanohalfmoonbay.com/> from <GET http://www.oceanohalfmoonbay.com/>
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Crawled (200) <GET http://metropolissalonspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb-listing&utm_content=brentwood> (referer: None)
DEBUG: Scraped from <200 https://www.romanspahotsprings.com/contact>
{'emails': ['Reservations75@Romanspahotsprings.com'],
 'facebook': 'https://www.facebook.com/romanspahotsprings',
 'instagram': 'https://www.instagram.com/romanspahotspringsresort/?ref=badge',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/romansparesort'}
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['golf@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'sales@silveradoresort.com',
            'silveradoreservations@silveradoresort.com',
            'tennis@silveradoresort.com',
            'spa@silveradoresort.com',
            'resv@silveradoresort.com',
            'info@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'loren.bates@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': ['info@wispausa.com'],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Crawled (200) <GET https://petitespa.net/contact-us-1> (referer: https://petitespa.net/)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 6587: character maps to <undefined>
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': ['reservations@miraclesprings.com',
            'catering@miraclesprings.com',
            'spa@miraclesprings.com',
            'events@miraclesprings.com'],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Scraped from <200 https://petitespa.net/contact-us-1>
{'emails': ['723petitespa@gmail.com', 'impallari@gmail.com'],
 'facebook': 'https://www.facebook.com/116067731773408',
 'instagram': 'https://www.instagram.com/petitespa',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.estancialajolla.com/contact/>
{'emails': ['events@estancialajolla.com',
            'rsv@estancialajolla.com',
            'bookzoe@noblehousehotels.com',
            'spa@estancialajolla.com',
            'sales@estancialajolla.com',
            'EstanciaConcierge@EstanciaLaJolla.com',
            'elj@20twostudio.com'],
 'facebook': 'https://www.facebook.com/EstanciaLaJolla/',
 'instagram': 'https://www.instagram.com/estancialajolla/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://mysheerbliss.com/pages/contact-us-spa-policy>
{'emails': ['glow@mysheerbliss.com', 'info@mysheerbliss.com'],
 'facebook': 'https://www.facebook.com/fresnoorganicspa/',
 'instagram': 'https://www.instagram.com/sheerblissspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/> (referer: None)
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
DEBUG: Crawled (200) <GET https://paradisepoint.com/?utm_source=google-local&utm_medium=organic&utm_campaign=gmb> (referer: None)
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Scraped from <200 https://harbin.org/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/harbinhotsprings',
 'instagram': 'https://www.instagram.com/harbin_hot_springs/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (451) <GET https://www.morongocasinoresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://oceanohalfmoonbay.com/contact/> (referer: https://oceanohalfmoonbay.com/)
INFO: Ignoring response <451 https://www.morongocasinoresort.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Scraped from <200 https://oceanohalfmoonbay.com/contact/>
{'emails': ['admin@oceanohalfmoonbay.com'],
 'facebook': 'https://www.facebook.com/oceanohotelspa/',
 'instagram': 'https://www.instagram.com/oceanohotelspa/?ref=badge',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': ['reception@senspa.com'],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': ['reservations@miraclesprings.com',
            'catering@miraclesprings.com',
            'spa@miraclesprings.com',
            'events@miraclesprings.com'],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/?utm_source=google-local&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': ['reception@senspa.com'],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['reservations@paradisepoint.com',
            'marketing@paradisepoint.com',
            'sales@paradisepoint.com',
            'weddings@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Scraped from <200 https://www.bardessono.com/contact.htm>
{'emails': [],
 'facebook': 'https://www.facebook.com/bardessonohotelspa/',
 'instagram': 'https://www.instagram.com/bardessonoyountville/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BardessonoHotel'}
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ventanabigsur.com/spa/overview> (referer: None)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ventanabigsur.com/contact-us> (referer: https://www.ventanabigsur.com/spa/overview)
DEBUG: Crawled (200) <GET https://www.macarthurplace.com/contact/> (referer: https://www.macarthurplace.com/)
DEBUG: Scraped from <200 https://www.ventanabigsur.com/contact-us>
{'emails': ['ventanaconcierge@ventanabigsur.com',
            'reservations@ventanabigsur.com'],
 'facebook': 'https://www.facebook.com/AlilaVentanaBigSur/',
 'instagram': 'https://www.instagram.com/ventanabigsur/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ventanabigsur'}
DEBUG: Scraped from <200 https://www.macarthurplace.com/contact/>
{'emails': ['press@macarthurplace.com', 'info@macarthurplace.com'],
 'facebook': 'https://www.facebook.com/MacArthurPlaceHotelandSpa/',
 'instagram': 'https://instagram.com/macarthurplace/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/macarthurplace'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 57294,
 'downloader/request_count': 199,
 'downloader/request_method_count/GET': 199,
 'downloader/response_bytes': 6542344,
 'downloader/response_count': 199,
 'downloader/response_status_count/200': 134,
 'downloader/response_status_count/301': 52,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 6,
 'downloader/response_status_count/451': 1,
 'downloader/response_status_count/502': 3,
 'elapsed_time_seconds': 14.134807,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 38, 42, 218173),
 'httpcompression/response_bytes': 24965378,
 'httpcompression/response_count': 136,
 'httperror/response_ignored_count': 7,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 2,
 'httperror/response_ignored_status_count/451': 1,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 56,
 'log_count/DEBUG': 262,
 'log_count/ERROR': 4,
 'log_count/INFO': 17,
 'request_depth_max': 1,
 'response_received_count': 141,
 'retry/count': 6,
 'retry/max_reached': 3,
 'retry/reason_count/429 Unknown Status': 4,
 'retry/reason_count/502 Bad Gateway': 2,
 'scheduler/dequeued': 199,
 'scheduler/dequeued/memory': 199,
 'scheduler/enqueued': 199,
 'scheduler/enqueued/memory': 199,
 'start_time': datetime.datetime(2022, 12, 9, 15, 38, 28, 83366)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 496517baa2fd06db
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Attempting to acquire lock 2539648005648 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2539648005648 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2539648005648 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2539648005648 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': ['guestservices@goldendoor.com',
            'molly@thestoriedgroup.com',
            'shop@goldendoor.com',
            'guestservices@goldendoor.com.'],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Scraped from <200 https://www.kellysspa.com/contact-location>
{'emails': ['SpaDirector@Missioninn.com', 'spadirector@missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn',
 'instagram': 'https://www.instagram.com/kellys_spa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Scraped from <200 https://www.fourseasons.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/FourSeasons',
 'instagram': 'https://www.instagram.com/fourseasons/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FourSeasons'}
DEBUG: Scraped from <200 https://cadayspa.com/contact-us>
{'emails': ['team@latofonts.com',
            'impallari@gmail.com',
            'filler@godaddy.com',
            'ron@cadayspa.com'],
 'facebook': 'https://www.facebook.com/californiadayspa',
 'instagram': 'https://www.instagram.com/cadayspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/califadayspa'}
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': ['cavinfo@cal-a-vie.com'],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/calaviespa'}
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Scraped from <200 https://www.osmosis.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/OsmosisDaySpaSanctuary',
 'instagram': 'https://www.instagram.com/osmosisdayspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/osmosisspa'}
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['spa@purpleorchid.com',
            'rhiannon@purpleorchid.com',
            'info@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['silveradodining@silveradoresort.com',
            'tennis@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'golf@silveradoresort.com',
            'spa@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'resv@silveradoresort.com',
            'info@silveradoresort.com',
            'sales@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Scraped from <200 https://www.urbanretreatspa.com/contact>
{'emails': ['contact@urbanretreatspa.com'],
 'facebook': 'https://www.facebook.com/pages/Urban-Retreat-Day-Spa/69993009232?ref=hl',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/URDaySpa'}
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
DEBUG: Scraped from <200 https://www.aubergeresorts.com/solage/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SolageResort/',
 'instagram': 'https://www.instagram.com/solageauberge/?hl=en',
 'linkedin': 'https://www.linkedin.com/company/auberge-resorts/',
 'twitter': 'https://twitter.com/solageauberge'}
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://montereyplazahotel.com/hotel/contact>
{'emails': ['coastalcurator@montereyplazahotel.com',
            'sales@montereyplazahotel.com',
            'weddings@montereyplazahotel.com',
            'forms@tambourine.com',
            'housekeeping@montereyplazahotel.com'],
 'facebook': 'https://www.facebook.com/montereyplazahotel',
 'instagram': 'https://www.instagram.com/montereyplaza/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Scraped from <200 https://www.terranea.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/Terranea',
 'instagram': 'http://instagram.com/terranearesort',
 'linkedin': 'https://www.linkedin.com/company/terranea-resort',
 'twitter': 'https://twitter.com/TerraneaResort'}
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Scraped from <200 https://boonhotels.com/contact/>
{'emails': ['info@boonhotels.com'],
 'facebook': 'http://www.facebook.com/boonhotelspa',
 'instagram': 'https://www.instagram.com/boonhotelspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/boonhotelspa'}
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Scraped from <200 https://thesisleyspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SisleySpaUSA/',
 'instagram': 'https://www.instagram.com/sisleyspausa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Scraped from <200 https://www.canyonranch.com/contact-us/>
{'emails': ['Lenox-Sales@canyonranch.com',
            'Tucson-Sales@canyonranch.com',
            'lchesloff@williampitt.com',
            'gmontgomery@williampitt.com',
            'media@canyonranch.com',
            'Las-Vegas-Sales@canyonranch.com',
            'jzimmermann@canyonranch.com',
            'Woodside-Sales@canyonranch.com',
            'nikki.field@sothebyshomes.com'],
 'facebook': 'https://www.facebook.com/CanyonRanch',
 'instagram': 'https://www.instagram.com/canyonranch/',
 'linkedin': 'https://www.linkedin.com/company/canyon-ranch',
 'twitter': 'https://twitter.com/CanyonRanch'}
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Scraped from <200 https://lagunacanyonspa.com/contact-us>
{'emails': ['impallari@gmail.com',
            'filler@godaddy.com',
            'info@ndiscovered.com',
            'hello@rfuenzalida.com'],
 'facebook': 'https://www.facebook.com/103690430994',
 'instagram': 'https://www.instagram.com/lagunacanyonspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/lagunacanyonspa/'}
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.lapeauspafresno.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/lapeauspa/?fref=ts',
 'instagram': 'https://www.instagram.com/lapeauspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['villas@ranchovalencia.com',
            'concierge@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'tennis@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['marketing@paradisepoint.com',
            'weddings@paradisepoint.com',
            'sales@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Scraped from <200 https://www.indianspringscalistoga.com/contact-us>
{'emails': ['forms@tambourine.com', 'inquiries@indianspringscalistoga.com'],
 'facebook': 'https://www.facebook.com/ISRNAPA/',
 'instagram': 'https://www.instagram.com/indianspringscalistoga/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://glenivy.com/contact-info/>
{'emails': [],
 'facebook': 'https://www.facebook.com/GlenIvyHotSprings',
 'instagram': 'https://instagram.com/glenivy_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/GlenIvySpas'}
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Scraped from <200 https://carmelvalleyranch.com/contact/>
{'emails': ['tennis@carmelvalleyranch.com',
            'cvrgolf@carmelvalleyranch.com',
            'spa@carmelvalleyranch.com',
            'cvrmembership@carmelvalleyranch.com',
            'cvrwedding@carmelvalleyranch.com',
            'guestservices@carmelvalleyranch.com',
            'cvrvalleykitchen@carmelvalleyranch.com',
            'cvrriverranch@carmelvalleyranch.com',
            'cvrclubhouse@carmelvalleyranch.com'],
 'facebook': 'https://www.facebook.com/carmelvalleyranch/',
 'instagram': 'https://www.instagram.com/carmelvranch',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchobernardoinn.com/contact-us/> from <GET https://www.ranchobernardoinn.com/contact-us>
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/contact-us> (referer: https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Scraped from <200 https://www.cavallopoint.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/CavalloPoint',
 'instagram': 'https://www.instagram.com/cavallopoint/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/CavalloPoint'}
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Crawled (200) <GET https://theravenspa.com/contact/> (referer: https://theravenspa.com/)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Scraped from <200 https://theravenspa.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 6308: character maps to <undefined>
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': ['info@wispausa.com'],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': ['info@wecarespa.com'],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Scraped from <200 https://www.missioninn.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/TheMissionInn/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/missioninnhotel?lang=en'}
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/contact-us/> (referer: https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['weddings@laquintaresort.com',
            'resinquiry@laquintaresort.com',
            'information@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/laquintaresort'}
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://www.ranchobernardoinn.com/contact-us/>
{'emails': ['ranchobernardoinn@jcresorts.com',
            'rbibilling@jcresorts.com',
            'rbiweddings@jcresorts.com',
            'rbijobs@jcresorts.com'],
 'facebook': 'https://www.facebook.com/RBInn',
 'instagram': 'https://instagram.com/ranchobernardoinn/',
 'linkedin': 'https://www.linkedin.com/company/rancho-bernardo-inn?trk=biz-brand-tree-co-logo',
 'twitter': 'https://twitter.com/rbernardoinn'}
DEBUG: Scraped from <200 https://www.teahousespa.com/contact-join-our-team>
{'emails': ['reception@teahousespa.com', 'TeaHouseSpaManagement@gmail.com'],
 'facebook': 'https://www.facebook.com/theteahousespa',
 'instagram': 'https://www.instagram.com/theteahousespa/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Scraped from <200 https://www.paseahotel.com/contact/press-room>
{'emails': ['frontdesk@paseahotel.com',
            'marketing@paseahotel.com',
            'forms@tambourine.com'],
 'facebook': 'https://www.facebook.com/PaseaHotel/',
 'instagram': 'https://www.instagram.com/paseahotel/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.estancialajolla.com/contact/>
{'emails': ['rsv@estancialajolla.com',
            'elj@20twostudio.com',
            'bookzoe@noblehousehotels.com',
            'sales@estancialajolla.com',
            'EstanciaConcierge@EstanciaLaJolla.com',
            'spa@estancialajolla.com'],
 'facebook': 'https://www.facebook.com/EstanciaLaJolla/',
 'instagram': 'https://www.instagram.com/estancialajolla/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Scraped from <200 http://www.athenaspa-mv.com/contact-us>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Scraped from <200 https://mysheerbliss.com/pages/contact-us-spa-policy>
{'emails': ['info@mysheerbliss.com', 'glow@mysheerbliss.com'],
 'facebook': 'https://www.facebook.com/fresnoorganicspa/',
 'instagram': 'https://www.instagram.com/sheerblissspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['villas@ranchovalencia.com',
            'concierge@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'tennis@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
DEBUG: Scraped from <200 https://harbin.org/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/harbinhotsprings',
 'instagram': 'https://www.instagram.com/harbin_hot_springs/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Scraped from <200 https://www.bardessono.com/contact.htm>
{'emails': [],
 'facebook': 'https://www.facebook.com/bardessonohotelspa/',
 'instagram': 'https://www.instagram.com/bardessonoyountville/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BardessonoHotel'}
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['silveradodining@silveradoresort.com',
            'tennis@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'golf@silveradoresort.com',
            'spa@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'resv@silveradoresort.com',
            'info@silveradoresort.com',
            'sales@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': ['catering@miraclesprings.com', 'spa@miraclesprings.com'],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 47610,
 'downloader/request_count': 165,
 'downloader/request_method_count/GET': 165,
 'downloader/response_bytes': 5782204,
 'downloader/response_count': 165,
 'downloader/response_status_count/200': 111,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 3,
 'downloader/response_status_count/502': 3,
 'elapsed_time_seconds': 14.067155,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 15, 41, 16, 867077),
 'httpcompression/response_bytes': 19827499,
 'httpcompression/response_count': 111,
 'httperror/response_ignored_count': 5,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 47,
 'log_count/DEBUG': 219,
 'log_count/ERROR': 3,
 'log_count/INFO': 15,
 'request_depth_max': 1,
 'response_received_count': 116,
 'retry/count': 4,
 'retry/max_reached': 2,
 'retry/reason_count/429 Unknown Status': 2,
 'retry/reason_count/502 Bad Gateway': 2,
 'scheduler/dequeued': 165,
 'scheduler/dequeued/memory': 165,
 'scheduler/enqueued': 165,
 'scheduler/enqueued/memory': 165,
 'start_time': datetime.datetime(2022, 12, 9, 15, 41, 2, 799922)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 19ba4c8d6cd3294d
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2032380068624 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2032380068624 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2032380068624 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2032380068624 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://theravenspa.com/contact/> (referer: https://theravenspa.com/)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/contact-us> (referer: https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchobernardoinn.com/contact-us/> from <GET https://www.ranchobernardoinn.com/contact-us>
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/contact-us/> (referer: https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 6185: character maps to <undefined>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/contact> (referer: https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb-listing&utm_content=brentwood> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 50316,
 'downloader/request_count': 174,
 'downloader/request_method_count/GET': 174,
 'downloader/response_bytes': 5862857,
 'downloader/response_count': 174,
 'downloader/response_status_count/200': 118,
 'downloader/response_status_count/301': 47,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 3,
 'downloader/response_status_count/502': 3,
 'elapsed_time_seconds': 14.678753,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 16, 36, 55, 880828),
 'httpcompression/response_bytes': 19821310,
 'httpcompression/response_count': 118,
 'httperror/response_ignored_count': 5,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'httperror/response_ignored_status_count/502': 1,
 'log_count/DEBUG': 181,
 'log_count/ERROR': 3,
 'log_count/INFO': 15,
 'request_depth_max': 1,
 'response_received_count': 123,
 'retry/count': 4,
 'retry/max_reached': 2,
 'retry/reason_count/429 Unknown Status': 2,
 'retry/reason_count/502 Bad Gateway': 2,
 'scheduler/dequeued': 174,
 'scheduler/dequeued/memory': 174,
 'scheduler/enqueued': 174,
 'scheduler/enqueued/memory': 174,
 'start_time': datetime.datetime(2022, 12, 9, 16, 36, 41, 202075)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 324624d6c81de3d7
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Attempting to acquire lock 1949319293216 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1949319293216 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1949319293216 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1949319293216 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Scraped from <200 https://www.kellysspa.com/contact-location>
{'emails': ['spadirector@missioninn.com', 'SpaDirector@Missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn',
 'instagram': 'https://www.instagram.com/kellys_spa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Scraped from <200 https://www.fourseasons.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/FourSeasons',
 'instagram': 'https://www.instagram.com/fourseasons/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FourSeasons'}
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': ['molly@thestoriedgroup.com',
            'shop@goldendoor.com',
            'guestservices@goldendoor.com.',
            'guestservices@goldendoor.com'],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Scraped from <200 https://cadayspa.com/contact-us>
{'emails': ['impallari@gmail.com',
            'team@latofonts.com',
            'ron@cadayspa.com',
            'filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/californiadayspa',
 'instagram': 'https://www.instagram.com/cadayspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/califadayspa'}
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': ['cavinfo@cal-a-vie.com'],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/calaviespa'}
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Scraped from <200 https://www.osmosis.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/OsmosisDaySpaSanctuary',
 'instagram': 'https://www.instagram.com/osmosisdayspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/osmosisspa'}
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['spa@purpleorchid.com',
            'rhiannon@purpleorchid.com',
            'info@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
DEBUG: Scraped from <200 https://www.urbanretreatspa.com/contact>
{'emails': ['contact@urbanretreatspa.com'],
 'facebook': 'https://www.facebook.com/pages/Urban-Retreat-Day-Spa/69993009232?ref=hl',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/URDaySpa'}
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Scraped from <200 https://www.aubergeresorts.com/solage/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SolageResort/',
 'instagram': 'https://www.instagram.com/solageauberge/?hl=en',
 'linkedin': 'https://www.linkedin.com/company/auberge-resorts/',
 'twitter': 'https://twitter.com/solageauberge'}
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://www.terranea.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/Terranea',
 'instagram': 'http://instagram.com/terranearesort',
 'linkedin': 'https://www.linkedin.com/company/terranea-resort',
 'twitter': 'https://twitter.com/TerraneaResort'}
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Scraped from <200 https://thesisleyspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SisleySpaUSA/',
 'instagram': 'https://www.instagram.com/sisleyspausa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://boonhotels.com/contact/>
{'emails': ['info@boonhotels.com'],
 'facebook': 'http://www.facebook.com/boonhotelspa',
 'instagram': 'https://www.instagram.com/boonhotelspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/boonhotelspa'}
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['jeff.vanparis@silveradoresort.com',
            'tennis@silveradoresort.com',
            'info@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'spa@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'golf@silveradoresort.com',
            'sales@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'resv@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['villas@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'concierge@ranchovalencia.com',
            'tennis@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Scraped from <200 https://lagunacanyonspa.com/contact-us>
{'emails': ['info@ndiscovered.com',
            'impallari@gmail.com',
            'hello@rfuenzalida.com',
            'filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/103690430994',
 'instagram': 'https://www.instagram.com/lagunacanyonspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/lagunacanyonspa/'}
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Scraped from <200 https://www.canyonranch.com/contact-us/>
{'emails': ['Woodside-Sales@canyonranch.com',
            'media@canyonranch.com',
            'Lenox-Sales@canyonranch.com',
            'gmontgomery@williampitt.com',
            'Tucson-Sales@canyonranch.com',
            'lchesloff@williampitt.com',
            'jzimmermann@canyonranch.com',
            'Las-Vegas-Sales@canyonranch.com',
            'nikki.field@sothebyshomes.com'],
 'facebook': 'https://www.facebook.com/CanyonRanch',
 'instagram': 'https://www.instagram.com/canyonranch/',
 'linkedin': 'https://www.linkedin.com/company/canyon-ranch',
 'twitter': 'https://twitter.com/CanyonRanch'}
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Scraped from <200 https://montereyplazahotel.com/hotel/contact>
{'emails': ['coastalcurator@montereyplazahotel.com',
            'sales@montereyplazahotel.com',
            'forms@tambourine.com',
            'housekeeping@montereyplazahotel.com',
            'weddings@montereyplazahotel.com'],
 'facebook': 'https://www.facebook.com/montereyplazahotel',
 'instagram': 'https://www.instagram.com/montereyplaza/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.lapeauspafresno.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/lapeauspa/?fref=ts',
 'instagram': 'https://www.instagram.com/lapeauspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Scraped from <200 https://www.indianspringscalistoga.com/contact-us>
{'emails': ['forms@tambourine.com', 'inquiries@indianspringscalistoga.com'],
 'facebook': 'https://www.facebook.com/ISRNAPA/',
 'instagram': 'https://www.instagram.com/indianspringscalistoga/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['marketing@paradisepoint.com',
            'sales@paradisepoint.com',
            'weddings@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/contact-us> (referer: https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb)
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Scraped from <200 https://www.cavallopoint.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/CavalloPoint',
 'instagram': 'https://www.instagram.com/cavallopoint/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/CavalloPoint'}
DEBUG: Scraped from <200 https://glenivy.com/contact-info/>
{'emails': [],
 'facebook': 'https://www.facebook.com/GlenIvyHotSprings',
 'instagram': 'https://instagram.com/glenivy_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/GlenIvySpas'}
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': ['info@wispausa.com'],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.ranchobernardoinn.com/contact-us/> from <GET https://www.ranchobernardoinn.com/contact-us>
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Crawled (200) <GET https://theravenspa.com/contact/> (referer: https://theravenspa.com/)
DEBUG: Scraped from <200 https://carmelvalleyranch.com/contact/>
{'emails': ['guestservices@carmelvalleyranch.com',
            'cvrvalleykitchen@carmelvalleyranch.com',
            'cvrgolf@carmelvalleyranch.com',
            'tennis@carmelvalleyranch.com',
            'cvrclubhouse@carmelvalleyranch.com',
            'spa@carmelvalleyranch.com',
            'cvrwedding@carmelvalleyranch.com',
            'cvrriverranch@carmelvalleyranch.com',
            'cvrmembership@carmelvalleyranch.com'],
 'facebook': 'https://www.facebook.com/carmelvalleyranch/',
 'instagram': 'https://www.instagram.com/carmelvranch',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/contact-us/> (referer: https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Scraped from <200 https://theravenspa.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 7052: character maps to <undefined>
DEBUG: Scraped from <200 http://www.athenaspa-mv.com/contact-us>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['villas@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'concierge@ranchovalencia.com',
            'tennis@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': ['info@wecarespa.com'],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': ['spa@miraclesprings.com', 'catering@miraclesprings.com'],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Scraped from <200 https://www.ranchobernardoinn.com/contact-us/>
{'emails': ['rbijobs@jcresorts.com',
            'rbibilling@jcresorts.com',
            'rbiweddings@jcresorts.com',
            'ranchobernardoinn@jcresorts.com'],
 'facebook': 'https://www.facebook.com/RBInn',
 'instagram': 'https://instagram.com/ranchobernardoinn/',
 'linkedin': 'https://www.linkedin.com/company/rancho-bernardo-inn?trk=biz-brand-tree-co-logo',
 'twitter': 'https://twitter.com/rbernardoinn'}
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Scraped from <200 https://www.missioninn.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/TheMissionInn/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/missioninnhotel?lang=en'}
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['weddings@laquintaresort.com',
            'resinquiry@laquintaresort.com',
            'information@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/laquintaresort'}
DEBUG: Crawled (200) <GET https://www.romanspahotsprings.com/contact> (referer: https://www.romanspahotsprings.com/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Scraped from <200 https://www.romanspahotsprings.com/contact>
{'emails': ['Reservations75@Romanspahotsprings.com'],
 'facebook': 'https://www.facebook.com/romanspahotsprings',
 'instagram': 'https://www.instagram.com/romanspahotspringsresort/?ref=badge',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/romansparesort'}
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Redirecting (301) to <GET https://www.senspa.com/> from <GET http://www.senspa.com/>
DEBUG: Scraped from <200 https://www.teahousespa.com/contact-join-our-team>
{'emails': ['TeaHouseSpaManagement@gmail.com', 'reception@teahousespa.com'],
 'facebook': 'https://www.facebook.com/theteahousespa',
 'instagram': 'https://www.instagram.com/theteahousespa/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 1 times): 502 Bad Gateway
DEBUG: Scraped from <200 https://www.estancialajolla.com/contact/>
{'emails': ['rsv@estancialajolla.com',
            'sales@estancialajolla.com',
            'bookzoe@noblehousehotels.com',
            'elj@20twostudio.com',
            'EstanciaConcierge@EstanciaLaJolla.com',
            'spa@estancialajolla.com'],
 'facebook': 'https://www.facebook.com/EstanciaLaJolla/',
 'instagram': 'https://www.instagram.com/estancialajolla/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 2 times): 502 Bad Gateway
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Scraped from <200 https://mysheerbliss.com/pages/contact-us-spa-policy>
{'emails': ['glow@mysheerbliss.com', 'info@mysheerbliss.com'],
 'facebook': 'https://www.facebook.com/fresnoorganicspa/',
 'instagram': 'https://www.instagram.com/sheerblissspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
ERROR: Gave up retrying <GET https://www.shuttersonthebeach.com/spa/one-spa> (failed 3 times): 502 Bad Gateway
DEBUG: Crawled (502) <GET https://www.shuttersonthebeach.com/spa/one-spa> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
INFO: Ignoring response <502 https://www.shuttersonthebeach.com/spa/one-spa>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['jeff.vanparis@silveradoresort.com',
            'tennis@silveradoresort.com',
            'info@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'spa@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'golf@silveradoresort.com',
            'sales@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'resv@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Crawled (200) <GET https://milkandhoneyspa.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb-listing&utm_content=brentwood> (referer: None)
DEBUG: Scraped from <200 https://harbin.org/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/harbinhotsprings',
 'instagram': 'https://www.instagram.com/harbin_hot_springs/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.senspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Scraped from <200 https://www.paseahotel.com/contact/press-room>
{'emails': ['forms@tambourine.com',
            'frontdesk@paseahotel.com',
            'marketing@paseahotel.com'],
 'facebook': 'https://www.facebook.com/PaseaHotel/',
 'instagram': 'https://www.instagram.com/paseahotel/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': ['reception@senspa.com'],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Scraped from <200 https://www.bardessono.com/contact.htm>
{'emails': [],
 'facebook': 'https://www.facebook.com/bardessonohotelspa/',
 'instagram': 'https://www.instagram.com/bardessonoyountville/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BardessonoHotel'}
DEBUG: Crawled (200) <GET https://www.senspa.com/contact> (referer: https://www.senspa.com/)
DEBUG: Scraped from <200 https://www.senspa.com/contact>
{'emails': ['reception@senspa.com'],
 'facebook': 'https://www.facebook.com/senspasf/',
 'instagram': 'http://instagram.com/senspasf',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SenSpa'}
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 50244,
 'downloader/request_count': 174,
 'downloader/request_method_count/GET': 174,
 'downloader/response_bytes': 5916405,
 'downloader/response_count': 174,
 'downloader/response_status_count/200': 118,
 'downloader/response_status_count/301': 47,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 3,
 'downloader/response_status_count/502': 3,
 'elapsed_time_seconds': 12.36165,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 16, 37, 22, 330298),
 'httpcompression/response_bytes': 20374932,
 'httpcompression/response_count': 118,
 'httperror/response_ignored_count': 5,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 50,
 'log_count/DEBUG': 231,
 'log_count/ERROR': 3,
 'log_count/INFO': 15,
 'request_depth_max': 1,
 'response_received_count': 123,
 'retry/count': 4,
 'retry/max_reached': 2,
 'retry/reason_count/429 Unknown Status': 2,
 'retry/reason_count/502 Bad Gateway': 2,
 'scheduler/dequeued': 174,
 'scheduler/dequeued/memory': 174,
 'scheduler/enqueued': 174,
 'scheduler/enqueued/memory': 174,
 'start_time': datetime.datetime(2022, 12, 9, 16, 37, 9, 968648)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: dba863023c6085e3
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Attempting to acquire lock 2138201973872 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2138201973872 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2138201973872 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2138201973872 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Scraped from <200 https://cadayspa.com/contact-us>
{'emails': ['team@latofonts.com',
            'filler@godaddy.com',
            'ron@cadayspa.com',
            'impallari@gmail.com'],
 'facebook': 'https://www.facebook.com/californiadayspa',
 'instagram': 'https://www.instagram.com/cadayspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/califadayspa'}
DEBUG: Scraped from <200 https://www.kellysspa.com/contact-location>
{'emails': ['SpaDirector@Missioninn.com', 'spadirector@missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn',
 'instagram': 'https://www.instagram.com/kellys_spa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': ['molly@thestoriedgroup.com',
            'guestservices@goldendoor.com.',
            'guestservices@goldendoor.com',
            'shop@goldendoor.com'],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': ['cavinfo@cal-a-vie.com'],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/calaviespa'}
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Scraped from <200 https://www.fourseasons.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/FourSeasons',
 'instagram': 'https://www.instagram.com/fourseasons/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FourSeasons'}
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['rhiannon@purpleorchid.com',
            'info@purpleorchid.com',
            'spa@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Scraped from <200 https://www.osmosis.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/OsmosisDaySpaSanctuary',
 'instagram': 'https://www.instagram.com/osmosisdayspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/osmosisspa'}
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Scraped from <200 https://www.aubergeresorts.com/solage/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SolageResort/',
 'instagram': 'https://www.instagram.com/solageauberge/?hl=en',
 'linkedin': 'https://www.linkedin.com/company/auberge-resorts/',
 'twitter': 'https://twitter.com/solageauberge'}
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Scraped from <200 https://montereyplazahotel.com/hotel/contact>
{'emails': ['housekeeping@montereyplazahotel.com',
            'coastalcurator@montereyplazahotel.com',
            'weddings@montereyplazahotel.com',
            'sales@montereyplazahotel.com',
            'forms@tambourine.com'],
 'facebook': 'https://www.facebook.com/montereyplazahotel',
 'instagram': 'https://www.instagram.com/montereyplaza/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Scraped from <200 https://www.terranea.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/Terranea',
 'instagram': 'http://instagram.com/terranearesort',
 'linkedin': 'https://www.linkedin.com/company/terranea-resort',
 'twitter': 'https://twitter.com/TerraneaResort'}
DEBUG: Scraped from <200 https://www.urbanretreatspa.com/contact>
{'emails': ['contact@urbanretreatspa.com'],
 'facebook': 'https://www.facebook.com/pages/Urban-Retreat-Day-Spa/69993009232?ref=hl',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/URDaySpa'}
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['tennis@silveradoresort.com',
            'sales@silveradoresort.com',
            'spa@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'info@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'resv@silveradoresort.com',
            'golf@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://boonhotels.com/contact/>
{'emails': ['info@boonhotels.com'],
 'facebook': 'http://www.facebook.com/boonhotelspa',
 'instagram': 'https://www.instagram.com/boonhotelspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/boonhotelspa'}
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Scraped from <200 https://thesisleyspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SisleySpaUSA/',
 'instagram': 'https://www.instagram.com/sisleyspausa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Scraped from <200 https://lagunacanyonspa.com/contact-us>
{'emails': ['filler@godaddy.com',
            'info@ndiscovered.com',
            'impallari@gmail.com',
            'hello@rfuenzalida.com'],
 'facebook': 'https://www.facebook.com/103690430994',
 'instagram': 'https://www.instagram.com/lagunacanyonspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/lagunacanyonspa/'}
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['concierge@ranchovalencia.com',
            'villas@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'tennis@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Scraped from <200 https://www.canyonranch.com/contact-us/>
{'emails': ['Woodside-Sales@canyonranch.com',
            'media@canyonranch.com',
            'Lenox-Sales@canyonranch.com',
            'lchesloff@williampitt.com',
            'jzimmermann@canyonranch.com',
            'nikki.field@sothebyshomes.com',
            'Tucson-Sales@canyonranch.com',
            'Las-Vegas-Sales@canyonranch.com',
            'gmontgomery@williampitt.com'],
 'facebook': 'https://www.facebook.com/CanyonRanch',
 'instagram': 'https://www.instagram.com/canyonranch/',
 'linkedin': 'https://www.linkedin.com/company/canyon-ranch',
 'twitter': 'https://twitter.com/CanyonRanch'}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/contact-us> (referer: https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['weddings@paradisepoint.com',
            'marketing@paradisepoint.com',
            'sales@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Scraped from <200 https://www.cavallopoint.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/CavalloPoint',
 'instagram': 'https://www.instagram.com/cavallopoint/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/CavalloPoint'}
DEBUG: Scraped from <200 https://www.lapeauspafresno.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/lapeauspa/?fref=ts',
 'instagram': 'https://www.instagram.com/lapeauspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': ['info@wispausa.com'],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://theravenspa.com/contact/> (referer: https://theravenspa.com/)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Scraped from <200 https://glenivy.com/contact-info/>
{'emails': [],
 'facebook': 'https://www.facebook.com/GlenIvyHotSprings',
 'instagram': 'https://instagram.com/glenivy_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/GlenIvySpas'}
DEBUG: Scraped from <200 https://theravenspa.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.indianspringscalistoga.com/contact-us>
{'emails': ['inquiries@indianspringscalistoga.com', 'forms@tambourine.com'],
 'facebook': 'https://www.facebook.com/ISRNAPA/',
 'instagram': 'https://www.instagram.com/indianspringscalistoga/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': ['info@wecarespa.com'],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['resinquiry@laquintaresort.com',
            'information@laquintaresort.com',
            'weddings@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/laquintaresort'}
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 7781: character maps to <undefined>
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchobernardoinn.com/contact-us/> from <GET https://www.ranchobernardoinn.com/contact-us>
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Scraped from <200 https://carmelvalleyranch.com/contact/>
{'emails': ['cvrvalleykitchen@carmelvalleyranch.com',
            'cvrgolf@carmelvalleyranch.com',
            'tennis@carmelvalleyranch.com',
            'cvrwedding@carmelvalleyranch.com',
            'cvrclubhouse@carmelvalleyranch.com',
            'cvrriverranch@carmelvalleyranch.com',
            'cvrmembership@carmelvalleyranch.com',
            'guestservices@carmelvalleyranch.com',
            'spa@carmelvalleyranch.com'],
 'facebook': 'https://www.facebook.com/carmelvalleyranch/',
 'instagram': 'https://www.instagram.com/carmelvranch',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/contact-us/> (referer: https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['concierge@ranchovalencia.com',
            'villas@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'tennis@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
DEBUG: Scraped from <200 https://www.ranchobernardoinn.com/contact-us/>
{'emails': ['rbibilling@jcresorts.com',
            'rbijobs@jcresorts.com',
            'rbiweddings@jcresorts.com',
            'ranchobernardoinn@jcresorts.com'],
 'facebook': 'https://www.facebook.com/RBInn',
 'instagram': 'https://instagram.com/ranchobernardoinn/',
 'linkedin': 'https://www.linkedin.com/company/rancho-bernardo-inn?trk=biz-brand-tree-co-logo',
 'twitter': 'https://twitter.com/rbernardoinn'}
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.missioninn.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/TheMissionInn/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/missioninnhotel?lang=en'}
DEBUG: Scraped from <200 http://www.athenaspa-mv.com/contact-us>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://mysheerbliss.com/pages/contact-us-spa-policy>
{'emails': ['info@mysheerbliss.com', 'glow@mysheerbliss.com'],
 'facebook': 'https://www.facebook.com/fresnoorganicspa/',
 'instagram': 'https://www.instagram.com/sheerblissspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://harbin.org/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/harbinhotsprings',
 'instagram': 'https://www.instagram.com/harbin_hot_springs/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Scraped from <200 https://www.estancialajolla.com/contact/>
{'emails': ['elj@20twostudio.com',
            'spa@estancialajolla.com',
            'bookzoe@noblehousehotels.com',
            'rsv@estancialajolla.com',
            'sales@estancialajolla.com',
            'EstanciaConcierge@EstanciaLaJolla.com'],
 'facebook': 'https://www.facebook.com/EstanciaLaJolla/',
 'instagram': 'https://www.instagram.com/estancialajolla/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.teahousespa.com/contact-join-our-team>
{'emails': ['reception@teahousespa.com', 'TeaHouseSpaManagement@gmail.com'],
 'facebook': 'https://www.facebook.com/theteahousespa',
 'instagram': 'https://www.instagram.com/theteahousespa/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': ['catering@miraclesprings.com', 'spa@miraclesprings.com'],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Scraped from <200 https://www.bardessono.com/contact.htm>
{'emails': [],
 'facebook': 'https://www.facebook.com/bardessonohotelspa/',
 'instagram': 'https://www.instagram.com/bardessonoyountville/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BardessonoHotel'}
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['tennis@silveradoresort.com',
            'sales@silveradoresort.com',
            'spa@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'info@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'resv@silveradoresort.com',
            'golf@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://www.paseahotel.com/contact/press-room>
{'emails': ['forms@tambourine.com',
            'marketing@paseahotel.com',
            'frontdesk@paseahotel.com'],
 'facebook': 'https://www.facebook.com/PaseaHotel/',
 'instagram': 'https://www.instagram.com/paseahotel/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 46903,
 'downloader/request_count': 162,
 'downloader/request_method_count/GET': 162,
 'downloader/response_bytes': 5803258,
 'downloader/response_count': 162,
 'downloader/response_status_count/200': 111,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 3,
 'elapsed_time_seconds': 16.5309,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 16, 38, 30, 985091),
 'httpcompression/response_bytes': 19915901,
 'httpcompression/response_count': 111,
 'httperror/response_ignored_count': 4,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'item_scraped_count': 47,
 'log_count/DEBUG': 216,
 'log_count/ERROR': 2,
 'log_count/INFO': 14,
 'request_depth_max': 1,
 'response_received_count': 115,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/429 Unknown Status': 2,
 'scheduler/dequeued': 162,
 'scheduler/dequeued/memory': 162,
 'scheduler/enqueued': 162,
 'scheduler/enqueued/memory': 162,
 'start_time': datetime.datetime(2022, 12, 9, 16, 38, 14, 454191)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 20872f6c95403dc3
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 31, in start_requests
    with open("data.csv") as csvfile: #read out data from .csv file and go through each link positioned in 2nd row
FileNotFoundError: [Errno 2] No such file or directory: 'data.csv'
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.004,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 18, 43, 23, 950865),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'start_time': datetime.datetime(2022, 12, 9, 18, 43, 23, 946865)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 4cf4f6a6cfde7789
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Attempting to acquire lock 2203508364080 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2203508364080 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2203508364080 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2203508364080 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/contact-us> (referer: https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://theravenspa.com/contact/> (referer: https://theravenspa.com/)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchobernardoinn.com/contact-us/> from <GET https://www.ranchobernardoinn.com/contact-us>
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 7784: character maps to <undefined>
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/contact-us/> (referer: https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
INFO: Received SIGINT, shutting down gracefully. Send again to force 
INFO: Closing spider (shutdown)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
INFO: Received SIGINT twice, forcing unclean shutdown
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
DEBUG: Retrying <GET http://www.athenaspa-mv.com/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
DEBUG: Retrying <GET https://doubleeagle.com/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: f0c912b289b46f0a
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Attempting to acquire lock 2806106620736 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2806106620736 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2806106620736 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2806106620736 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Scraped from <200 https://www.kellysspa.com/contact-location>
{'emails': ['SpaDirector@Missioninn.com', 'spadirector@missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn',
 'instagram': 'https://www.instagram.com/kellys_spa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Scraped from <200 https://cadayspa.com/contact-us>
{'emails': ['team@latofonts.com',
            'impallari@gmail.com',
            'ron@cadayspa.com',
            'filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/californiadayspa',
 'instagram': 'https://www.instagram.com/cadayspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/califadayspa'}
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': ['molly@thestoriedgroup.com',
            'guestservices@goldendoor.com.',
            'shop@goldendoor.com',
            'guestservices@goldendoor.com'],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Scraped from <200 https://www.fourseasons.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/FourSeasons',
 'instagram': 'https://www.instagram.com/fourseasons/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FourSeasons'}
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': ['cavinfo@cal-a-vie.com'],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/calaviespa'}
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['rhiannon@purpleorchid.com',
            'spa@purpleorchid.com',
            'info@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Scraped from <200 https://montereyplazahotel.com/hotel/contact>
{'emails': ['weddings@montereyplazahotel.com',
            'forms@tambourine.com',
            'sales@montereyplazahotel.com',
            'housekeeping@montereyplazahotel.com',
            'coastalcurator@montereyplazahotel.com'],
 'facebook': 'https://www.facebook.com/montereyplazahotel',
 'instagram': 'https://www.instagram.com/montereyplaza/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Scraped from <200 https://www.osmosis.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/OsmosisDaySpaSanctuary',
 'instagram': 'https://www.instagram.com/osmosisdayspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/osmosisspa'}
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Scraped from <200 https://www.urbanretreatspa.com/contact>
{'emails': ['contact@urbanretreatspa.com'],
 'facebook': 'https://www.facebook.com/pages/Urban-Retreat-Day-Spa/69993009232?ref=hl',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/URDaySpa'}
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['jeff.vanparis@silveradoresort.com',
            'golf@silveradoresort.com',
            'spa@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'resv@silveradoresort.com',
            'tennis@silveradoresort.com',
            'sales@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'info@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.aubergeresorts.com/solage/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SolageResort/',
 'instagram': 'https://www.instagram.com/solageauberge/?hl=en',
 'linkedin': 'https://www.linkedin.com/company/auberge-resorts/',
 'twitter': 'https://twitter.com/solageauberge'}
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Scraped from <200 https://www.terranea.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/Terranea',
 'instagram': 'http://instagram.com/terranearesort',
 'linkedin': 'https://www.linkedin.com/company/terranea-resort',
 'twitter': 'https://twitter.com/TerraneaResort'}
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Scraped from <200 https://boonhotels.com/contact/>
{'emails': ['info@boonhotels.com'],
 'facebook': 'http://www.facebook.com/boonhotelspa',
 'instagram': 'https://www.instagram.com/boonhotelspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/boonhotelspa'}
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Scraped from <200 https://thesisleyspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SisleySpaUSA/',
 'instagram': 'https://www.instagram.com/sisleyspausa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Scraped from <200 https://lagunacanyonspa.com/contact-us>
{'emails': ['hello@rfuenzalida.com',
            'info@ndiscovered.com',
            'impallari@gmail.com',
            'filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/103690430994',
 'instagram': 'https://www.instagram.com/lagunacanyonspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/lagunacanyonspa/'}
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['villas@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'tennis@ranchovalencia.com',
            'concierge@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Scraped from <200 https://www.canyonranch.com/contact-us/>
{'emails': ['Tucson-Sales@canyonranch.com',
            'media@canyonranch.com',
            'lchesloff@williampitt.com',
            'nikki.field@sothebyshomes.com',
            'Woodside-Sales@canyonranch.com',
            'Lenox-Sales@canyonranch.com',
            'Las-Vegas-Sales@canyonranch.com',
            'gmontgomery@williampitt.com',
            'jzimmermann@canyonranch.com'],
 'facebook': 'https://www.facebook.com/CanyonRanch',
 'instagram': 'https://www.instagram.com/canyonranch/',
 'linkedin': 'https://www.linkedin.com/company/canyon-ranch',
 'twitter': 'https://twitter.com/CanyonRanch'}
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/contact-us> (referer: https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['resinquiry@laquintaresort.com',
            'information@laquintaresort.com',
            'weddings@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/laquintaresort'}
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://www.cavallopoint.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/CavalloPoint',
 'instagram': 'https://www.instagram.com/cavallopoint/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/CavalloPoint'}
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Scraped from <200 https://www.lapeauspafresno.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/lapeauspa/?fref=ts',
 'instagram': 'https://www.instagram.com/lapeauspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['weddings@paradisepoint.com',
            'marketing@paradisepoint.com',
            'sales@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Scraped from <200 https://www.indianspringscalistoga.com/contact-us>
{'emails': ['inquiries@indianspringscalistoga.com', 'forms@tambourine.com'],
 'facebook': 'https://www.facebook.com/ISRNAPA/',
 'instagram': 'https://www.instagram.com/indianspringscalistoga/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': ['info@wispausa.com'],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Scraped from <200 https://glenivy.com/contact-info/>
{'emails': [],
 'facebook': 'https://www.facebook.com/GlenIvyHotSprings',
 'instagram': 'https://instagram.com/glenivy_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/GlenIvySpas'}
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Crawled (200) <GET https://theravenspa.com/contact/> (referer: https://theravenspa.com/)
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Scraped from <200 https://theravenspa.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://carmelvalleyranch.com/contact/>
{'emails': ['cvrmembership@carmelvalleyranch.com',
            'cvrriverranch@carmelvalleyranch.com',
            'cvrvalleykitchen@carmelvalleyranch.com',
            'cvrwedding@carmelvalleyranch.com',
            'cvrclubhouse@carmelvalleyranch.com',
            'spa@carmelvalleyranch.com',
            'guestservices@carmelvalleyranch.com',
            'cvrgolf@carmelvalleyranch.com',
            'tennis@carmelvalleyranch.com'],
 'facebook': 'https://www.facebook.com/carmelvalleyranch/',
 'instagram': 'https://www.instagram.com/carmelvranch',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchobernardoinn.com/contact-us/> from <GET https://www.ranchobernardoinn.com/contact-us>
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 7784: character maps to <undefined>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['villas@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'tennis@ranchovalencia.com',
            'concierge@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/contact-us/> (referer: https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
DEBUG: Scraped from <200 https://www.ranchobernardoinn.com/contact-us/>
{'emails': ['rbiweddings@jcresorts.com',
            'ranchobernardoinn@jcresorts.com',
            'rbibilling@jcresorts.com',
            'rbijobs@jcresorts.com'],
 'facebook': 'https://www.facebook.com/RBInn',
 'instagram': 'https://instagram.com/ranchobernardoinn/',
 'linkedin': 'https://www.linkedin.com/company/rancho-bernardo-inn?trk=biz-brand-tree-co-logo',
 'twitter': 'https://twitter.com/rbernardoinn'}
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://www.missioninn.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/TheMissionInn/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/missioninnhotel?lang=en'}
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['jeff.vanparis@silveradoresort.com',
            'golf@silveradoresort.com',
            'spa@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'resv@silveradoresort.com',
            'tennis@silveradoresort.com',
            'sales@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'info@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': ['info@wecarespa.com'],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Scraped from <200 https://www.estancialajolla.com/contact/>
{'emails': ['rsv@estancialajolla.com',
            'sales@estancialajolla.com',
            'spa@estancialajolla.com',
            'elj@20twostudio.com',
            'EstanciaConcierge@EstanciaLaJolla.com',
            'bookzoe@noblehousehotels.com'],
 'facebook': 'https://www.facebook.com/EstanciaLaJolla/',
 'instagram': 'https://www.instagram.com/estancialajolla/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.paseahotel.com/contact/press-room>
{'emails': ['frontdesk@paseahotel.com',
            'forms@tambourine.com',
            'marketing@paseahotel.com'],
 'facebook': 'https://www.facebook.com/PaseaHotel/',
 'instagram': 'https://www.instagram.com/paseahotel/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://mysheerbliss.com/pages/contact-us-spa-policy>
{'emails': ['info@mysheerbliss.com', 'glow@mysheerbliss.com'],
 'facebook': 'https://www.facebook.com/fresnoorganicspa/',
 'instagram': 'https://www.instagram.com/sheerblissspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Scraped from <200 https://www.teahousespa.com/contact-join-our-team>
{'emails': ['TeaHouseSpaManagement@gmail.com', 'reception@teahousespa.com'],
 'facebook': 'https://www.facebook.com/theteahousespa',
 'instagram': 'https://www.instagram.com/theteahousespa/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://harbin.org/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/harbinhotsprings',
 'instagram': 'https://www.instagram.com/harbin_hot_springs/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': ['catering@miraclesprings.com', 'spa@miraclesprings.com'],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Scraped from <200 http://www.athenaspa-mv.com/contact-us>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Scraped from <200 https://www.bardessono.com/contact.htm>
{'emails': [],
 'facebook': 'https://www.facebook.com/bardessonohotelspa/',
 'instagram': 'https://www.instagram.com/bardessonoyountville/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BardessonoHotel'}
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 46881,
 'downloader/request_count': 162,
 'downloader/request_method_count/GET': 162,
 'downloader/response_bytes': 5821695,
 'downloader/response_count': 162,
 'downloader/response_status_count/200': 111,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 3,
 'elapsed_time_seconds': 12.104421,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 18, 44, 3, 780409),
 'httpcompression/response_bytes': 20349184,
 'httpcompression/response_count': 111,
 'httperror/response_ignored_count': 4,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'item_scraped_count': 47,
 'log_count/DEBUG': 216,
 'log_count/ERROR': 2,
 'log_count/INFO': 14,
 'request_depth_max': 1,
 'response_received_count': 115,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/429 Unknown Status': 2,
 'scheduler/dequeued': 162,
 'scheduler/dequeued/memory': 162,
 'scheduler/enqueued': 162,
 'scheduler/enqueued/memory': 162,
 'start_time': datetime.datetime(2022, 12, 9, 18, 43, 51, 675988)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 1e88e36df1236c79
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1299262477536 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1299262477536 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1299262477536 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1299262477536 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Scraped from <200 https://www.fourseasons.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/FourSeasons',
 'instagram': 'https://www.instagram.com/fourseasons/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FourSeasons'}
DEBUG: Scraped from <200 https://www.kellysspa.com/contact-location>
{'emails': ['SpaDirector@Missioninn.com', 'spadirector@missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn',
 'instagram': 'https://www.instagram.com/kellys_spa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://cadayspa.com/contact-us>
{'emails': ['filler@godaddy.com',
            'impallari@gmail.com',
            'team@latofonts.com',
            'ron@cadayspa.com'],
 'facebook': 'https://www.facebook.com/californiadayspa',
 'instagram': 'https://www.instagram.com/cadayspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/califadayspa'}
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': ['cavinfo@cal-a-vie.com'],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/calaviespa'}
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': ['molly@thestoriedgroup.com',
            'guestservices@goldendoor.com',
            'guestservices@goldendoor.com.',
            'shop@goldendoor.com'],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Scraped from <200 https://www.osmosis.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/OsmosisDaySpaSanctuary',
 'instagram': 'https://www.instagram.com/osmosisdayspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/osmosisspa'}
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['info@purpleorchid.com',
            'spa@purpleorchid.com',
            'rhiannon@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://montereyplazahotel.com/hotel/contact>
{'emails': ['forms@tambourine.com',
            'housekeeping@montereyplazahotel.com',
            'coastalcurator@montereyplazahotel.com',
            'sales@montereyplazahotel.com',
            'weddings@montereyplazahotel.com'],
 'facebook': 'https://www.facebook.com/montereyplazahotel',
 'instagram': 'https://www.instagram.com/montereyplaza/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
DEBUG: Scraped from <200 https://www.urbanretreatspa.com/contact>
{'emails': ['contact@urbanretreatspa.com'],
 'facebook': 'https://www.facebook.com/pages/Urban-Retreat-Day-Spa/69993009232?ref=hl',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/URDaySpa'}
DEBUG: Scraped from <200 https://www.aubergeresorts.com/solage/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SolageResort/',
 'instagram': 'https://www.instagram.com/solageauberge/?hl=en',
 'linkedin': 'https://www.linkedin.com/company/auberge-resorts/',
 'twitter': 'https://twitter.com/solageauberge'}
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Scraped from <200 https://boonhotels.com/contact/>
{'emails': ['info@boonhotels.com'],
 'facebook': 'http://www.facebook.com/boonhotelspa',
 'instagram': 'https://www.instagram.com/boonhotelspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/boonhotelspa'}
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Scraped from <200 https://www.terranea.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/Terranea',
 'instagram': 'http://instagram.com/terranearesort',
 'linkedin': 'https://www.linkedin.com/company/terranea-resort',
 'twitter': 'https://twitter.com/TerraneaResort'}
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Scraped from <200 https://thesisleyspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SisleySpaUSA/',
 'instagram': 'https://www.instagram.com/sisleyspausa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['tennis@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'villas@ranchovalencia.com',
            'concierge@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.estanciadayspa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.canyonranch.com/contact-us/>
{'emails': ['Tucson-Sales@canyonranch.com',
            'gmontgomery@williampitt.com',
            'media@canyonranch.com',
            'Lenox-Sales@canyonranch.com',
            'nikki.field@sothebyshomes.com',
            'lchesloff@williampitt.com',
            'Woodside-Sales@canyonranch.com',
            'jzimmermann@canyonranch.com',
            'Las-Vegas-Sales@canyonranch.com'],
 'facebook': 'https://www.facebook.com/CanyonRanch',
 'instagram': 'https://www.instagram.com/canyonranch/',
 'linkedin': 'https://www.linkedin.com/company/canyon-ranch',
 'twitter': 'https://twitter.com/CanyonRanch'}
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.trilogyspa.com/> from <GET http://www.trilogyspa.com/>
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Crawled (200) <GET https://www.cavallopoint.com/contact-us> (referer: https://www.cavallopoint.com/spa?utm_source=google-gmb&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': ['info@wispausa.com'],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['marketing@paradisepoint.com',
            'weddings@paradisepoint.com',
            'sales@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['resinquiry@laquintaresort.com',
            'information@laquintaresort.com',
            'weddings@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/laquintaresort'}
DEBUG: Crawled (200) <GET https://theravenspa.com/> (referer: None)
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://lagunacanyonspa.com/contact-us>
{'emails': ['filler@godaddy.com',
            'impallari@gmail.com',
            'hello@rfuenzalida.com',
            'info@ndiscovered.com'],
 'facebook': 'https://www.facebook.com/103690430994',
 'instagram': 'https://www.instagram.com/lagunacanyonspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/lagunacanyonspa/'}
DEBUG: Scraped from <200 https://www.lapeauspafresno.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/lapeauspa/?fref=ts',
 'instagram': 'https://www.instagram.com/lapeauspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.cavallopoint.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/CavalloPoint',
 'instagram': 'https://www.instagram.com/cavallopoint/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/CavalloPoint'}
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Redirecting (301) to <GET https://www.thebluedoorhanford.com/> from <GET http://www.thebluedoorhanford.com/>
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/spa/spa-aiyana/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchobernardoinn.com/contact-us/> from <GET https://www.ranchobernardoinn.com/contact-us>
DEBUG: Scraped from <200 https://glenivy.com/contact-info/>
{'emails': [],
 'facebook': 'https://www.facebook.com/GlenIvyHotSprings',
 'instagram': 'https://instagram.com/glenivy_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/GlenIvySpas'}
DEBUG: Crawled (200) <GET https://www.trilogyspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Redirecting (301) to <GET https://harbin.org/> from <GET http://www.harbin.org/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://thehealingcornerca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://theravenspa.com/contact/> (referer: https://theravenspa.com/)
DEBUG: Crawled (200) <GET https://www.ranchobernardoinn.com/contact-us/> (referer: https://www.ranchobernardoinn.com/spa/overview?utm_source=gmb&utm_medium=yext)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://doubleeagle.com/> from <GET http://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['silveradodining@silveradoresort.com',
            'tennis@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'spa@silveradoresort.com',
            'resv@silveradoresort.com',
            'golf@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'info@silveradoresort.com',
            'sales@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Scraped from <200 https://theravenspa.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.ranchobernardoinn.com/contact-us/>
{'emails': ['rbijobs@jcresorts.com',
            'ranchobernardoinn@jcresorts.com',
            'rbibilling@jcresorts.com',
            'rbiweddings@jcresorts.com'],
 'facebook': 'https://www.facebook.com/RBInn',
 'instagram': 'https://instagram.com/ranchobernardoinn/',
 'linkedin': 'https://www.linkedin.com/company/rancho-bernardo-inn?trk=biz-brand-tree-co-logo',
 'twitter': 'https://twitter.com/rbernardoinn'}
DEBUG: Redirecting (301) to <GET https://www.teahousespa.com/> from <GET http://www.teahousespa.com/>
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': ['info@wecarespa.com'],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Redirecting (301) to <GET https://www.missioninn.com/> from <GET http://www.missioninn.com/>
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://www.thebluedoorhanford.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://www.thelandingtahoe.com/> (referer: None)
DEBUG: Crawled (200) <GET https://carmelvalleyranch.com/contact/> (referer: https://carmelvalleyranch.com/spa/spa-aiyana/)
DEBUG: Crawled (403) <GET https://www.montagehotels.com/lagunabeach/> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 37, in start_requests
    for row in reader:
  File "C:\Users\moffi\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 7781: character maps to <undefined>
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://www.missioninn.com/> (referer: None)
INFO: Ignoring response <403 https://www.montagehotels.com/lagunabeach/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://carmelvalleyranch.com/contact/>
{'emails': ['cvrwedding@carmelvalleyranch.com',
            'spa@carmelvalleyranch.com',
            'guestservices@carmelvalleyranch.com',
            'cvrriverranch@carmelvalleyranch.com',
            'cvrgolf@carmelvalleyranch.com',
            'cvrmembership@carmelvalleyranch.com',
            'tennis@carmelvalleyranch.com',
            'cvrclubhouse@carmelvalleyranch.com',
            'cvrvalleykitchen@carmelvalleyranch.com'],
 'facebook': 'https://www.facebook.com/carmelvalleyranch/',
 'instagram': 'https://www.instagram.com/carmelvranch',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://mysheerbliss.com/> from <GET https://www.mysheerbliss.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://harbin.org/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.doubleeagle.com/> from <GET https://doubleeagle.com/>
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET https://www.missioninn.com/contact> (referer: https://www.missioninn.com/)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.bardessono.com/> from <GET https://bardessono.com/>
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/> (referer: None)
DEBUG: Scraped from <200 https://www.indianspringscalistoga.com/contact-us>
{'emails': ['forms@tambourine.com', 'inquiries@indianspringscalistoga.com'],
 'facebook': 'https://www.facebook.com/ISRNAPA/',
 'instagram': 'https://www.instagram.com/indianspringscalistoga/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['tennis@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'villas@ranchovalencia.com',
            'concierge@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Crawled (200) <GET https://mysheerbliss.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing> (referer: None)
DEBUG: Scraped from <200 https://www.missioninn.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/TheMissionInn/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/missioninnhotel?lang=en'}
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET http://www.athenaspa-mv.com/contact-us> (referer: http://www.athenaspa-mv.com/)
DEBUG: Crawled (200) <GET https://mysheerbliss.com/pages/contact-us-spa-policy> (referer: https://mysheerbliss.com/)
DEBUG: Crawled (200) <GET https://www.teahousespa.com/contact-join-our-team> (referer: https://www.teahousespa.com/)
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Scraped from <200 http://www.athenaspa-mv.com/contact-us>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://mysheerbliss.com/pages/contact-us-spa-policy>
{'emails': ['info@mysheerbliss.com', 'glow@mysheerbliss.com'],
 'facebook': 'https://www.facebook.com/fresnoorganicspa/',
 'instagram': 'https://www.instagram.com/sheerblissspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.teahousespa.com/contact-join-our-team>
{'emails': ['reception@teahousespa.com', 'TeaHouseSpaManagement@gmail.com'],
 'facebook': 'https://www.facebook.com/theteahousespa',
 'instagram': 'https://www.instagram.com/theteahousespa/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://harbin.org/contact-us/> (referer: https://harbin.org/)
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['silveradodining@silveradoresort.com',
            'tennis@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'spa@silveradoresort.com',
            'resv@silveradoresort.com',
            'golf@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'info@silveradoresort.com',
            'sales@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.estancialajolla.com/contact/> (referer: https://www.estancialajolla.com/spa/?utm_source=gmb-spa&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://harbin.org/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/harbinhotsprings',
 'instagram': 'https://www.instagram.com/harbin_hot_springs/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.estancialajolla.com/contact/>
{'emails': ['bookzoe@noblehousehotels.com',
            'rsv@estancialajolla.com',
            'elj@20twostudio.com',
            'sales@estancialajolla.com',
            'spa@estancialajolla.com',
            'EstanciaConcierge@EstanciaLaJolla.com'],
 'facebook': 'https://www.facebook.com/EstanciaLaJolla/',
 'instagram': 'https://www.instagram.com/estancialajolla/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bardessono.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.miraclesprings.com/contact/> (referer: https://www.miraclesprings.com/)
DEBUG: Crawled (200) <GET https://www.paseahotel.com/contact/press-room> (referer: https://www.paseahotel.com/?utm_medium=organic&utm_source=google&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://www.miraclesprings.com/contact/>
{'emails': ['catering@miraclesprings.com', 'spa@miraclesprings.com'],
 'facebook': 'https://www.facebook.com/miraclesprings',
 'instagram': 'https://www.instagram.com/miraclespringsresort/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/ResortMiracle'}
DEBUG: Scraped from <200 https://www.paseahotel.com/contact/press-room>
{'emails': ['forms@tambourine.com',
            'frontdesk@paseahotel.com',
            'marketing@paseahotel.com'],
 'facebook': 'https://www.facebook.com/PaseaHotel/',
 'instagram': 'https://www.instagram.com/paseahotel/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bardessono.com/contact.htm> (referer: https://www.bardessono.com/)
DEBUG: Scraped from <200 https://www.bardessono.com/contact.htm>
{'emails': [],
 'facebook': 'https://www.facebook.com/bardessonohotelspa/',
 'instagram': 'https://www.instagram.com/bardessonoyountville/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BardessonoHotel'}
DEBUG: Crawled (200) <GET https://www.doubleeagle.com/> (referer: None)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 46893,
 'downloader/request_count': 162,
 'downloader/request_method_count/GET': 162,
 'downloader/response_bytes': 5780416,
 'downloader/response_count': 162,
 'downloader/response_status_count/200': 111,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 3,
 'elapsed_time_seconds': 12.283953,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 18, 44, 39, 953614),
 'httpcompression/response_bytes': 19831180,
 'httpcompression/response_count': 111,
 'httperror/response_ignored_count': 4,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'item_scraped_count': 47,
 'log_count/DEBUG': 216,
 'log_count/ERROR': 2,
 'log_count/INFO': 14,
 'request_depth_max': 1,
 'response_received_count': 115,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/429 Unknown Status': 2,
 'scheduler/dequeued': 162,
 'scheduler/dequeued/memory': 162,
 'scheduler/enqueued': 162,
 'scheduler/enqueued/memory': 162,
 'start_time': datetime.datetime(2022, 12, 9, 18, 44, 27, 669661)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 313610d49ba65d4b
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://kellysspa.com/> from <GET http://kellysspa.com/>
DEBUG: Attempting to acquire lock 2971926052976 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2971926052976 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2971926052976 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2971926052976 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://cadayspa.com/> from <GET http://cadayspa.com/>
DEBUG: Redirecting (301) to <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> from <GET http://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing>
DEBUG: Redirecting (301) to <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa/?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> from <GET http://walnutcreek.woodhousespas.com/?utm_source=google&utm_medium=yext>
DEBUG: Redirecting (301) to <GET https://www.kellysspa.com/> from <GET https://kellysspa.com/>
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> from <GET http://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D>
DEBUG: Redirecting (301) to <GET https://www.goldenhaven.com/> from <GET http://www.goldenhaven.com/>
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/half-moon-bay/spa?scid=45f93f1b-bd77-45c9-8dab-83b6a417f6fe&y_source=1_MTY0OTQwNC03MTUtbG9jYXRpb24ud2Vic2l0ZQ%3D%3D> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.glenivy.com/> from <GET http://www.glenivy.com/>
DEBUG: Crawled (200) <GET https://locations.woodhousespas.com/dir/ca/walnut-creek/1636-cypress-st> (referer: None)
DEBUG: Crawled (200) <GET https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer> (referer: None)
DEBUG: Crawled (200) <GET https://cadayspa.com/contact-us> (referer: https://cadayspa.com/)
DEBUG: Crawled (200) <GET https://www.kellysspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Crawled (200) <GET https://www.madonnainn.com/spa> (referer: None)
DEBUG: Redirecting (301) to <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET https://aubergeresorts.com/solage/wellness/spa?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://goldendoor.com/> (referer: None)
DEBUG: Scraped from <200 https://cadayspa.com/contact-us>
{'emails': ['impallari@gmail.com',
            'filler@godaddy.com',
            'team@latofonts.com',
            'ron@cadayspa.com'],
 'facebook': 'https://www.facebook.com/californiadayspa',
 'instagram': 'https://www.instagram.com/cadayspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/califadayspa'}
DEBUG: Crawled (200) <GET https://www.kellysspa.com/contact-location> (referer: https://www.kellysspa.com/)
DEBUG: Redirecting (301) to <GET https://www.mytrilogylife.com/monarchdunes/spa/> from <GET http://www.mytrilogylife.com/monarchdunes/spa/>
DEBUG: Scraped from <200 https://www.kellysspa.com/contact-location>
{'emails': ['SpaDirector@Missioninn.com', 'spadirector@missioninn.com'],
 'facebook': 'https://www.facebook.com/TheMissionInn',
 'instagram': 'https://www.instagram.com/kellys_spa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> from <GET http://aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website>
DEBUG: Crawled (200) <GET https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://goldendoor.com/contact-us/> (referer: https://goldendoor.com/)
DEBUG: Crawled (200) <GET https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.goldenhaven.com/> (referer: None)
DEBUG: Scraped from <200 https://goldendoor.com/contact-us/>
{'emails': ['guestservices@goldendoor.com.',
            'guestservices@goldendoor.com',
            'shop@goldendoor.com',
            'molly@thestoriedgroup.com'],
 'facebook': 'https://www.facebook.com/Goldendoorspa/',
 'instagram': 'https://www.instagram.com/thegoldendoor/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/goldendoor'}
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/los-angeles/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> from <GET http://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2>
DEBUG: Crawled (200) <GET https://www.fourseasons.com/contact-us/> (referer: https://www.fourseasons.com/westlakevillage/spa/?seo=google_local_wes6_amer)
DEBUG: Crawled (200) <GET https://www.cal-a-vie.com/contact-us> (referer: https://www.cal-a-vie.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Crawled (200) <GET https://www.ritzcarlton.com/en/hotels/california/santa-barbara/spa?scid=bb1a189a-fec3-4d19-a255-54ba596febe2> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.laquintaresort.com/> from <GET http://www.laquintaresort.com/>
DEBUG: Scraped from <200 https://www.fourseasons.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/FourSeasons',
 'instagram': 'https://www.instagram.com/fourseasons/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FourSeasons'}
DEBUG: Scraped from <200 https://www.cal-a-vie.com/contact-us>
{'emails': ['cavinfo@cal-a-vie.com'],
 'facebook': 'https://www.facebook.com/CalaVie',
 'instagram': 'https://www.instagram.com/calaviespa',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/calaviespa'}
DEBUG: Redirecting (301) to <GET https://www.wispausa.com/> from <GET http://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://www.osmosis.com/contact/> (referer: https://www.osmosis.com/?y_source=1_MjI1MDUzNzItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Redirecting (301) to <GET https://www.boonhotels.com/> from <GET http://www.boonhotels.com/>
DEBUG: Scraped from <200 https://www.osmosis.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/OsmosisDaySpaSanctuary',
 'instagram': 'https://www.instagram.com/osmosisdayspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/osmosisspa'}
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 1 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.purpleorchid.com/contact-us/> (referer: https://www.purpleorchid.com/)
DEBUG: Scraped from <200 https://www.purpleorchid.com/contact-us/>
{'emails': ['spa@purpleorchid.com',
            'info@purpleorchid.com',
            'rhiannon@purpleorchid.com'],
 'facebook': 'https://www.facebook.com/ThePurpleOrchid',
 'instagram': 'https://www.instagram.com/thepurpleorchid/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/purpleorchidcom'}
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting> (referer: None)
DEBUG: Retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 2 times): 429 Unknown Status
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website> (referer: None)
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/> (referer: None)
DEBUG: Crawled (200) <GET https://the-spring.com/> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places> (referer: None)
DEBUG: Redirecting (301) to <GET https://glenivy.com/> from <GET https://www.glenivy.com/>
ERROR: Gave up retrying <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (failed 3 times): 429 Unknown Status
DEBUG: Crawled (429) <GET https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.southcoastwinery.com/spa/> from <GET https://www.southcoastwinery.com/spa>
DEBUG: Crawled (200) <GET https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page> (referer: None)
DEBUG: Crawled (200) <GET https://www.omnihotels.com/forms/contact-us> (referer: https://www.omnihotels.com/hotels/san-diego-la-costa/spa?utm_source=GMBlisting&utm_medium=organic)
INFO: Ignoring response <429 https://www.hyatt.com/en-US/spas/Pacific-Waters-Spa/home.html>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sycamoresprings.com/> from <GET http://www.sycamoresprings.com/>
DEBUG: Redirecting (301) to <GET https://boonhotels.com/> from <GET https://www.boonhotels.com/>
DEBUG: Scraped from <200 https://www.omnihotels.com/forms/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/omnihotels/',
 'instagram': 'https://www.instagram.com/omnihotels/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/omnihotels?lang=en'}
DEBUG: Redirecting (301) to <GET https://www.evo-spa.com/> from <GET http://www.evo-spa.com/>
DEBUG: Crawled (403) <GET https://www.constantcontact.com/legal/service-provider> (referer: https://the-spring.com/)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/> (referer: None)
INFO: Ignoring response <403 https://www.constantcontact.com/legal/service-provider>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.mytrilogylife.com/monarchdunes/spa/#contacts> (referer: https://www.mytrilogylife.com/monarchdunes/spa/)
DEBUG: Redirecting (301) to <GET http://beverlyhotsprings.com/> from <GET http://www.beverlyhotsprings.com/>
DEBUG: Crawled (200) <GET https://www.aubergeresorts.com/solage/contact-us/> (referer: https://www.aubergeresorts.com/solage/wellness/spa/?utm_source=google%20my%20business&utm_medium=listing&utm_campaign=visit%20website)
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/> (referer: None)
DEBUG: Scraped from <200 https://www.mytrilogylife.com/monarchdunes/spa/>
{'emails': [],
 'facebook': 'https://www.facebook.com/sandalwoodtrilogy/',
 'instagram': 'https://www.instagram.com/sandalwood_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/monarch_club/'}
DEBUG: Scraped from <200 https://www.aubergeresorts.com/solage/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SolageResort/',
 'instagram': 'https://www.instagram.com/solageauberge/?hl=en',
 'linkedin': 'https://www.linkedin.com/company/auberge-resorts/',
 'twitter': 'https://twitter.com/solageauberge'}
DEBUG: Crawled (200) <GET https://www.urbanretreatspa.com/contact> (referer: https://www.urbanretreatspa.com/)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/los-angeles/> (referer: None)
DEBUG: Crawled (200) <GET https://montereyplazahotel.com/hotel/contact> (referer: https://montereyplazahotel.com/spa/vista-blue-spa/?utm_source=google&utm_medium=bizlisting&utm_campaign=google_places)
DEBUG: Crawled (200) <GET https://www.terranea.com/contact-us> (referer: https://www.terranea.com/offers?utm_source=google-knowledge-graph&utm_medium=organic&utm_campaign=my_business_page)
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/spa/> (referer: None)
DEBUG: Scraped from <200 https://www.urbanretreatspa.com/contact>
{'emails': ['contact@urbanretreatspa.com'],
 'facebook': 'https://www.facebook.com/pages/Urban-Retreat-Day-Spa/69993009232?ref=hl',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/URDaySpa'}
DEBUG: Redirecting (301) to <GET https://sweetwaterspa.com/> from <GET http://www.sweetwaterspa.com/>
DEBUG: Scraped from <200 https://montereyplazahotel.com/hotel/contact>
{'emails': ['coastalcurator@montereyplazahotel.com',
            'housekeeping@montereyplazahotel.com',
            'sales@montereyplazahotel.com',
            'forms@tambourine.com',
            'weddings@montereyplazahotel.com'],
 'facebook': 'https://www.facebook.com/montereyplazahotel',
 'instagram': 'https://www.instagram.com/montereyplaza/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.terranea.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/Terranea',
 'instagram': 'http://instagram.com/terranearesort',
 'linkedin': 'https://www.linkedin.com/company/terranea-resort',
 'twitter': 'https://twitter.com/TerraneaResort'}
DEBUG: Crawled (200) <GET https://www.sycamoresprings.com/contact> (referer: https://www.sycamoresprings.com/)
DEBUG: Crawled (200) <GET https://www.evo-spa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ranchovalencia.com/> from <GET http://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://boonhotels.com/> (referer: None)
DEBUG: Scraped from <200 https://www.sycamoresprings.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/sycamoremineralsprings',
 'instagram': 'https://instagram.com/sycamoresprings',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/sycamoresprings'}
DEBUG: Redirecting (301) to <GET https://wispausa.com/> from <GET https://www.wispausa.com/>
DEBUG: Crawled (200) <GET https://www.silveradoresort.com/contact-us> (referer: https://www.silveradoresort.com/napa-valley-spa?utm_medium=organic&utm_source=google&utm_campaign=spabusinesslisting)
DEBUG: Redirecting (301) to <GET https://www.lapeauspafresno.com/> from <GET http://www.lapeauspafresno.com/>
DEBUG: Scraped from <200 https://www.silveradoresort.com/contact-us>
{'emails': ['info@silveradoresort.com',
            'loren.bates@silveradoresort.com',
            'jeff.vanparis@silveradoresort.com',
            'golf@silveradoresort.com',
            'silveradodining@silveradoresort.com',
            'silverado.concierge@silveradoresort.com',
            'sales@silveradoresort.com',
            'heather.mckenna@silveradoresort.com',
            'resv@silveradoresort.com',
            'spa@silveradoresort.com',
            'tennis@silveradoresort.com'],
 'facebook': 'https://www.facebook.com/silveradoresort',
 'instagram': 'https://www.instagram.com/silveradoresort',
 'linkedin': 'https://www.linkedin.com/company/silverado-resort',
 'twitter': 'https://twitter.com/silveradoresort'}
DEBUG: Crawled (200) <GET https://www.southcoastwinery.com/contact> (referer: https://www.southcoastwinery.com/spa/)
DEBUG: Crawled (200) <GET https://boonhotels.com/contact/> (referer: https://boonhotels.com/)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/> from <GET http://www.wecarespa.com/>
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/> (referer: None)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thesisleyspa.com/contact-us/> (referer: https://thesisleyspa.com/los-angeles/)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 40, in start_requests
    url = row[1]
IndexError: list index out of range
DEBUG: Scraped from <200 https://www.southcoastwinery.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/SouthCoastWinery',
 'instagram': 'https://www.instagram.com/southcoastwineryresort/',
 'linkedin': 'https://www.linkedin.com/company/south-coast-winery-&-spa/',
 'twitter': 'https://twitter.com/SCWinery'}
DEBUG: Scraped from <200 https://boonhotels.com/contact/>
{'emails': ['info@boonhotels.com'],
 'facebook': 'http://www.facebook.com/boonhotelspa',
 'instagram': 'https://www.instagram.com/boonhotelspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/boonhotelspa'}
DEBUG: Crawled (200) <GET https://www.canyonranch.com/woodside/northern-california-retreat/?utm_source=googlemybusiness&utm_medium=organic&utm_campaign=woodsidegmb&utm_term=googlemybusiness> (referer: None)
DEBUG: Redirecting (301) to <GET https://lagunacanyonspa.com/> from <GET http://www.lagunacanyonspa.com/>
DEBUG: Crawled (200) <GET https://davidrubensteinforum.uchicago.edu/contact/> (referer: https://www.chaminade.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://thesisleyspa.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/SisleySpaUSA/',
 'instagram': 'https://www.instagram.com/sisleyspausa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://glenivy.com/> (referer: None)
DEBUG: Crawled (200) <GET https://azurepalmhotsprings.com/> (referer: None)
DEBUG: Scraped from <200 https://davidrubensteinforum.uchicago.edu/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.carnerosresort.com/> from <GET http://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://lagunacanyonspa.com/contact-us> (referer: https://lagunacanyonspa.com/)
DEBUG: Crawled (200) <GET https://wispausa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Crawled (200) <GET http://beverlyhotsprings.com/contact/> (referer: http://beverlyhotsprings.com/)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.canyonranch.com/contact-us/> (referer: https://www.canyonranch.com/)
DEBUG: Scraped from <200 https://lagunacanyonspa.com/contact-us>
{'emails': ['impallari@gmail.com',
            'filler@godaddy.com',
            'info@ndiscovered.com',
            'hello@rfuenzalida.com'],
 'facebook': 'https://www.facebook.com/103690430994',
 'instagram': 'https://www.instagram.com/lagunacanyonspa',
 'linkedin': 'N/A',
 'twitter': 'https://www.twitter.com/lagunacanyonspa/'}
DEBUG: Crawled (200) <GET https://www.laquintaresort.com/map-and-contact/> (referer: https://www.laquintaresort.com/)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['concierge@ranchovalencia.com',
            'villas@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'tennis@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
DEBUG: Scraped from <200 http://beverlyhotsprings.com/contact/>
{'emails': ['beverlyhotsprings@gmail.com'],
 'facebook': 'https://www.facebook.com/beverlyhotsprings',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/BHSdayspa'}
DEBUG: Scraped from <200 https://www.canyonranch.com/contact-us/>
{'emails': ['gmontgomery@williampitt.com',
            'Tucson-Sales@canyonranch.com',
            'nikki.field@sothebyshomes.com',
            'media@canyonranch.com',
            'jzimmermann@canyonranch.com',
            'lchesloff@williampitt.com',
            'Lenox-Sales@canyonranch.com',
            'Las-Vegas-Sales@canyonranch.com',
            'Woodside-Sales@canyonranch.com'],
 'facebook': 'https://www.facebook.com/CanyonRanch',
 'instagram': 'https://www.instagram.com/canyonranch/',
 'linkedin': 'https://www.linkedin.com/company/canyon-ranch',
 'twitter': 'https://twitter.com/CanyonRanch'}
DEBUG: Scraped from <200 https://www.laquintaresort.com/map-and-contact/>
{'emails': ['weddings@laquintaresort.com',
            'resinquiry@laquintaresort.com',
            'information@laquintaresort.com'],
 'facebook': 'https://www.facebook.com/laquintaresort',
 'instagram': 'http://instagram.com/laquintaresort',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/laquintaresort'}
DEBUG: Redirecting (301) to <GET https://ranchovalencia.com/> from <GET https://www.ranchovalencia.com/>
DEBUG: Crawled (200) <GET https://paradisepoint.com/california-resort-spa/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lapeauspafresno.com/contact> (referer: https://www.lapeauspafresno.com/)
DEBUG: Redirecting (301) to <GET http://carnerosresort.com/> from <GET https://www.carnerosresort.com/>
DEBUG: Crawled (200) <GET https://wecarespa.com/> (referer: None)
DEBUG: Scraped from <200 https://www.lapeauspafresno.com/contact>
{'emails': [],
 'facebook': 'https://www.facebook.com/lapeauspa/?fref=ts',
 'instagram': 'https://www.instagram.com/lapeauspa/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://wispausa.com/contact/> (referer: https://wispausa.com/)
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing> (referer: None)
DEBUG: Scraped from <200 https://wispausa.com/contact/>
{'emails': ['info@wispausa.com'],
 'facebook': 'https://www.facebook.com/wispa.usa',
 'instagram': 'https://www.instagram.com/wispa_usa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/WiSpa_USA'}
DEBUG: Redirecting (301) to <GET https://carnerosresort.com/> from <GET http://carnerosresort.com/>
DEBUG: Crawled (200) <GET https://glenivy.com/contact-info/> (referer: https://glenivy.com/)
DEBUG: Crawled (200) <GET https://amenitiesspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://paradisepoint.com/contact-us/> (referer: https://paradisepoint.com/california-resort-spa/)
DEBUG: Scraped from <200 https://glenivy.com/contact-info/>
{'emails': [],
 'facebook': 'https://www.facebook.com/GlenIvyHotSprings',
 'instagram': 'https://instagram.com/glenivy_spa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/GlenIvySpas'}
DEBUG: Scraped from <200 https://paradisepoint.com/contact-us/>
{'emails': ['marketing@paradisepoint.com',
            'weddings@paradisepoint.com',
            'sales@paradisepoint.com'],
 'facebook': 'https://www.facebook.com/paradisepointsd',
 'instagram': 'https://www.instagram.com/paradisepointsd/',
 'linkedin': 'https://www.linkedin.com/company/paradise-point-resort-&-spa',
 'twitter': 'https://twitter.com/paradisepointsd'}
DEBUG: Crawled (404) <GET https://azurepalmhotsprings.com/dev/contact-us/> (referer: https://azurepalmhotsprings.com/)
DEBUG: Redirecting (301) to <GET https://wecarespa.com/contact-us/> from <GET https://wecarespa.com/contact/>
INFO: Ignoring response <404 https://azurepalmhotsprings.com/dev/contact-us/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://wecarespa.com/contact-us/> (referer: https://wecarespa.com/)
DEBUG: Redirecting (301) to <GET https://www.sweetwaterspa.com/> from <GET https://sweetwaterspa.com/>
DEBUG: Scraped from <200 https://wecarespa.com/contact-us/>
{'emails': ['info@wecarespa.com'],
 'facebook': 'https://www.facebook.com/WeCareSpa',
 'instagram': 'https://www.instagram.com/wecarespaca/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/wecarespa'}
DEBUG: Crawled (200) <GET https://www.indianspringscalistoga.com/contact-us> (referer: https://www.indianspringscalistoga.com/?utm_source=google&utm_medium=organic&utm_campaign=business-listing)
DEBUG: Scraped from <200 https://www.indianspringscalistoga.com/contact-us>
{'emails': ['forms@tambourine.com', 'inquiries@indianspringscalistoga.com'],
 'facebook': 'https://www.facebook.com/ISRNAPA/',
 'instagram': 'https://www.instagram.com/indianspringscalistoga/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://carnerosresort.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchovalencia.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sweetwaterspa.com/contact-us/#sweetwater-location> (referer: https://www.sweetwaterspa.com/)
DEBUG: Scraped from <200 https://www.sweetwaterspa.com/contact-us/>
{'emails': ['lodging@sweetwaterspa.com'],
 'facebook': 'https://www.facebook.com/SweetwaterInnandSpa/',
 'instagram': 'https://www.instagram.com/sweetwaterinnspa/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/SweetwaterInnCA'}
DEBUG: Crawled (200) <GET https://ranchovalencia.com/contact-us/> (referer: https://ranchovalencia.com/)
DEBUG: Scraped from <200 https://ranchovalencia.com/contact-us/>
{'emails': ['concierge@ranchovalencia.com',
            'villas@ranchovalencia.com',
            'info@villasranchovalencia.com',
            'tennis@ranchovalencia.com'],
 'facebook': 'https://www.facebook.com/RanchoValencia',
 'instagram': 'https://www.instagram.com/ranchovalencia/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/RanchoValencia'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 33201,
 'downloader/request_count': 115,
 'downloader/request_method_count/GET': 115,
 'downloader/response_bytes': 2772701,
 'downloader/response_count': 115,
 'downloader/response_status_count/200': 75,
 'downloader/response_status_count/301': 35,
 'downloader/response_status_count/403': 1,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/429': 3,
 'elapsed_time_seconds': 8.138622,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 18, 54, 37, 821154),
 'httpcompression/response_bytes': 9658270,
 'httpcompression/response_count': 74,
 'httperror/response_ignored_count': 3,
 'httperror/response_ignored_status_count/403': 1,
 'httperror/response_ignored_status_count/404': 1,
 'httperror/response_ignored_status_count/429': 1,
 'item_scraped_count': 32,
 'log_count/DEBUG': 154,
 'log_count/ERROR': 2,
 'log_count/INFO': 13,
 'request_depth_max': 1,
 'response_received_count': 78,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/429 Unknown Status': 2,
 'scheduler/dequeued': 115,
 'scheduler/dequeued/memory': 115,
 'scheduler/enqueued': 115,
 'scheduler/enqueued/memory': 115,
 'start_time': datetime.datetime(2022, 12, 9, 18, 54, 29, 682532)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 698938bfa22db82f
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 44, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.005002,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 9, 18, 55, 18, 591227),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'start_time': datetime.datetime(2022, 12, 9, 18, 55, 18, 586225)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: b2a7206301660422
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Attempting to acquire lock 3201520138320 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 3201520138320 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 3201520138320 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 3201520138320 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Crawled (200) <GET https://timberline-tree-works.business.site/> (referer: None)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Redirecting (301) to <GET http://www.isaacstreeservice.com/> from <GET http://isaacstreeservice.com/>
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (302) to <GET http://www.sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
DEBUG: Crawled (403) <GET http://www.isaacstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
INFO: Ignoring response <403 http://www.isaacstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Scraped from <200 https://www.caltreeservice.com/contact-us>
{'emails': ['office@caltreeservice.com'],
 'facebook': 'https://www.facebook.com/samcolemanluxury',
 'instagram': 'https://www.instagram.com/samcolemanluxury/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Scraped from <200 https://octreeservices.com/contact-us/>
{'emails': ['octreeservices1@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/south-bay/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Monster-Tree-Service-of-South-Bay-1088163361240866/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
DEBUG: Scraped from <200 https://rndtreeservices.com/contact-us>
{'emails': ['filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/106157038650413',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.monstertreeservice.com/west-valley/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/Monster-Tree-Service-of-West-Valley-1287919078019258/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/'}
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
DEBUG: Scraped from <200 https://westcoastarborists.com/>
{'emails': ['wcahiring@wcainc.com', 'corporate@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Scraped from <200 https://www.tomdaytreeservice.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/TomDayTreeService/reviews/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Scraped from <200 http://www.specializedtreeworks.com/contact.html>
{'emails': ['ContactUs@specializedtreeworks.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/coast/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsteroftheCoast/',
 'instagram': 'https://www.instagram.com/monsterofthecoast/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://arborworksinc.com/contact/>
{'emails': ['information@arborworksinc.com'],
 'facebook': 'https://www.facebook.com/arborworks1/',
 'instagram': 'https://www.instagram.com/arborworksllc/',
 'linkedin': 'https://www.linkedin.com/company/arborworksinc',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Scraped from <200 https://losangelesca-treeservice.com/contact>
{'emails': ['losangelescatreeservice@gmail.com',
            'u003Elosangelescatreeservice@gmail.com'],
 'facebook': 'https://www.facebook.com/losangelescatreeservice/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
DEBUG: Scraped from <200 http://www.vetreeservice.com/contactus.html>
{'emails': ['dns@technologydimensions.com',
            'Ed@vetreeservice.com',
            'Eric@vetreeservice.com',
            'Vic@vetreeservice.com',
            'Patti@vetreeservice.com',
            'Ashleigh@vetreeservice.com',
            'patti@vetreeservice.com',
            'John@vetreeservice.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.traversotree.com/contacts/>
{'emails': ['Office@traversotree.com', 'office@traversotree.com'],
 'facebook': 'https://www.facebook.com/traversotree',
 'instagram': 'https://www.instagram.com/traversotree/?hl=en',
 'linkedin': 'https://www.linkedin.com/pub/traverso-tree-service/38/6a3/a40',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://bayareatreespecialists.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Bay-Area-Tree-Specialists-658134177581480/?timeline_context_item_type=intro_card_work&timeline_context_item_source=100007956785104',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/TreesSpecialist'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/contact> (referer: https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
DEBUG: Scraped from <200 https://www.modestotreeservicecompany.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.bigtstrees.com/contact>
{'emails': ['igtstrees@yahoo.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'bigtstrees@yahoo.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'http://www.facebook.com/BigTsTrees',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Scraped from <200 https://californiagreentreecare.com/contact.php>
{'emails': ['info@californiagreentreecare.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Retrying <GET https://www.c/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (failed 1 times): DNS lookup failed: no results for hostname lookup: www.c.
DEBUG: Retrying <GET https://www.c/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (failed 2 times): DNS lookup failed: no results for hostname lookup: www.c.
ERROR: Gave up retrying <GET https://www.c/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (failed 3 times): DNS lookup failed: no results for hostname lookup: www.c.
DEBUG: Scraped from <200 https://fallenleaftree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/fallenleaftreemanagement',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FallenLeafTree'}
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
ERROR: Error downloading <GET https://www.c/?utm_source=google&utm_medium=organic&utm_campaign=gmb>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\defer.py", line 1693, in _inlineCallbacks
    result = context.run(
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\python\failure.py", line 518, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\endpoints.py", line 1022, in startConnectionAttempts
    raise error.DNSLookupError(
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.c.
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Scraped from <200 https://www.herculestreeservice.com/contact/>
{'emails': ['info@herculestreeservice.com'],
 'facebook': 'https://www.facebook.com/510799tree/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Scraped from <200 http://www.aearborists.com/contact-us/>
{'emails': ['aearborists@gmail.com'],
 'facebook': 'https://www.facebook.com/AE-Arborists-Tree-Care-428707717460988/ ',
 'instagram': 'https://www.instagram.com/aearborists/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/aearborists'}
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
DEBUG: Scraped from <200 https://jesustreeserviceandlandscaping.com/contact/>
{'emails': ['jesusjgr1987@gmail.com'],
 'facebook': 'https://www.facebook.com/Jesus-Tree-Services-Landscaping-104850001236628',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['sales@shipmantree.com', 'dillanmcather@gmail.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['sales@shipmantree.com', 'dillanmcather@gmail.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://foresttreeservices.com/contact-us/>
{'emails': ['info@foresttreeservices.com'],
 'facebook': 'https://www.facebook.com/foresttreeservices',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/company/forest-tree-services/about/',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['fred@richardstree.com', 'info@richardstree.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.commercialtreeservices.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/commercialtreeservices',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['info@mowbrays.com', 'customerservice@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
DEBUG: Scraped from <200 https://www.theneckofthewoods.com/contact-us.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/eddie.farquharson',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (301) to <GET https://www.eastbaytreeservice.com/> from <GET http://www.eastbaytreeservice.com/>
DEBUG: Scraped from <200 https://www.sequoiastreeservice.com/>
{'emails': ['evencio.martinez@yahoo.com'],
 'facebook': 'https://www.facebook.com/Sequoias-Tree-Service-104264014496885/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.atlas-tree.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/AtlasTreeSurgery',
 'instagram': 'https://www.instagram.com/atlas.tree/',
 'linkedin': 'https://www.linkedin.com/company/atlas-tree-landscape-inc/about/',
 'twitter': 'https://twitter.com/atlas_and'}
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
DEBUG: Scraped from <200 https://www.a1treeredding.com/contact/>
{'emails': ['office@a1treeredding.com', 'Office@a1treeredding.com'],
 'facebook': 'https://www.facebook.com/A1treeredding/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.a1treeredding.com/contact/>
{'emails': ['office@a1treeredding.com', 'Office@a1treeredding.com'],
 'facebook': 'https://www.facebook.com/A1treeredding/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.eastbaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['info@mowbrays.com', 'customerservice@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.adamstreeservice.org/> from <GET http://www.adamstreeservice.org/>
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.adamstreeservice.org/> from <GET http://www.adamstreeservice.org/>
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
DEBUG: Scraped from <200 https://www.treeserviceroseville.com/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://stocktontreeservices.com/> from <GET https://www.stocktontreeservices.com/>
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://ranchotreeservice.com/contact/>
{'emails': ['info@ranchotreeservice.com'],
 'facebook': 'https://www.facebook.com/Rancho-Tree-Service-109046575024387',
 'instagram': 'https://www.instagram.com/ranchotreeservice/',
 'linkedin': 'https://www.linkedin.com/company/rancho-inc-california/',
 'twitter': 'https://twitter.com/RanchoTree'}
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.adamstreeservice.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://www.adamstreeservice.org/> (referer: None)
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.adamstreeservice.org/contact.html> (referer: https://www.adamstreeservice.org/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Scraped from <200 https://www.adamstreeservice.org/contact.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/Adams-Tree-Service-1566642230319508',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.adamstreeservice.org/contact.html> (referer: https://www.adamstreeservice.org/)
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
DEBUG: Scraped from <200 https://www.adamstreeservice.org/contact.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/Adams-Tree-Service-1566642230319508',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://jtstree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/category/Shopping---Retail/Jts-Inc-510518789043998/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
DEBUG: Redirecting (301) to <GET https://capitaltreeserviceco.com/> from <GET http://www.capitaltreeserviceco.com/>
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
DEBUG: Scraped from <200 https://dprotreeservice.com/contact-us/>
{'emails': ['d.protreeservice@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.adamstreeservice.org/> from <GET http://www.adamstreeservice.org/>
DEBUG: Redirecting (301) to <GET https://www.adamstreeservice.org/> from <GET http://www.adamstreeservice.org/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
DEBUG: Scraped from <200 https://ranchotreeservice.com/contact/>
{'emails': ['info@ranchotreeservice.com'],
 'facebook': 'https://www.facebook.com/Rancho-Tree-Service-109046575024387',
 'instagram': 'https://www.instagram.com/ranchotreeservice/',
 'linkedin': 'https://www.linkedin.com/company/rancho-inc-california/',
 'twitter': 'https://twitter.com/RanchoTree'}
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.adamstreeservice.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.adamstreeservice.org/> (referer: None)
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
DEBUG: Crawled (200) <GET https://www.adamstreeservice.org/contact.html> (referer: https://www.adamstreeservice.org/)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Scraped from <200 https://greenzwaytreeservice.com/contact/>
{'emails': ['greenzway@hotmail.com', 'Greenzway@hotmail.com'],
 'facebook': 'https://www.facebook.com/pg/greenzway',
 'instagram': 'https://www.instagram.com/greenzway_official',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Scraped from <200 https://www.adamstreeservice.org/contact.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/Adams-Tree-Service-1566642230319508',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.adamstreeservice.org/contact.html> (referer: https://www.adamstreeservice.org/)
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Scraped from <200 https://www.adamstreeservice.org/contact.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/Adams-Tree-Service-1566642230319508',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/contact-2/> (referer: https://stocktontreeservices.com/)
DEBUG: Scraped from <200 https://jtstree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/category/Shopping---Retail/Jts-Inc-510518789043998/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Redirecting (301) to <GET https://www.stevestreeservice.net/> from <GET http://www.stevestreeservice.net/>
DEBUG: Redirecting (301) to <GET https://capitaltreeserviceco.com/> from <GET http://www.capitaltreeserviceco.com/>
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Scraped from <200 https://stocktontreeservices.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (403) <GET https://www.runyonstree.com/> (referer: None)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 https://www.runyonstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.lunatreetrimming.com/> (referer: None)
DEBUG: Scraped from <200 https://greenzwaytreeservice.com/contact/>
{'emails': ['greenzway@hotmail.com', 'Greenzway@hotmail.com'],
 'facebook': 'https://www.facebook.com/pg/greenzway',
 'instagram': 'https://www.instagram.com/greenzway_official',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.lunatreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.treecareofca.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.petestreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.treecareofca.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 https://www.petestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://rodrigueztreesservicellc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://arbortask.com/> from <GET http://www.arbortask.com/>
DEBUG: Crawled (200) <GET https://capitaltreeserviceco.com/> (referer: None)
INFO: Ignoring response <403 http://rodrigueztreesservicellc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://arnoldstreeservice.net/> (referer: None)
DEBUG: Crawled (200) <GET https://capitaltreeserviceco.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.natestree.com/> from <GET http://www.natestree.com/>
DEBUG: Crawled (403) <GET https://arnoldstreeservice.net/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
INFO: Ignoring response <403 https://arnoldstreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://www.vistatreeserviceinc.com/> (referer: None)
INFO: Ignoring response <403 https://arnoldstreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://aaatree1.com/> from <GET http://www.aaatree1.com/>
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/> (referer: None)
DEBUG: Crawled (403) <GET http://www.jackbenignostreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.vistatreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://risinggreeninc.com/> from <GET http://risinggreeninc.com/>
INFO: Ignoring response <403 http://www.jackbenignostreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://risinggreeninc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Redirecting (301) to <GET https://www.bartlett.com/locations/pasadena-ca.cfm> from <GET https://www.bartlett.com/locations/Pasadena-CA.cfm>
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.bartlett.com/locations/pasadena-ca.cfm> from <GET https://www.bartlett.com/locations/Pasadena-CA.cfm>
DEBUG: Crawled (200) <GET https://risinggreeninc.com/contact-us> (referer: https://risinggreeninc.com/)
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/contact/> (referer: https://www.stevestreeservice.net/)
DEBUG: Crawled (200) <GET https://aaatree1.com/> (referer: None)
DEBUG: Scraped from <200 https://risinggreeninc.com/contact-us>
{'emails': ['contact@sansoxygen.com'],
 'facebook': 'https://www.facebook.com/290105377704362',
 'instagram': 'https://www.instagram.com/Risinggreeninc',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.communitytreeservice.net/> (referer: None)
DEBUG: Scraped from <200 https://www.stevestreeservice.net/contact/>
{'emails': ['steves8733@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
INFO: Ignoring response <403 http://www.communitytreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
DEBUG: Crawled (200) <GET http://www.spmcclenahan.com/> (referer: None)
DEBUG: Crawled (200) <GET https://capitaltreeserviceco.com/contact/> (referer: https://capitaltreeserviceco.com/)
DEBUG: Scraped from <200 https://capitaltreeserviceco.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/CapitalTreeServices',
 'instagram': 'https://www.instagram.com/capitaltreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://capitaltreeserviceco.com/contact/> (referer: https://capitaltreeserviceco.com/)
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arbortask.com/> (referer: None)
DEBUG: Scraped from <200 https://capitaltreeserviceco.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/CapitalTreeServices',
 'instagram': 'https://www.instagram.com/capitaltreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://aaatree1.com/contact-us/> (referer: https://aaatree1.com/)
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Redirecting (301) to <GET https://clovistreecare.com/> from <GET http://clovistreecare.com/>
DEBUG: Scraped from <200 https://treeservicemantecaca.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bartlett.com/locations/pasadena-ca.cfm> (referer: None)
DEBUG: Crawled (200) <GET https://a-central-valley-ca-tree-service-and-landscaping.business.site/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Crawled (200) <GET https://www.bartlett.com/locations/pasadena-ca.cfm> (referer: None)
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Scraped from <200 https://aaatree1.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/AAA-Tree-Service-341926629769127',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.lctrees.com/contact/>
{'emails': ['info@lctrees.com'],
 'facebook': 'https://www.facebook.com/LC-Tree-Service-162733330551792/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET https://www.bundystreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.alspawtreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://clovistreecare.com/> (referer: None)
INFO: Ignoring response <403 https://www.bundystreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 https://www.alspawtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://www.conejovalleytreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.kingtreeservices.com/> from <GET http://www.kingtreeservices.com/>
DEBUG: Crawled (200) <GET https://www.natestree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://arbortask.com/contact/> from <GET https://arbortask.com/contact>
INFO: Ignoring response <403 https://www.conejovalleytreeservices.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.bartlett.com/contact-us.cfm> (referer: https://www.bartlett.com/locations/pasadena-ca.cfm)
DEBUG: Redirecting (301) to <GET https://www.ectreeservice.com/> from <GET http://www.ectreeservice.com/>
DEBUG: Redirecting (301) to <GET https://clovistreecare.com/contact-us/> from <GET https://clovistreecare.com/contact-us>
DEBUG: Scraped from <200 https://www.bartlett.com/contact-us.cfm>
{'emails': [],
 'facebook': 'https://www.facebook.com/BartlettSanGabriel',
 'instagram': 'https://www.instagram.com/lifeatbartlett/?hl=en/',
 'linkedin': 'https://www.linkedin.com/company/bartlett-tree-experts',
 'twitter': 'http://twitter.com/BartlettTreeExp'}
DEBUG: Redirecting (301) to <GET https://thetreewalkers.com/> from <GET http://thetreewalkers.com/>
DEBUG: Redirecting (301) to <GET http://www.cumorahtreeservice.com/> from <GET http://cumorahtreeservice.com/>
DEBUG: Redirecting (301) to <GET https://thetreewalkers.com/> from <GET http://thetreewalkers.com/>
DEBUG: Crawled (200) <GET https://clovistreecare.com/contact-us/> (referer: https://clovistreecare.com/)
DEBUG: Crawled (200) <GET https://www.bartlett.com/contact-us.cfm> (referer: https://www.bartlett.com/locations/pasadena-ca.cfm)
DEBUG: Crawled (200) <GET https://sctreeandlandscape.com/> (referer: None)
DEBUG: Crawled (200) <GET https://sctreeandlandscape.com/> (referer: None)
DEBUG: Scraped from <200 https://clovistreecare.com/contact-us/>
{'emails': ['clovistreecare@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.bartlett.com/contact-us.cfm>
{'emails': [],
 'facebook': 'https://www.facebook.com/BartlettSanGabriel',
 'instagram': 'https://www.instagram.com/lifeatbartlett/?hl=en/',
 'linkedin': 'https://www.linkedin.com/company/bartlett-tree-experts',
 'twitter': 'http://twitter.com/BartlettTreeExp'}
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/index.html#contact> (referer: http://www.abotreeservice.com/)
DEBUG: Crawled (200) <GET https://a-central-valley-ca-tree-service-and-landscaping.business.site/> (referer: None)
DEBUG: Scraped from <200 http://www.abotreeservice.com/index.html>
{'emails': ['operation@abotreeservice.com',
            'krasimira.stoyanova@deluxe.com',
            'info@abotreeservice.com'],
 'facebook': 'https://www.facebook.com/abotreeservice',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/abotreeservice',
 'twitter': 'https://twitter.com/abotreeservice'}
DEBUG: Crawled (200) <GET https://sctreeandlandscape.com/> (referer: None)
DEBUG: Crawled (200) <GET https://sctreeandlandscape.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.ectreeservice.com/> from <GET http://www.ectreeservice.com/>
DEBUG: Crawled (403) <GET https://www.conejovalleytreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.cumorahtreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.conejovalleytreeservices.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://www.cumorahtreeservice.com/> from <GET http://cumorahtreeservice.com/>
INFO: Ignoring response <403 http://www.cumorahtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Crawled (200) <GET https://sctreeandlandscape.com/contact-us/careers/> (referer: https://sctreeandlandscape.com/)
DEBUG: Crawled (403) <GET http://www.cumorahtreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.lctrees.com/contact/>
{'emails': ['info@lctrees.com'],
 'facebook': 'https://www.facebook.com/LC-Tree-Service-162733330551792/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://thetreewalkers.com/> (referer: None)
DEBUG: Crawled (200) <GET https://sctreeandlandscape.com/contact-us/careers/> (referer: https://sctreeandlandscape.com/)
DEBUG: Scraped from <200 https://sctreeandlandscape.com/contact-us/careers/>
{'emails': ['info@sctreeandlandscape.com'],
 'facebook': 'https://www.facebook.com/pages/Southern-California-Tree-and-Landscape/386243674774828',
 'instagram': 'https://www.instagram.com/sctreeandlandscape/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.cumorahtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Redirecting (301) to <GET https://thetreewalkers.com/> from <GET http://thetreewalkers.com/>
DEBUG: Crawled (200) <GET https://thetreewalkers.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://thetreewalkers.com/> from <GET http://thetreewalkers.com/>
DEBUG: Crawled (200) <GET https://arbortask.com/contact/> (referer: https://arbortask.com/)
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
DEBUG: Scraped from <200 https://sctreeandlandscape.com/contact-us/careers/>
{'emails': ['info@sctreeandlandscape.com'],
 'facebook': 'https://www.facebook.com/pages/Southern-California-Tree-and-Landscape/386243674774828',
 'instagram': 'https://www.instagram.com/sctreeandlandscape/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://treeservicemantecaca.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://thetreewalkers.com/> (referer: None)
DEBUG: Scraped from <200 https://arbortask.com/contact/>
{'emails': ['almangrant@yahoo.com'],
 'facebook': 'https://www.facebook.com/arbortasktreeservice/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://bunyonbros.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/bunyonbrostreeserviceSLO',
 'instagram': 'https://www.instagram.com/bunyonbrostreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://bunyonbros.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/bunyonbrostreeserviceSLO',
 'instagram': 'https://www.instagram.com/bunyonbrostreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://thetreewalkers.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.bartlett.com/locations/santa-monica-ca.cfm> from <GET https://www.bartlett.com/locations/Santa-Monica-CA.cfm>
DEBUG: Crawled (200) <GET https://sctreeandlandscape.com/contact-us/careers/> (referer: https://sctreeandlandscape.com/)
DEBUG: Crawled (200) <GET https://www.kingtreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://sctreeandlandscape.com/contact-us/careers/>
{'emails': ['info@sctreeandlandscape.com'],
 'facebook': 'https://www.facebook.com/pages/Southern-California-Tree-and-Landscape/386243674774828',
 'instagram': 'https://www.instagram.com/sctreeandlandscape/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://kennedy-s-pro-cuts.ueniweb.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thetreewalkers.com/contact> (referer: https://thetreewalkers.com/)
DEBUG: Redirecting (301) to <GET https://glts559.wixsite.com/greersstumps-1> from <GET http://glts559.wixsite.com/greersstumps-1>
DEBUG: Crawled (200) <GET https://thetreewalkers.com/contact> (referer: https://thetreewalkers.com/)
DEBUG: Redirecting (301) to <GET https://ectreeservice.com/> from <GET https://www.ectreeservice.com/>
DEBUG: Crawled (200) <GET http://jandrtreeservice.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.skylaketreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thetreewalkers.com/contact> (referer: https://thetreewalkers.com/)
DEBUG: Crawled (200) <GET https://sctreeandlandscape.com/contact-us/careers/> (referer: https://sctreeandlandscape.com/)
DEBUG: Crawled (200) <GET https://www.natestree.com/contact/> (referer: https://www.natestree.com/)
DEBUG: Crawled (200) <GET https://njtreeworx.com/> (referer: None)
DEBUG: Crawled (200) <GET https://thetreewalkers.com/contact> (referer: https://thetreewalkers.com/)
DEBUG: Crawled (200) <GET https://www.bartlett.com/locations/santa-monica-ca.cfm> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.kingtreeservices.com/contact-us/> from <GET https://www.kingtreeservices.com/contact-us>
DEBUG: Crawled (200) <GET https://www.elitetreeinc.com/> (referer: None)
DEBUG: Scraped from <200 https://thetreewalkers.com/contact>
{'emails': ['isatreewalkers@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/lancewalker818',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://thetreewalkers.com/contact>
{'emails': ['isatreewalkers@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/lancewalker818',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://ectreeservice.com/> from <GET https://www.ectreeservice.com/>
DEBUG: Scraped from <200 https://thetreewalkers.com/contact>
{'emails': ['isatreewalkers@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/lancewalker818',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://sctreeandlandscape.com/contact-us/careers/>
{'emails': ['info@sctreeandlandscape.com'],
 'facebook': 'https://www.facebook.com/pages/Southern-California-Tree-and-Landscape/386243674774828',
 'instagram': 'https://www.instagram.com/sctreeandlandscape/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.natestree.com/contact/>
{'emails': ['info@natestree.com'],
 'facebook': 'https://www.facebook.com/Nates-Tree-Service-112491558796249/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://thetreewalkers.com/contact>
{'emails': ['isatreewalkers@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/lancewalker818',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.rockstreeandhillside.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET http://www.fallenleaftree.com/>
DEBUG: Crawled (200) <GET https://kennedy-s-pro-cuts.ueniweb.com/#contact_us> (referer: https://kennedy-s-pro-cuts.ueniweb.com/)
INFO: Ignoring response <403 http://www.rockstreeandhillside.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://kennedy-s-pro-cuts.ueniweb.com/>
{'emails': ['peter.kennedy600@gmail.com'],
 'facebook': 'https://www.facebook.com/share.php?u=https%3A%2F%2Fkennedy-s-pro-cuts.ueniweb.com&title=Kennedy%27s+Pro+Cuts',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/intent/tweet?text=Kennedy%27s+Pro+Cuts&url=https%3A%2F%2Fkennedy-s-pro-cuts.ueniweb.com'}
DEBUG: Crawled (200) <GET https://www.bartlett.com/contact-us.cfm> (referer: https://www.bartlett.com/locations/santa-monica-ca.cfm)
DEBUG: Crawled (200) <GET https://cervantestreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://goldenstatetreeserviceinc.com/> from <GET http://www.goldenstatetreeserviceinc.com/>
DEBUG: Crawled (200) <GET https://glts559.wixsite.com/greersstumps-1> (referer: None)
DEBUG: Crawled (200) <GET https://www.elitetreeinc.com/contact> (referer: https://www.elitetreeinc.com/)
DEBUG: Crawled (200) <GET https://www.kingtreeservices.com/contact-us/> (referer: https://www.kingtreeservices.com/)
DEBUG: Scraped from <200 https://www.bartlett.com/contact-us.cfm>
{'emails': [],
 'facebook': 'https://www.facebook.com/MellingerTreeService/',
 'instagram': 'https://www.instagram.com/lifeatbartlett/?hl=en/',
 'linkedin': 'https://www.linkedin.com/company/bartlett-tree-experts',
 'twitter': 'http://twitter.com/BartlettTreeExp'}
DEBUG: Crawled (403) <GET http://www.treeoflifetree.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.treeoflifetree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://goldenstatetreeserviceinc.com/> (referer: None)
DEBUG: Scraped from <200 https://www.elitetreeinc.com/contact>
{'emails': ['info@elitetreeinc.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.kingtreeservices.com/contact-us/>
{'emails': ['kingstreeservice11@yahoo.com'],
 'facebook': 'https://www.facebook.com/Kings-Tree-Service-160320150664555/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/kingstreesvc/media'}
DEBUG: Crawled (200) <GET http://www.professionaltreeservice.org/> (referer: None)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
INFO: Ignoring response <403 http://www.treeoflifetree.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.treeoflifetree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://jandrtreeservice.org/contact.html> (referer: http://jandrtreeservice.org/)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/menlo-park-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Menlo%20Park> (referer: None)
DEBUG: Crawled (200) <GET https://cervantestreeservices.com/contact-us> (referer: https://cervantestreeservices.com/)
DEBUG: Crawled (200) <GET https://njtreeworx.com/contact/> (referer: https://njtreeworx.com/)
DEBUG: Redirecting (301) to <GET https://www.bartlett.com/locations/redwood-city-ca.cfm> from <GET https://www.bartlett.com/locations/Redwood-City-CA.cfm>
DEBUG: Crawled (403) <GET http://www.reliabletreeserv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://goldenstatetreeserviceinc.com/contact-us> (referer: https://goldenstatetreeserviceinc.com/)
DEBUG: Crawled (200) <GET https://www.rgtreecare.com/> (referer: None)
DEBUG: Scraped from <200 http://jandrtreeservice.org/contact.html>
{'emails': ['Mail@Gardenhub.com'],
 'facebook': 'https://www.facebook.com/pg/JR-Tree-Service-708474745998669/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://cervantestreeservices.com/contact-us>
{'emails': ['team@latofonts.com',
            'impallari@gmail.com',
            'cervantestreeservices@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://njtreeworx.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/N-J-Tree-Service-112940604169867/',
 'instagram': 'https://www.instagram.com/njtreeservice_/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.professionaltreeservice.org/> (referer: None)
DEBUG: Crawled (200) <GET https://ectreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ectreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.reliabletreeserv.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://goldenstatetreeserviceinc.com/contact-us>
{'emails': ['info@indiantypefoundry.com'],
 'facebook': 'https://www.facebook.com/178166702799920',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.bartlett.com/locations/palo-alto-ca.cfm> from <GET https://www.bartlett.com/locations/redwood-city-ca.cfm>
DEBUG: Crawled (200) <GET http://www.professionaltreeservice.org/contact-us.html> (referer: http://www.professionaltreeservice.org/)
DEBUG: Crawled (200) <GET http://skistreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Crawled (200) <GET https://www.skylaketreeservice.com/contact-us> (referer: https://www.skylaketreeservice.com/)
DEBUG: Scraped from <200 http://www.professionaltreeservice.org/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://fallenleaftree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/fallenleaftreemanagement',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FallenLeafTree'}
DEBUG: Scraped from <200 https://www.skylaketreeservice.com/contact-us>
{'emails': ['some@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.charleston-tree.com/> from <GET http://www.charleston-tree.com/>
DEBUG: Redirecting (301) to <GET https://www.charleston-tree.com/> from <GET http://www.charleston-tree.com/>
DEBUG: Redirecting (301) to <GET https://www.treeservicebakersfield.com/> from <GET http://www.treeservicebakersfield.com/>
DEBUG: Crawled (200) <GET http://www.professionaltreeservice.org/contact-us.html> (referer: http://www.professionaltreeservice.org/)
DEBUG: Crawled (200) <GET https://www.rgtreecare.com/contact/> (referer: https://www.rgtreecare.com/)
DEBUG: Scraped from <200 http://www.professionaltreeservice.org/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.rgtreecare.com/contact/>
{'emails': ['info@rgtreecare.com'],
 'facebook': 'https://www.facebook.com/RGTREECARE/',
 'instagram': 'https://www.instagram.com/rollinggreeninc/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://ectreeservice.com/contact/> from <GET http://ectreeservice.com/contact/>
DEBUG: Redirecting (301) to <GET https://ectreeservice.com/contact/> from <GET http://ectreeservice.com/contact/>
DEBUG: Redirecting (307) to <GET https://www.wcainc.com/> from <GET http://www.wcainc.com/>
DEBUG: Redirecting (307) to <GET https://www.wcainc.com/> from <GET http://www.wcainc.com/>
DEBUG: Redirecting (301) to <GET https://aplustree.com/?utm_source=gmb&utm_medium=organic> from <GET http://www.aplustree.com/?utm_source=gmb&utm_medium=organic>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/menlo-park-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Menlo%20Park)
DEBUG: Crawled (200) <GET https://www.bartlett.com/locations/palo-alto-ca.cfm> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://christiansontreeexperts.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ectreeservice.com/contact/> (referer: None)
DEBUG: Crawled (200) <GET https://ectreeservice.com/contact/> (referer: None)
DEBUG: Crawled (200) <GET https://www.durkintreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treeservicebakersfield.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://loneoaktreeservice.com/> from <GET http://loneoaktreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.nvroots.com/> from <GET http://nvroots.com/>
DEBUG: Scraped from <200 https://ectreeservice.com/contact/>
{'emails': ['ectreeservice@yahoo.com'],
 'facebook': 'https://www.facebook.com/ectreeservice',
 'instagram': 'https://www.instagram.com/ectreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://stewartstreesvc.com/> from <GET http://www.stewartstreesvc.com/>
DEBUG: Crawled (200) <GET http://skistreeservice.com/index.html#contactus> (referer: http://skistreeservice.com/)
DEBUG: Crawled (403) <GET http://www.gastelumtreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.gastelumtreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.gastelumtreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://ectreeservice.com/contact/>
{'emails': ['ectreeservice@yahoo.com'],
 'facebook': 'https://www.facebook.com/ectreeservice',
 'instagram': 'https://www.instagram.com/ectreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bartlett.com/contact-us.cfm> (referer: https://www.bartlett.com/locations/palo-alto-ca.cfm)
DEBUG: Scraped from <200 http://skistreeservice.com/index.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.gastelumtreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.gastelumtreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.gastelumtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://charleston-tree.com/> from <GET https://www.charleston-tree.com/>
DEBUG: Scraped from <200 https://www.bartlett.com/contact-us.cfm>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/Bartlett-Tree-Experts/128790543841',
 'instagram': 'https://www.instagram.com/lifeatbartlett/?hl=en/',
 'linkedin': 'https://www.linkedin.com/company/bartlett-tree-experts',
 'twitter': 'http://twitter.com/BartlettTreeExp'}
DEBUG: Crawled (403) <GET http://www.newhousetreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://stewartstreesvc.com/> from <GET http://www.stewartstreesvc.com/>
DEBUG: Crawled (200) <GET https://www.californiatreesolutions.com/index.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.wcainc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.wcainc.com/> (referer: None)
INFO: Ignoring response <403 http://www.newhousetreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.gastelumtreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.gastelumtreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.gastelumtreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.newhousetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.durkintreeservice.com/contact/> (referer: https://www.durkintreeservice.com/)
INFO: Ignoring response <403 http://www.gastelumtreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.gastelumtreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.gastelumtreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.newhousetreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.durkintreeservice.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DurkinTreeService/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://charleston-tree.com/> from <GET https://www.charleston-tree.com/>
DEBUG: Crawled (200) <GET https://charlesgilberttreeservice-ca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://christiansontreeexperts.com/contact-us/> (referer: https://christiansontreeexperts.com/)
DEBUG: Crawled (200) <GET http://marintrees.com/> (referer: None)
DEBUG: Crawled (200) <GET http://marintrees.com/> (referer: None)
DEBUG: Scraped from <200 https://christiansontreeexperts.com/contact-us/>
{'emails': ['ed@christiansontreeexperts.com'],
 'facebook': 'https://www.facebook.com/Christianson-Tree-Experts-Co-324864840893123/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/TreeExperts'}
DEBUG: Crawled (200) <GET https://www.wcainc.com/#contact> (referer: https://www.wcainc.com/)
DEBUG: Crawled (200) <GET http://marintrees.com/> (referer: None)
DEBUG: Crawled (200) <GET http://marintrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.wcainc.com/#contact> (referer: https://www.wcainc.com/)
DEBUG: Crawled (200) <GET https://aplustree.com/?utm_source=gmb&utm_medium=organic> (referer: None)
DEBUG: Crawled (403) <GET http://www.silverleaftreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.wcainc.com/>
{'emails': ['wcahiring@wcainc.com', 'corporate@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://charlesgilberttreeservice-ca.com/> (referer: None)
DEBUG: Scraped from <200 https://www.wcainc.com/>
{'emails': ['wcahiring@wcainc.com', 'corporate@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://loneoaktreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.silverleaftreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.professionaltreecare.com/> from <GET http://www.professionaltreecare.com/>
DEBUG: Crawled (200) <GET https://charlesgilberttreeservice-ca.com/contact-us/> (referer: https://charlesgilberttreeservice-ca.com/)
DEBUG: Crawled (200) <GET https://www.nvroots.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.professionaltreecare.com/> from <GET http://www.professionaltreecare.com/>
DEBUG: Scraped from <200 https://charlesgilberttreeservice-ca.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://charleston-tree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://charlesgilberttreeservice-ca.com/contact-us/> (referer: https://charlesgilberttreeservice-ca.com/)
DEBUG: Redirecting (301) to <GET https://capitalarborists.com/> from <GET http://www.capitalarborists.com/>
DEBUG: Redirecting (301) to <GET https://capitalarborists.com/> from <GET http://www.capitalarborists.com/>
DEBUG: Crawled (200) <GET https://stewartstreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://stewartstreesvc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sanjosetreecutting.com/> from <GET http://www.sanjosetreecutting.com/>
DEBUG: Crawled (200) <GET https://www.professionaltreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treemasters.com/> (referer: None)
DEBUG: Scraped from <200 https://charlesgilberttreeservice-ca.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.a-1treeserviceinc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sanjosetreecutting.com/> from <GET http://www.sanjosetreecutting.com/>
DEBUG: Crawled (200) <GET https://www.professionaltreecare.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.jerrystreeservice.net/> (referer: None)
DEBUG: Crawled (200) <GET http://www.halseytreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.jerrystreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://charleston-tree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://stewartstreesvc.com/contact-us/> from <GET http://stewartstreesvc.com/contact-us/>
DEBUG: Redirecting (301) to <GET https://stewartstreesvc.com/contact-us/> from <GET http://stewartstreesvc.com/contact-us/>
DEBUG: Crawled (200) <GET http://www.joestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://loneoaktreeservice.com/contact-lone-oak/> (referer: https://loneoaktreeservice.com/)
DEBUG: Redirecting (301) to <GET https://charleston-tree.com/contact/> from <GET http://charleston-tree.com/contact/>
DEBUG: Scraped from <200 https://loneoaktreeservice.com/contact-lone-oak/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://aplustree.com/contact-us/> (referer: https://aplustree.com/?utm_source=gmb&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.nvroots.com/contact> (referer: https://www.nvroots.com/)
DEBUG: Crawled (200) <GET https://capitalarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://capitalarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://charleston-tree.com/contact/> (referer: None)
DEBUG: Scraped from <200 https://aplustree.com/contact-us/>
{'emails': ['marketing@aplustree.com', 'sherri@aplustree.com'],
 'facebook': 'https://www.facebook.com/aplustree/',
 'instagram': 'https://www.instagram.com/a.plus.tree/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.nvroots.com/contact>
{'emails': ['info@nvroots.com',
            'info@nvroots.com.',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'https://www.facebook.com/nevadarootstreeservice/',
 'instagram': 'https://www.instagram.com/nevadaroots/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.a-1treeserviceinc.com/contact-us/> (referer: https://www.a-1treeserviceinc.com/)
DEBUG: Scraped from <200 https://charleston-tree.com/contact/>
{'emails': ['charlestontreeservices@gmail.com', 'email@charlestontree.com'],
 'facebook': 'https://www.facebook.com/charlestontreeservices/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://charleston-tree.com/contact/> from <GET http://charleston-tree.com/contact/>
DEBUG: Crawled (200) <GET https://stewartstreesvc.com/contact-us/> (referer: None)
DEBUG: Crawled (200) <GET https://stewartstreesvc.com/contact-us/> (referer: None)
DEBUG: Scraped from <200 https://www.a-1treeserviceinc.com/contact-us/>
{'emails': ['a1landmanagement@gmail.com', 'A1LandManagement@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.professionaltreecare.com/contact> (referer: https://www.professionaltreecare.com/)
DEBUG: Crawled (200) <GET https://www.professionaltreecare.com/contact> (referer: https://www.professionaltreecare.com/)
DEBUG: Scraped from <200 https://stewartstreesvc.com/contact-us/>
{'emails': ['info@stewartstreesvc.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://stewartstreesvc.com/contact-us/>
{'emails': ['info@stewartstreesvc.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.professionaltreecare.com/contact>
{'emails': ['831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.professionaltreecare.com/contact>
{'emails': ['831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.sanjosetreecutting.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.garciasfenceandtreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sanjosetreecutting.com/> (referer: None)
DEBUG: Crawled (200) <GET https://charleston-tree.com/contact/> (referer: None)
DEBUG: Crawled (403) <GET http://www.communitytreeservice.net/> (referer: None)
INFO: Ignoring response <403 https://www.garciasfenceandtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://charleston-tree.com/contact/>
{'emails': ['charlestontreeservices@gmail.com', 'email@charlestontree.com'],
 'facebook': 'https://www.facebook.com/charlestontreeservices/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.mckinleyarborists.com/> from <GET http://mckinleyarborists.com/>
INFO: Ignoring response <403 http://www.communitytreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://quinonestreeservice.com/> from <GET http://www.quinonestreeservice.com/>
DEBUG: Crawled (200) <GET https://capitalarborists.com/contact/> (referer: https://capitalarborists.com/)
DEBUG: Crawled (200) <GET https://capitalarborists.com/contact/> (referer: https://capitalarborists.com/)
DEBUG: Crawled (200) <GET https://treetrimmingsanclemente.com/> (referer: None)
DEBUG: Retrying <GET http://hanfordtree.com/contact-2/> (failed 1 times): 500 Internal Server Error
DEBUG: Scraped from <200 https://capitalarborists.com/contact/>
{'emails': ['info@capitalarborists.com'],
 'facebook': 'https://www.facebook.com/capitalarborists/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://capitalarborists.com/contact/>
{'emails': ['info@capitalarborists.com'],
 'facebook': 'https://www.facebook.com/capitalarborists/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://delhitreesservices.weebly.com/> (referer: None)
DEBUG: Crawled (200) <GET https://delhitreesservices.weebly.com/> (referer: None)
DEBUG: Retrying <GET http://hanfordtree.com/contact-2/> (failed 2 times): 500 Internal Server Error
DEBUG: Crawled (200) <GET https://www.leontreeservicesinc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://renotahoetreeservice.com/> from <GET http://renotahoetreeservice.com/>
DEBUG: Crawled (200) <GET https://treetrimmingsanclemente.com/contact-luna-tree-service.php> (referer: https://treetrimmingsanclemente.com/)
DEBUG: Crawled (200) <GET http://www.marincountyarborists.com/> (referer: None)
ERROR: Gave up retrying <GET http://hanfordtree.com/contact-2/> (failed 3 times): 500 Internal Server Error
DEBUG: Crawled (500) <GET http://hanfordtree.com/contact-2/> (referer: None)
INFO: Ignoring response <500 http://hanfordtree.com/contact-2/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://treetrimmingsanclemente.com/contact-luna-tree-service.php>
{'emails': [],
 'facebook': 'https://www.facebook.com/TreeTrimmingOrangeCounty/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.wilhelmllc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sanjosetreecutting.com/contact> (referer: https://www.sanjosetreecutting.com/)
DEBUG: Crawled (200) <GET https://delhitreesservices.weebly.com/contact.html> (referer: https://delhitreesservices.weebly.com/)
DEBUG: Crawled (200) <GET https://delhitreesservices.weebly.com/contact.html> (referer: https://delhitreesservices.weebly.com/)
DEBUG: Crawled (200) <GET https://www.sanjosetreecutting.com/contact> (referer: https://www.sanjosetreecutting.com/)
DEBUG: Crawled (200) <GET https://mileystreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://mileystreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.urbantree.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.wilhelmllc.com/> (referer: None)
DEBUG: Scraped from <200 https://www.sanjosetreecutting.com/contact>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://delhitreesservices.weebly.com/contact.html>
{'emails': ['delhitreesservices@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://delhitreesservices.weebly.com/contact.html>
{'emails': ['delhitreesservices@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (409) <GET https://www.leontreeservicesinc.com/contact.php> (referer: None)
DEBUG: Crawled (200) <GET https://treemasters.com/contact-us/> (referer: https://treemasters.com/)
DEBUG: Crawled (200) <GET http://www.marincountyarborists.com/contact.php> (referer: http://www.marincountyarborists.com/)
DEBUG: Scraped from <200 https://www.sanjosetreecutting.com/contact>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://renotahoetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.mckinleyarborists.com/> (referer: None)
INFO: Ignoring response <409 https://www.leontreeservicesinc.com/contact.php>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://treemasters.com/contact-us/>
{'emails': ['treemasters@treemasters.com'],
 'facebook': 'https://www.facebook.com/Treemasters-372883788818/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/Treemasters'}
DEBUG: Scraped from <200 http://www.marincountyarborists.com/contact.php>
{'emails': ['customerservice@marincountyarborists.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.wilhelmllc.com/contact> (referer: https://www.wilhelmllc.com/)
DEBUG: Crawled (200) <GET http://www.urbantree.org/contact.shtml> (referer: http://www.urbantree.org/)
DEBUG: Scraped from <200 https://www.wilhelmllc.com/contact>
{'emails': ['info@wilhelmllc.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'dd0a55ccb8124b9c9d938e3acf41f8aa@sentry.wixpress.com',
            'info@mysite.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com'],
 'facebook': 'https://www.facebook.com/wilhelmllc',
 'instagram': 'https://www.instagram.com/wilhelmllc/',
 'linkedin': 'https://www.linkedin.com/company/wilhelmllc/',
 'twitter': 'https://twitter.com/WilhelmLLC'}
DEBUG: Crawled (200) <GET https://www.wilhelmllc.com/contact> (referer: https://www.wilhelmllc.com/)
DEBUG: Scraped from <200 http://www.urbantree.org/contact.shtml>
{'emails': ['webmaster@kentdev.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://jimmiestreecompany.com/> from <GET http://www.jimmiestreecompany.com/>
DEBUG: Scraped from <200 https://www.wilhelmllc.com/contact>
{'emails': ['info@wilhelmllc.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'dd0a55ccb8124b9c9d938e3acf41f8aa@sentry.wixpress.com',
            'info@mysite.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '8eb368c655b84e029ed79ad7a5c1718e@sentry.wixpress.com'],
 'facebook': 'https://www.facebook.com/wilhelmllc',
 'instagram': 'https://www.instagram.com/wilhelmllc/',
 'linkedin': 'https://www.linkedin.com/company/wilhelmllc/',
 'twitter': 'https://twitter.com/WilhelmLLC'}
DEBUG: Crawled (200) <GET https://mileystreeservice.com/contact-me/> (referer: https://mileystreeservice.com/)
DEBUG: Redirecting (301) to <GET https://provhort.com/> from <GET http://www.provhort.com/>
DEBUG: Crawled (200) <GET https://www.vtstreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://mileystreeservice.com/contact-me/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://jimmiestreecompany.com/> (referer: None)
DEBUG: Crawled (200) <GET https://mileystreeservice.com/contact-me/> (referer: https://mileystreeservice.com/)
DEBUG: Crawled (200) <GET http://loraxtreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://newburyparktree.com/> from <GET http://newburyparktree.com/>
DEBUG: Scraped from <200 https://mileystreeservice.com/contact-me/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.fisktreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.adamstreeservice.org/about-us.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.vtstreeservice.com/contact/> (referer: https://www.vtstreeservice.com/)
DEBUG: Crawled (200) <GET http://www.mckinleyarborists.com/contact-us/> (referer: http://www.mckinleyarborists.com/)
DEBUG: Scraped from <200 https://www.vtstreeservice.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.mckinleyarborists.com/contact-us/>
{'emails': ['william@mckinleyarborists.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/bill-mckinley-4262b664/',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.adamstreeservice.org/about-us.html> (referer: None)
DEBUG: Crawled (200) <GET http://torostreeservice.com/contact.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.vtstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.vtstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.adamstreeservice.org/contact.html> (referer: https://www.adamstreeservice.org/about-us.html)
DEBUG: Crawled (200) <GET https://www.fisktreesvc.com/contact.html> (referer: https://www.fisktreesvc.com/)
DEBUG: Redirecting (301) to <GET https://lepleytreesservice.com/> from <GET http://lepleytreesservice.com/>
DEBUG: Scraped from <200 https://www.adamstreeservice.org/contact.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/Adams-Tree-Service-1566642230319508',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.fisktreesvc.com/contact.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/Fisks-Tree-Excavating-Service-1429871923805110/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.adamstreeservice.org/contact.html> (referer: https://www.adamstreeservice.org/about-us.html)
DEBUG: Crawled (403) <GET https://www.gastelumtreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://newburyparktree.com/> (referer: None)
INFO: Ignoring response <403 https://www.gastelumtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Scraped from <200 https://www.adamstreeservice.org/contact.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/Adams-Tree-Service-1566642230319508',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://caltlc.com/> from <GET http://caltlc.com/>
DEBUG: Crawled (200) <GET http://torostreeservice.com/contact.html> (referer: http://torostreeservice.com/contact.html)
DEBUG: Crawled (200) <GET https://www.vtstreeservice.com/contact/> (referer: https://www.vtstreeservice.com/)
DEBUG: Crawled (200) <GET https://www.vtstreeservice.com/contact/> (referer: https://www.vtstreeservice.com/)
DEBUG: Crawled (200) <GET https://provhort.com/> (referer: None)
DEBUG: Scraped from <200 http://torostreeservice.com/contact.html>
{'emails': ['TorosTreeCare@hotmail.com',
            'torostreecare@hotmail.com',
            'Torostreecare@hotmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.vtstreeservice.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.vtstreeservice.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://newburyparktree.com/contact/> (referer: https://newburyparktree.com/)
DEBUG: Crawled (200) <GET http://www.coastaltreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.coastaltreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.experttreenv.com/> from <GET http://experttreenv.com/>
DEBUG: Redirecting (302) to <GET https://lepleytreesservice.com/site-cannot-be-accessed-from-your-current-location.html> from <GET https://lepleytreesservice.com/>
DEBUG: Scraped from <200 https://newburyparktree.com/contact/>
{'emails': ['info@newburyparktree.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET https://www.lopeztreeservicemonterey.com/> (referer: None)
DEBUG: Crawled (200) <GET https://lepleytreesservice.com/site-cannot-be-accessed-from-your-current-location.html> (referer: None)
INFO: Ignoring response <403 https://www.lopeztreeservicemonterey.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://provhort.com/about-us/contact-us/> (referer: https://provhort.com/)
DEBUG: Crawled (200) <GET https://renotahoetreeservice.com/contact/> (referer: https://renotahoetreeservice.com/)
WARNING: Remote certificate is not valid for hostname "www.happygrowinglandscaping.com"; VerificationError(errors=[DNSMismatch(mismatched_id=DNS_ID(hostname=b'www.happygrowinglandscaping.com'))])
DEBUG: Redirecting (301) to <GET http://shaverlakefun.org> from <GET http://shaverlakepowercenter.com/>
DEBUG: Scraped from <200 https://provhort.com/about-us/contact-us/>
{'emails': ['info@provhort.com'],
 'facebook': 'https://www.facebook.com/TreeDoctoRx/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://renotahoetreeservice.com/contact/>
{'emails': ['treeservice.rtr@gmail.com'],
 'facebook': 'https://www.facebook.com/',
 'instagram': 'https://www.instagram.com/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/'}
DEBUG: Crawled (200) <GET https://treeremovalsanmateo.com/> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 44, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.martinezlandscapeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://gomeztreecare.webs.com/> from <GET http://gomeztreecare.webs.com/>
DEBUG: Crawled (200) <GET http://www.coastaltreeservice.com/contact> (referer: http://www.coastaltreeservice.com/)
DEBUG: Crawled (200) <GET http://www.coastaltreeservice.com/contact> (referer: http://www.coastaltreeservice.com/)
DEBUG: Redirecting (301) to <GET https://happygrowinglandscaping.com/> from <GET https://www.happygrowinglandscaping.com/>
DEBUG: Crawled (200) <GET https://caltlc.com/> (referer: None)
DEBUG: Scraped from <200 http://www.coastaltreeservice.com/contact>
{'emails': [],
 'facebook': 'http://www.facebook.com/CoastalTreeService',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.coastaltreeservice.com/contact>
{'emails': [],
 'facebook': 'http://www.facebook.com/CoastalTreeService',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.martinezlandscapeservice.com/contact-us/> (referer: https://www.martinezlandscapeservice.com/)
DEBUG: Redirecting (301) to <GET https://experiencedgardener.com/> from <GET http://www.experiencedgardener.com/>
DEBUG: Redirecting (301) to <GET https://www.kingtreeservices.com/> from <GET http://kingtreeservices.com/>
DEBUG: Scraped from <200 https://www.martinezlandscapeservice.com/contact-us/>
{'emails': ['amartinez@martunezlandscapeservice.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://caltlc.com/contact-us/> from <GET https://caltlc.com/contact>
DEBUG: Crawled (200) <GET https://gomeztreecare.webs.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.experttreenv.com/> (referer: None)
DEBUG: Crawled (200) <GET https://caltlc.com/contact-us/> (referer: https://caltlc.com/)
DEBUG: Crawled (200) <GET https://happygrowinglandscaping.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://durkintreeservice.com/> from <GET http://durkintreeservice.com/>
DEBUG: Scraped from <200 https://caltlc.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/gordon.mann.568',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/gordon-mann-rca-480-059927/',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://shaverlakefun.org> (referer: None)
DEBUG: Crawled (200) <GET https://gomeztreecare.webs.com/contact-us> (referer: https://gomeztreecare.webs.com/)
DEBUG: Scraped from <200 https://gomeztreecare.webs.com/contact-us>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://orionlandscapeco.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.kingtreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://durkintreeservice.com/> from <GET http://durkintreeservice.com/>
DEBUG: Crawled (200) <GET https://happygrowinglandscaping.com/contact/> (referer: https://happygrowinglandscaping.com/)
DEBUG: Crawled (200) <GET https://experiencedgardener.com/> (referer: None)
DEBUG: Scraped from <200 https://happygrowinglandscaping.com/contact/>
{'emails': ['info@happygrowinglandscaping.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://leadinjection.io/landscape/#contact> (referer: http://orionlandscapeco.com/)
DEBUG: Crawled (200) <GET https://quinonestreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.durkintreeservice.com/> from <GET https://durkintreeservice.com/>
DEBUG: Scraped from <200 https://leadinjection.io/landscape/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.durkintreeservice.com/> from <GET https://durkintreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.kingtreeservices.com/contact-us/> from <GET https://www.kingtreeservices.com/contact-us>
DEBUG: Crawled (200) <GET https://www.durkintreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://experiencedgardener.com/contact-us/> (referer: https://experiencedgardener.com/)
DEBUG: Crawled (200) <GET https://www.durkintreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.durkintreeservice.com/contact/> (referer: https://www.durkintreeservice.com/)
DEBUG: Scraped from <200 https://experiencedgardener.com/contact-us/>
{'emails': ['info@experiencedgardener.com'],
 'facebook': ' https://www.facebook.com/theexperiencedgardener',
 'instagram': 'https://www.instagram.com/theexperiencedgardener/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.kingtreeservices.com/contact-us/> (referer: https://www.kingtreeservices.com/)
DEBUG: Crawled (200) <GET https://quinonestreeservice.com/contact-us/> (referer: https://quinonestreeservice.com/)
DEBUG: Scraped from <200 https://www.durkintreeservice.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DurkinTreeService/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.kingtreeservices.com/contact-us/>
{'emails': ['kingstreeservice11@yahoo.com'],
 'facebook': 'https://www.facebook.com/Kings-Tree-Service-160320150664555/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/kingstreesvc/media'}
DEBUG: Scraped from <200 https://quinonestreeservice.com/contact-us/>
{'emails': ['info@quinonestreeservice.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.durkintreeservice.com/contact/> (referer: https://www.durkintreeservice.com/)
DEBUG: Scraped from <200 https://www.durkintreeservice.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DurkinTreeService/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Crawled 430 pages (at 430 pages/min), scraped 166 items (at 166 items/min)
ERROR: Gave up retrying <GET http://www.alliancetrees.com/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Error downloading <GET http://www.alliancetrees.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 6,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 165026,
 'downloader/request_count': 581,
 'downloader/request_method_count/GET': 581,
 'downloader/response_bytes': 12894548,
 'downloader/response_count': 575,
 'downloader/response_status_count/200': 368,
 'downloader/response_status_count/301': 133,
 'downloader/response_status_count/302': 5,
 'downloader/response_status_count/307': 3,
 'downloader/response_status_count/308': 2,
 'downloader/response_status_count/403': 60,
 'downloader/response_status_count/409': 1,
 'downloader/response_status_count/500': 3,
 'elapsed_time_seconds': 70.029529,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 10, 15, 7, 35, 142193),
 'httpcompression/response_bytes': 52131626,
 'httpcompression/response_count': 389,
 'httperror/response_ignored_count': 62,
 'httperror/response_ignored_status_count/403': 60,
 'httperror/response_ignored_status_count/409': 1,
 'httperror/response_ignored_status_count/500': 1,
 'item_scraped_count': 166,
 'log_count/DEBUG': 752,
 'log_count/ERROR': 6,
 'log_count/INFO': 73,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 430,
 'retry/count': 6,
 'retry/max_reached': 3,
 'retry/reason_count/500 Internal Server Error': 2,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'scheduler/dequeued': 581,
 'scheduler/dequeued/memory': 581,
 'scheduler/enqueued': 581,
 'scheduler/enqueued/memory': 581,
 'start_time': datetime.datetime(2022, 12, 10, 15, 6, 25, 112664)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 7dc3bc25e1fb29e2
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (meta refresh) to <GET https://www.facebook.com/ads/library/?active_status=all&ad_type=all&country=US&view_all_page_id=108448151941309&sort_data%5Bdirection%5D=desc&sort_data%5Bmode%5D=relevancy_monthly_grouped&search_type=page&media_type=all&_fb_noscript=1> from <GET https://www.facebook.com/ads/library/?active_status=all&ad_type=all&country=US&view_all_page_id=108448151941309&sort_data%5Bdirection%5D=desc&sort_data%5Bmode%5D=relevancy_monthly_grouped&search_type=page&media_type=all>
DEBUG: Attempting to acquire lock 2307337890848 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2307337890848 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2307337890848 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2307337890848 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.facebook.com/ads/library/?active_status=all&ad_type=all&country=US&view_all_page_id=108448151941309&sort_data%5Bdirection%5D=desc&sort_data%5Bmode%5D=relevancy_monthly_grouped&search_type=page&media_type=all&_fb_noscript=1> (referer: None)
ERROR: Spider error processing <GET https://www.facebook.com/ads/library/?active_status=all&ad_type=all&country=US&view_all_page_id=108448151941309&sort_data%5Bdirection%5D=desc&sort_data%5Bmode%5D=relevancy_monthly_grouped&search_type=page&media_type=all&_fb_noscript=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\twisted\internet\defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\spiders\__init__.py", line 67, in _parse
    return self.parse(response, **kwargs)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\tester_meta.py", line 34, in parse
    if "secure" in cookie:
TypeError: a bytes-like object is required, not 'str'
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 835,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 160644,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 1.484938,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 10, 15, 9, 30, 455181),
 'httpcompression/response_bytes': 672039,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 9,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2022, 12, 10, 15, 9, 28, 970243)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: b77f30b40ff0f233
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 3011360292048 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 3011360292048 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 3011360292048 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 3011360292048 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (302) to <GET http://www.sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Scraped from <200 https://www.caltreeservice.com/contact-us>
{'emails': ['office@caltreeservice.com'],
 'facebook': 'https://www.facebook.com/samcolemanluxury',
 'instagram': 'https://www.instagram.com/samcolemanluxury/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://octreeservices.com/contact-us/>
{'emails': ['octreeservices1@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/coast/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsteroftheCoast/',
 'instagram': 'https://www.instagram.com/monsterofthecoast/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Scraped from <200 https://westcoastarborists.com/>
{'emails': ['corporate@wcainc.com', 'wcahiring@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://rndtreeservices.com/contact-us>
{'emails': ['filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/106157038650413',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.monstertreeservice.com/west-valley/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/Monster-Tree-Service-of-West-Valley-1287919078019258/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/'}
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Scraped from <200 https://www.modestotreeservicecompany.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.monstertreeservice.com/south-bay/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Monster-Tree-Service-of-South-Bay-1088163361240866/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Scraped from <200 http://www.specializedtreeworks.com/contact.html>
{'emails': ['ContactUs@specializedtreeworks.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite> (referer: None)
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Scraped from <200 https://www.tomdaytreeservice.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/TomDayTreeService/reviews/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://arborworksinc.com/contact/>
{'emails': ['information@arborworksinc.com'],
 'facebook': 'https://www.facebook.com/arborworks1/',
 'instagram': 'https://www.instagram.com/arborworksllc/',
 'linkedin': 'https://www.linkedin.com/company/arborworksinc',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Scraped from <200 https://www.traversotree.com/contacts/>
{'emails': ['Office@traversotree.com', 'office@traversotree.com'],
 'facebook': 'https://www.facebook.com/traversotree',
 'instagram': 'https://www.instagram.com/traversotree/?hl=en',
 'linkedin': 'https://www.linkedin.com/pub/traverso-tree-service/38/6a3/a40',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
DEBUG: Scraped from <200 https://losangelesca-treeservice.com/contact>
{'emails': ['losangelescatreeservice@gmail.com',
            'u003Elosangelescatreeservice@gmail.com'],
 'facebook': 'https://www.facebook.com/losangelescatreeservice/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/contact.html> (referer: http://www.blackbeartrees.com/)
DEBUG: Scraped from <200 http://www.vetreeservice.com/contactus.html>
{'emails': ['dns@technologydimensions.com',
            'Ashleigh@vetreeservice.com',
            'Patti@vetreeservice.com',
            'Vic@vetreeservice.com',
            'patti@vetreeservice.com',
            'Ed@vetreeservice.com',
            'Eric@vetreeservice.com',
            'John@vetreeservice.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://bayareatreespecialists.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Bay-Area-Tree-Specialists-658134177581480/?timeline_context_item_type=intro_card_work&timeline_context_item_source=100007956785104',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/TreesSpecialist'}
DEBUG: Scraped from <200 http://www.blackbeartrees.com/contact.html>
{'emails': ['blackbeartreeservice559@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/contact/privacy/> (referer: https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite)
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Scraped from <200 https://www.tiptoparborists.com/contact/privacy/>
{'emails': ['privacy@reachlocal.com.'],
 'facebook': 'https://www.facebook.com/pg/Tip-Top-Arborists-Inc-608355719230396/reviews/',
 'instagram': 'https://www.instagram.com/tip_top_arborists/',
 'linkedin': 'https://www.linkedin.com/company/tip-top-arborists',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Scraped from <200 https://fallenleaftree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/fallenleaftreemanagement',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FallenLeafTree'}
DEBUG: Scraped from <200 http://www.aearborists.com/contact-us/>
{'emails': ['aearborists@gmail.com'],
 'facebook': 'https://www.facebook.com/AE-Arborists-Tree-Care-428707717460988/ ',
 'instagram': 'https://www.instagram.com/aearborists/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/aearborists'}
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Scraped from <200 https://californiagreentreecare.com/contact.php>
{'emails': ['info@californiagreentreecare.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_conte5%22> (referer: None)
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Scraped from <200 https://www.herculestreeservice.com/contact/>
{'emails': ['info@herculestreeservice.com'],
 'facebook': 'https://www.facebook.com/510799tree/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://jesustreeserviceandlandscaping.com/contact/>
{'emails': ['jesusjgr1987@gmail.com'],
 'facebook': 'https://www.facebook.com/Jesus-Tree-Services-Landscaping-104850001236628',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['dillanmcather@gmail.com', 'sales@shipmantree.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Scraped from <200 https://cutitrighttreeservicefresno.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Scraped from <200 https://www.sequoiastreeservice.com/>
{'emails': ['evencio.martinez@yahoo.com'],
 'facebook': 'https://www.facebook.com/Sequoias-Tree-Service-104264014496885/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['dillanmcather@gmail.com', 'sales@shipmantree.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://foresttreeservices.com/contact-us/>
{'emails': ['info@foresttreeservices.com'],
 'facebook': 'https://www.facebook.com/foresttreeservices',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/company/forest-tree-services/about/',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET https://www.adolphstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
INFO: Ignoring response <403 https://www.adolphstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Scraped from <200 https://foresttreeservices.com/contact-us/>
{'emails': ['info@foresttreeservices.com'],
 'facebook': 'https://www.facebook.com/foresttreeservices',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/company/forest-tree-services/about/',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_conte5%22)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['info@mowbrays.com', 'customerservice@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.commercialtreeservices.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/commercialtreeservices',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Redirecting (301) to <GET https://www.eastbaytreeservice.com/> from <GET http://www.eastbaytreeservice.com/>
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Scraped from <200 https://cutitrighttreeservicefresno.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Scraped from <200 https://www.theneckofthewoods.com/contact-us.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/eddie.farquharson',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Redirecting (301) to <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> from <GET https://www.gomezlandscapeandtreecare.com/contact.php>
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.affordabletreeservicesorangecounty.com/> from <GET http://www.affordabletreeservicesorangecounty.com/>
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> (referer: https://www.gomezlandscapeandtreecare.com/)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php>
{'emails': ['sales@gomezltc.com'],
 'facebook': '//www.facebook.com/Gomez-Landscape-Tree-Care-Inc-885181728164027/',
 'instagram': '//www.instagram.com/gomezlandscapetreecare/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.atlas-tree.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/AtlasTreeSurgery',
 'instagram': 'https://www.instagram.com/atlas.tree/',
 'linkedin': 'https://www.linkedin.com/company/atlas-tree-landscape-inc/about/',
 'twitter': 'https://twitter.com/atlas_and'}
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.eastbaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://www.treeserviceroseville.com/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
DEBUG: Scraped from <200 https://www.a1treeredding.com/contact/>
{'emails': ['Office@a1treeredding.com', 'office@a1treeredding.com'],
 'facebook': 'https://www.facebook.com/A1treeredding/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://stocktontreeservices.com/> from <GET https://www.stocktontreeservices.com/>
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/index.html#contact> (referer: http://www.abotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
DEBUG: Scraped from <200 http://www.abotreeservice.com/index.html>
{'emails': ['operation@abotreeservice.com',
            'krasimira.stoyanova@deluxe.com',
            'info@abotreeservice.com'],
 'facebook': 'https://www.facebook.com/abotreeservice',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/abotreeservice',
 'twitter': 'https://twitter.com/abotreeservice'}
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/contact-us/> (referer: https://www.affordabletreeservicesorangecounty.com/)
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['info@mowbrays.com', 'customerservice@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.affordabletreeservicesorangecounty.com/contact-us/>
{'emails': ['treeremovaloc@gmail.com', '20treeremovaloc@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Scraped from <200 https://ranchotreeservice.com/contact/>
{'emails': ['info@ranchotreeservice.com'],
 'facebook': 'https://www.facebook.com/Rancho-Tree-Service-109046575024387',
 'instagram': 'https://www.instagram.com/ranchotreeservice/',
 'linkedin': 'https://www.linkedin.com/company/rancho-inc-california/',
 'twitter': 'https://twitter.com/RanchoTree'}
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://jtstree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/category/Shopping---Retail/Jts-Inc-510518789043998/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://ranchotreeservice.com/contact/>
{'emails': ['info@ranchotreeservice.com'],
 'facebook': 'https://www.facebook.com/Rancho-Tree-Service-109046575024387',
 'instagram': 'https://www.instagram.com/ranchotreeservice/',
 'linkedin': 'https://www.linkedin.com/company/rancho-inc-california/',
 'twitter': 'https://twitter.com/RanchoTree'}
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/contact-2/> (referer: https://stocktontreeservices.com/)
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Scraped from <200 https://stocktontreeservices.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Scraped from <200 https://dprotreeservice.com/contact-us/>
{'emails': ['d.protreeservice@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
DEBUG: Scraped from <200 https://jtstree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/category/Shopping---Retail/Jts-Inc-510518789043998/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.stevestreeservice.net/> from <GET http://www.stevestreeservice.net/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.buenavistatree.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.runyonstree.com/> (referer: None)
INFO: Ignoring response <403 http://www.buenavistatree.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 https://www.runyonstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://navastree.wixsite.com/my-site> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 44, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.lunatreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (403) <GET https://www.petestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
DEBUG: Redirecting (301) to <GET https://arbortask.com/> from <GET http://www.arbortask.com/>
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
INFO: Ignoring response <403 http://www.lunatreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 https://www.petestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Crawled (200) <GET http://acutabovetreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Crawled (200) <GET http://acutabovetreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/contact/> (referer: https://www.stevestreeservice.net/)
DEBUG: Scraped from <200 https://www.stevestreeservice.net/contact/>
{'emails': ['steves8733@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
DEBUG: Scraped from <200 https://greenzwaytreeservice.com/contact/>
{'emails': ['greenzway@hotmail.com', 'Greenzway@hotmail.com'],
 'facebook': 'https://www.facebook.com/pg/greenzway',
 'instagram': 'https://www.instagram.com/greenzway_official',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Scraped from <200 https://treeservicemantecaca.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arbortask.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
DEBUG: Scraped from <200 https://bunyonbros.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/bunyonbrostreeserviceSLO',
 'instagram': 'https://www.instagram.com/bunyonbrostreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Redirecting (301) to <GET https://arbortask.com/contact/> from <GET https://arbortask.com/contact>
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Scraped from <200 https://treeservicemantecaca.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.lctrees.com/contact/>
{'emails': ['info@lctrees.com'],
 'facebook': 'https://www.facebook.com/LC-Tree-Service-162733330551792/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Scraped from <200 https://www.lctrees.com/contact/>
{'emails': ['info@lctrees.com'],
 'facebook': 'https://www.facebook.com/LC-Tree-Service-162733330551792/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arbortask.com/contact/> (referer: https://arbortask.com/)
DEBUG: Scraped from <200 https://arbortask.com/contact/>
{'emails': ['almangrant@yahoo.com'],
 'facebook': 'https://www.facebook.com/arbortasktreeservice/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/contact-us/> (referer: http://www.lewistreeserviceinc.com/)
DEBUG: Scraped from <200 http://www.lewistreeserviceinc.com/contact-us/>
{'emails': ['Admin@lewistreeserviceinc.com', 'admin@lewistreeserviceinc.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Crawled 209 pages (at 209 pages/min), scraped 79 items (at 79 items/min)
ERROR: Gave up retrying <GET http://www.alliancetrees.com/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Error downloading <GET http://www.alliancetrees.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 85329,
 'downloader/request_count': 278,
 'downloader/request_method_count/GET': 278,
 'downloader/response_bytes': 6511544,
 'downloader/response_count': 275,
 'downloader/response_status_count/200': 177,
 'downloader/response_status_count/301': 60,
 'downloader/response_status_count/302': 3,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/308': 2,
 'downloader/response_status_count/403': 32,
 'elapsed_time_seconds': 70.680097,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 10, 15, 29, 55, 58330),
 'httpcompression/response_bytes': 27833158,
 'httpcompression/response_count': 190,
 'httperror/response_ignored_count': 32,
 'httperror/response_ignored_status_count/403': 32,
 'item_scraped_count': 79,
 'log_count/DEBUG': 363,
 'log_count/ERROR': 3,
 'log_count/INFO': 43,
 'request_depth_max': 1,
 'response_received_count': 209,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'scheduler/dequeued': 278,
 'scheduler/dequeued/memory': 278,
 'scheduler/enqueued': 278,
 'scheduler/enqueued/memory': 278,
 'start_time': datetime.datetime(2022, 12, 10, 15, 28, 44, 378233)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 3afbb3a5a245331c
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2225737239952 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2225737239952 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2225737239952 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2225737239952 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
DEBUG: Scraped from <200 https://www.caltreeservice.com/contact-us>
{'emails': ['office@caltreeservice.com'],
 'facebook': 'https://www.facebook.com/samcolemanluxury',
 'instagram': 'https://www.instagram.com/samcolemanluxury/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/coast/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsteroftheCoast/',
 'instagram': 'https://www.instagram.com/monsterofthecoast/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/south-bay/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Monster-Tree-Service-of-South-Bay-1088163361240866/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://octreeservices.com/contact-us/>
{'emails': ['octreeservices1@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/west-valley/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/Monster-Tree-Service-of-West-Valley-1287919078019258/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/'}
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Scraped from <200 https://rndtreeservices.com/contact-us>
{'emails': ['filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/106157038650413',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://westcoastarborists.com/>
{'emails': ['wcahiring@wcainc.com', 'corporate@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.specializedtreeworks.com/contact.html>
{'emails': ['ContactUs@specializedtreeworks.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite> (referer: None)
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.modestotreeservicecompany.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.tomdaytreeservice.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/TomDayTreeService/reviews/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
DEBUG: Scraped from <200 https://losangelesca-treeservice.com/contact>
{'emails': ['u003Elosangelescatreeservice@gmail.com',
            'losangelescatreeservice@gmail.com'],
 'facebook': 'https://www.facebook.com/losangelescatreeservice/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://arborworksinc.com/contact/>
{'emails': ['information@arborworksinc.com'],
 'facebook': 'https://www.facebook.com/arborworks1/',
 'instagram': 'https://www.instagram.com/arborworksllc/',
 'linkedin': 'https://www.linkedin.com/company/arborworksinc',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/contact.html> (referer: http://www.blackbeartrees.com/)
DEBUG: Scraped from <200 https://bayareatreespecialists.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Bay-Area-Tree-Specialists-658134177581480/?timeline_context_item_type=intro_card_work&timeline_context_item_source=100007956785104',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/TreesSpecialist'}
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Scraped from <200 http://www.vetreeservice.com/contactus.html>
{'emails': ['Vic@vetreeservice.com',
            'Ed@vetreeservice.com',
            'Ashleigh@vetreeservice.com',
            'patti@vetreeservice.com',
            'Patti@vetreeservice.com',
            'John@vetreeservice.com',
            'dns@technologydimensions.com',
            'Eric@vetreeservice.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.blackbeartrees.com/contact.html>
{'emails': ['blackbeartreeservice559@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Scraped from <200 https://www.traversotree.com/contacts/>
{'emails': ['Office@traversotree.com', 'office@traversotree.com'],
 'facebook': 'https://www.facebook.com/traversotree',
 'instagram': 'https://www.instagram.com/traversotree/?hl=en',
 'linkedin': 'https://www.linkedin.com/pub/traverso-tree-service/38/6a3/a40',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/contact/privacy/> (referer: https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite)
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Scraped from <200 http://www.aearborists.com/contact-us/>
{'emails': ['aearborists@gmail.com'],
 'facebook': 'https://www.facebook.com/AE-Arborists-Tree-Care-428707717460988/ ',
 'instagram': 'https://www.instagram.com/aearborists/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/aearborists'}
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Scraped from <200 https://www.tiptoparborists.com/contact/privacy/>
{'emails': ['privacy@reachlocal.com.'],
 'facebook': 'https://www.facebook.com/pg/Tip-Top-Arborists-Inc-608355719230396/reviews/',
 'instagram': 'https://www.instagram.com/tip_top_arborists/',
 'linkedin': 'https://www.linkedin.com/company/tip-top-arborists',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/contact> (referer: https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Scraped from <200 https://www.bigtstrees.com/contact>
{'emails': ['igtstrees@yahoo.com',
            'bigtstrees@yahoo.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'http://www.facebook.com/BigTsTrees',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://californiagreentreecare.com/contact.php>
{'emails': ['info@californiagreentreecare.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
DEBUG: Scraped from <200 https://fallenleaftree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/fallenleaftreemanagement',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FallenLeafTree'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Crawled (403) <GET https://www.adolphstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
INFO: Ignoring response <403 https://www.adolphstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Scraped from <200 https://www.herculestreeservice.com/contact/>
{'emails': ['info@herculestreeservice.com'],
 'facebook': 'https://www.facebook.com/510799tree/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://jesustreeserviceandlandscaping.com/contact/>
{'emails': ['jesusjgr1987@gmail.com'],
 'facebook': 'https://www.facebook.com/Jesus-Tree-Services-Landscaping-104850001236628',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
DEBUG: Scraped from <200 https://www.commercialtreeservices.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/commercialtreeservices',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Scraped from <200 https://www.a1treeredding.com/contact/>
{'emails': ['Office@a1treeredding.com', 'office@a1treeredding.com'],
 'facebook': 'https://www.facebook.com/A1treeredding/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['dillanmcather@gmail.com', 'sales@shipmantree.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> from <GET https://www.gomezlandscapeandtreecare.com/contact.php>
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Scraped from <200 https://cutitrighttreeservicefresno.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.atlas-tree.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/AtlasTreeSurgery',
 'instagram': 'https://www.instagram.com/atlas.tree/',
 'linkedin': 'https://www.linkedin.com/company/atlas-tree-landscape-inc/about/',
 'twitter': 'https://twitter.com/atlas_and'}
DEBUG: Scraped from <200 https://www.theneckofthewoods.com/contact-us.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/eddie.farquharson',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> (referer: https://www.gomezlandscapeandtreecare.com/)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Redirecting (301) to <GET https://www.affordabletreeservicesorangecounty.com/> from <GET http://www.affordabletreeservicesorangecounty.com/>
DEBUG: Scraped from <200 https://foresttreeservices.com/contact-us/>
{'emails': ['info@foresttreeservices.com'],
 'facebook': 'https://www.facebook.com/foresttreeservices',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/company/forest-tree-services/about/',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.eastbaytreeservice.com/> from <GET http://www.eastbaytreeservice.com/>
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php>
{'emails': ['sales@gomezltc.com'],
 'facebook': '//www.facebook.com/Gomez-Landscape-Tree-Care-Inc-885181728164027/',
 'instagram': '//www.instagram.com/gomezlandscapetreecare/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
DEBUG: Scraped from <200 https://www.treeserviceroseville.com/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.sequoiastreeservice.com/>
{'emails': ['evencio.martinez@yahoo.com'],
 'facebook': 'https://www.facebook.com/Sequoias-Tree-Service-104264014496885/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.eastbaytreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['info@mowbrays.com', 'customerservice@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/> (referer: None)
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://acutabovetreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/index.html#contact> (referer: http://www.abotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://stocktontreeservices.com/> from <GET https://www.stocktontreeservices.com/>
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/contact-us/> (referer: https://www.affordabletreeservicesorangecounty.com/)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.abotreeservice.com/index.html>
{'emails': ['operation@abotreeservice.com',
            'krasimira.stoyanova@deluxe.com',
            'info@abotreeservice.com'],
 'facebook': 'https://www.facebook.com/abotreeservice',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/abotreeservice',
 'twitter': 'https://twitter.com/abotreeservice'}
DEBUG: Crawled (200) <GET https://navastree.wixsite.com/my-site> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.affordabletreeservicesorangecounty.com/contact-us/>
{'emails': ['treeremovaloc@gmail.com', '20treeremovaloc@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Scraped from <200 https://ranchotreeservice.com/contact/>
{'emails': ['info@ranchotreeservice.com'],
 'facebook': 'https://www.facebook.com/Rancho-Tree-Service-109046575024387',
 'instagram': 'https://www.instagram.com/ranchotreeservice/',
 'linkedin': 'https://www.linkedin.com/company/rancho-inc-california/',
 'twitter': 'https://twitter.com/RanchoTree'}
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Scraped from <200 https://jtstree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/category/Shopping---Retail/Jts-Inc-510518789043998/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.stevestreeservice.net/> from <GET http://www.stevestreeservice.net/>
DEBUG: Crawled (403) <GET http://www.buenavistatree.com/> (referer: None)
INFO: Ignoring response <403 http://www.buenavistatree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.lunatreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
INFO: Ignoring response <403 http://www.lunatreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 44, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.runyonstree.com/> (referer: None)
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.petestreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.runyonstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
INFO: Ignoring response <403 https://www.petestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Redirecting (301) to <GET https://arbortask.com/> from <GET http://www.arbortask.com/>
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://dprotreeservice.com/contact-us/>
{'emails': ['d.protreeservice@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/contact-2/> (referer: https://stocktontreeservices.com/)
DEBUG: Scraped from <200 https://greenzwaytreeservice.com/contact/>
{'emails': ['Greenzway@hotmail.com', 'greenzway@hotmail.com'],
 'facebook': 'https://www.facebook.com/pg/greenzway',
 'instagram': 'https://www.instagram.com/greenzway_official',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://stocktontreeservices.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/contact/> (referer: https://www.stevestreeservice.net/)
DEBUG: Scraped from <200 https://www.stevestreeservice.net/contact/>
{'emails': ['steves8733@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
DEBUG: Scraped from <200 https://www.lctrees.com/contact/>
{'emails': ['info@lctrees.com'],
 'facebook': 'https://www.facebook.com/LC-Tree-Service-162733330551792/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://bunyonbros.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/bunyonbrostreeserviceSLO',
 'instagram': 'https://www.instagram.com/bunyonbrostreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arbortask.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://arbortask.com/contact/> from <GET https://arbortask.com/contact>
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arbortask.com/contact/> (referer: https://arbortask.com/)
DEBUG: Scraped from <200 https://arbortask.com/contact/>
{'emails': ['almangrant@yahoo.com'],
 'facebook': 'https://www.facebook.com/arbortasktreeservice/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/contact-us/> (referer: http://www.lewistreeserviceinc.com/)
DEBUG: Scraped from <200 http://www.lewistreeserviceinc.com/contact-us/>
{'emails': ['admin@lewistreeserviceinc.com', 'Admin@lewistreeserviceinc.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Scraped from <200 https://treeservicemantecaca.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Crawled 163 pages (at 163 pages/min), scraped 64 items (at 64 items/min)
ERROR: Gave up retrying <GET http://www.alliancetrees.com/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Error downloading <GET http://www.alliancetrees.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 61322,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 5290120,
 'downloader/response_count': 212,
 'downloader/response_status_count/200': 142,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/302': 2,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/308': 1,
 'downloader/response_status_count/403': 21,
 'elapsed_time_seconds': 68.148338,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 10, 15, 34, 25, 794319),
 'httpcompression/response_bytes': 22329848,
 'httpcompression/response_count': 144,
 'httperror/response_ignored_count': 21,
 'httperror/response_ignored_status_count/403': 21,
 'item_scraped_count': 64,
 'log_count/DEBUG': 285,
 'log_count/ERROR': 3,
 'log_count/INFO': 32,
 'request_depth_max': 1,
 'response_received_count': 163,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2022, 12, 10, 15, 33, 17, 645981)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: d1416645c694d16b
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Attempting to acquire lock 2640349922160 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2640349922160 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2640349922160 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2640349922160 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Redirecting (302) to <GET http://www.sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/contact> (referer: https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/contact.html> (referer: http://www.blackbeartrees.com/)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/contact/privacy/> (referer: https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.adolphstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.adolphstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Redirecting (301) to <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> from <GET https://www.gomezlandscapeandtreecare.com/contact.php>
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> (referer: https://www.gomezlandscapeandtreecare.com/)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Redirecting (301) to <GET https://www.eastbaytreeservice.com/> from <GET http://www.eastbaytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Crawled (200) <GET https://www.eastbaytreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Redirecting (301) to <GET https://stocktontreeservices.com/> from <GET https://www.stocktontreeservices.com/>
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/index.html#contact> (referer: http://www.abotreeservice.com/)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://navastree.wixsite.com/my-site> (referer: None)
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Redirecting (301) to <GET https://www.affordabletreeservicesorangecounty.com/> from <GET http://www.affordabletreeservicesorangecounty.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.buenavistatree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.stevestreeservice.net/> from <GET http://www.stevestreeservice.net/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.runyonstree.com/> (referer: None)
INFO: Ignoring response <403 http://www.buenavistatree.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
INFO: Ignoring response <403 https://www.runyonstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 44, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (403) <GET http://www.lunatreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/contact-2/> (referer: https://stocktontreeservices.com/)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/contact-us/> (referer: https://www.affordabletreeservicesorangecounty.com/)
INFO: Ignoring response <403 http://www.lunatreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (403) <GET https://www.petestreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://arbortask.com/> from <GET http://www.arbortask.com/>
INFO: Ignoring response <403 https://www.petestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/contact/> (referer: https://www.stevestreeservice.net/)
DEBUG: Crawled (200) <GET http://acutabovetreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arbortask.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://arbortask.com/contact/> from <GET https://arbortask.com/contact>
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Crawled (200) <GET https://arbortask.com/contact/> (referer: https://arbortask.com/)
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/contact-us/> (referer: http://www.lewistreeserviceinc.com/)
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
INFO: Crawled 163 pages (at 163 pages/min), scraped 0 items (at 0 items/min)
ERROR: Gave up retrying <GET http://www.alliancetrees.com/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Error downloading <GET http://www.alliancetrees.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 61544,
 'downloader/request_count': 216,
 'downloader/request_method_count/GET': 216,
 'downloader/response_bytes': 5291536,
 'downloader/response_count': 213,
 'downloader/response_status_count/200': 142,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/302': 3,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/308': 1,
 'downloader/response_status_count/403': 21,
 'elapsed_time_seconds': 68.929809,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 10, 16, 32, 56, 929441),
 'httpcompression/response_bytes': 22332033,
 'httpcompression/response_count': 144,
 'httperror/response_ignored_count': 21,
 'httperror/response_ignored_status_count/403': 21,
 'log_count/DEBUG': 222,
 'log_count/ERROR': 3,
 'log_count/INFO': 32,
 'request_depth_max': 1,
 'response_received_count': 163,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'scheduler/dequeued': 216,
 'scheduler/dequeued/memory': 216,
 'scheduler/enqueued': 216,
 'scheduler/enqueued/memory': 216,
 'start_time': datetime.datetime(2022, 12, 10, 16, 31, 47, 999632)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 51dba6766f6de456
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1901663439648 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1901663439648 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1901663439648 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1901663439648 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/south-bay/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Monster-Tree-Service-of-South-Bay-1088163361240866/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Scraped from <200 https://www.caltreeservice.com/contact-us>
{'emails': ['office@caltreeservice.com'],
 'facebook': 'https://www.facebook.com/samcolemanluxury',
 'instagram': 'https://www.instagram.com/samcolemanluxury/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/west-valley/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/Monster-Tree-Service-of-West-Valley-1287919078019258/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/'}
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/contact> (referer: https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://octreeservices.com/contact-us/>
{'emails': ['octreeservices1@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Scraped from <200 https://www.bigtstrees.com/contact>
{'emails': ['igtstrees@yahoo.com',
            'bigtstrees@yahoo.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com'],
 'facebook': 'http://www.facebook.com/BigTsTrees',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/coast/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsteroftheCoast/',
 'instagram': 'https://www.instagram.com/monsterofthecoast/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite> (referer: None)
DEBUG: Scraped from <200 https://westcoastarborists.com/>
{'emails': ['corporate@wcainc.com', 'wcahiring@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://rndtreeservices.com/contact-us>
{'emails': ['filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/106157038650413',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.specializedtreeworks.com/contact.html>
{'emails': ['ContactUs@specializedtreeworks.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.tomdaytreeservice.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/TomDayTreeService/reviews/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.modestotreeservicecompany.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Scraped from <200 https://arborworksinc.com/contact/>
{'emails': ['information@arborworksinc.com'],
 'facebook': 'https://www.facebook.com/arborworks1/',
 'instagram': 'https://www.instagram.com/arborworksllc/',
 'linkedin': 'https://www.linkedin.com/company/arborworksinc',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Scraped from <200 http://www.vetreeservice.com/contactus.html>
{'emails': ['Eric@vetreeservice.com',
            'Vic@vetreeservice.com',
            'John@vetreeservice.com',
            'patti@vetreeservice.com',
            'Patti@vetreeservice.com',
            'Ashleigh@vetreeservice.com',
            'dns@technologydimensions.com',
            'Ed@vetreeservice.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/contact.html> (referer: http://www.blackbeartrees.com/)
DEBUG: Scraped from <200 https://losangelesca-treeservice.com/contact>
{'emails': ['losangelescatreeservice@gmail.com',
            'u003Elosangelescatreeservice@gmail.com'],
 'facebook': 'https://www.facebook.com/losangelescatreeservice/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.blackbeartrees.com/contact.html>
{'emails': ['blackbeartreeservice559@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Scraped from <200 https://bayareatreespecialists.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Bay-Area-Tree-Specialists-658134177581480/?timeline_context_item_type=intro_card_work&timeline_context_item_source=100007956785104',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/TreesSpecialist'}
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
DEBUG: Scraped from <200 https://www.traversotree.com/contacts/>
{'emails': ['office@traversotree.com', 'Office@traversotree.com'],
 'facebook': 'https://www.facebook.com/traversotree',
 'instagram': 'https://www.instagram.com/traversotree/?hl=en',
 'linkedin': 'https://www.linkedin.com/pub/traverso-tree-service/38/6a3/a40',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/contact/privacy/> (referer: https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Scraped from <200 https://www.tiptoparborists.com/contact/privacy/>
{'emails': ['privacy@reachlocal.com.'],
 'facebook': 'https://www.facebook.com/pg/Tip-Top-Arborists-Inc-608355719230396/reviews/',
 'instagram': 'https://www.instagram.com/tip_top_arborists/',
 'linkedin': 'https://www.linkedin.com/company/tip-top-arborists',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://fallenleaftree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/fallenleaftreemanagement',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FallenLeafTree'}
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://californiagreentreecare.com/contact.php>
{'emails': ['info@californiagreentreecare.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
DEBUG: Scraped from <200 http://www.aearborists.com/contact-us/>
{'emails': ['aearborists@gmail.com'],
 'facebook': 'https://www.facebook.com/AE-Arborists-Tree-Care-428707717460988/ ',
 'instagram': 'https://www.instagram.com/aearborists/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/aearborists'}
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.herculestreeservice.com/contact/>
{'emails': ['info@herculestreeservice.com'],
 'facebook': 'https://www.facebook.com/510799tree/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET https://www.adolphstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
INFO: Ignoring response <403 https://www.adolphstreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['sales@shipmantree.com', 'dillanmcather@gmail.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/> (referer: None)
DEBUG: Scraped from <200 https://www.commercialtreeservices.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/commercialtreeservices',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Scraped from <200 https://www.theneckofthewoods.com/contact-us.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/eddie.farquharson',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.affordabletreeservicesorangecounty.com/> from <GET http://www.affordabletreeservicesorangecounty.com/>
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Scraped from <200 https://cutitrighttreeservicefresno.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> from <GET https://www.gomezlandscapeandtreecare.com/contact.php>
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> (referer: https://www.gomezlandscapeandtreecare.com/)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Scraped from <200 https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php>
{'emails': ['sales@gomezltc.com'],
 'facebook': '//www.facebook.com/Gomez-Landscape-Tree-Care-Inc-885181728164027/',
 'instagram': '//www.instagram.com/gomezlandscapetreecare/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
DEBUG: Redirecting (301) to <GET https://www.eastbaytreeservice.com/> from <GET http://www.eastbaytreeservice.com/>
DEBUG: Scraped from <200 https://www.atlas-tree.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/AtlasTreeSurgery',
 'instagram': 'https://www.instagram.com/atlas.tree/',
 'linkedin': 'https://www.linkedin.com/company/atlas-tree-landscape-inc/about/',
 'twitter': 'https://twitter.com/atlas_and'}
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.sequoiastreeservice.com/>
{'emails': ['evencio.martinez@yahoo.com'],
 'facebook': 'https://www.facebook.com/Sequoias-Tree-Service-104264014496885/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Scraped from <200 https://www.treeserviceroseville.com/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/> (referer: None)
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://foresttreeservices.com/contact-us/>
{'emails': ['info@foresttreeservices.com'],
 'facebook': 'https://www.facebook.com/foresttreeservices',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/company/forest-tree-services/about/',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
DEBUG: Crawled (200) <GET https://www.eastbaytreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['info@mowbrays.com', 'customerservice@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/contact-us/> (referer: https://www.affordabletreeservicesorangecounty.com/)
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.affordabletreeservicesorangecounty.com/contact-us/>
{'emails': ['20treeremovaloc@gmail.com', 'treeremovaloc@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Redirecting (301) to <GET https://stocktontreeservices.com/> from <GET https://www.stocktontreeservices.com/>
DEBUG: Crawled (200) <GET http://acutabovetreesvc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/index.html#contact> (referer: http://www.abotreeservice.com/)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
DEBUG: Scraped from <200 http://www.abotreeservice.com/index.html>
{'emails': ['operation@abotreeservice.com',
            'krasimira.stoyanova@deluxe.com',
            'info@abotreeservice.com'],
 'facebook': 'https://www.facebook.com/abotreeservice',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/abotreeservice',
 'twitter': 'https://twitter.com/abotreeservice'}
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://navastree.wixsite.com/my-site> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Scraped from <200 https://ranchotreeservice.com/contact/>
{'emails': ['info@ranchotreeservice.com'],
 'facebook': 'https://www.facebook.com/Rancho-Tree-Service-109046575024387',
 'instagram': 'https://www.instagram.com/ranchotreeservice/',
 'linkedin': 'https://www.linkedin.com/company/rancho-inc-california/',
 'twitter': 'https://twitter.com/RanchoTree'}
DEBUG: Scraped from <200 https://jesustreeserviceandlandscaping.com/contact/>
{'emails': ['jesusjgr1987@gmail.com'],
 'facebook': 'https://www.facebook.com/Jesus-Tree-Services-Landscaping-104850001236628',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://jtstree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/category/Shopping---Retail/Jts-Inc-510518789043998/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
DEBUG: Redirecting (301) to <GET https://www.stevestreeservice.net/> from <GET http://www.stevestreeservice.net/>
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (403) <GET https://www.petestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/contact-2/> (referer: https://stocktontreeservices.com/)
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.buenavistatree.com/> (referer: None)
INFO: Ignoring response <403 https://www.petestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://stocktontreeservices.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (403) <GET https://www.runyonstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
INFO: Ignoring response <403 http://www.buenavistatree.com/>: HTTP status code is not handled or not allowed
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 44, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
INFO: Ignoring response <403 https://www.runyonstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.lunatreetrimming.com/> (referer: None)
DEBUG: Scraped from <200 https://dprotreeservice.com/contact-us/>
{'emails': ['d.protreeservice@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.lunatreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
DEBUG: Redirecting (301) to <GET https://arbortask.com/> from <GET http://www.arbortask.com/>
DEBUG: Scraped from <200 https://greenzwaytreeservice.com/contact/>
{'emails': ['greenzway@hotmail.com', 'Greenzway@hotmail.com'],
 'facebook': 'https://www.facebook.com/pg/greenzway',
 'instagram': 'https://www.instagram.com/greenzway_official',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/contact/> (referer: https://www.stevestreeservice.net/)
DEBUG: Scraped from <200 https://www.stevestreeservice.net/contact/>
{'emails': ['steves8733@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Scraped from <200 https://www.lctrees.com/contact/>
{'emails': ['info@lctrees.com'],
 'facebook': 'https://www.facebook.com/LC-Tree-Service-162733330551792/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/> (referer: None)
DEBUG: Scraped from <200 https://bunyonbros.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/bunyonbrostreeserviceSLO',
 'instagram': 'https://www.instagram.com/bunyonbrostreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arbortask.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Redirecting (301) to <GET https://arbortask.com/contact/> from <GET https://arbortask.com/contact>
DEBUG: Scraped from <200 https://treeservicemantecaca.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arbortask.com/contact/> (referer: https://arbortask.com/)
DEBUG: Scraped from <200 https://arbortask.com/contact/>
{'emails': ['almangrant@yahoo.com'],
 'facebook': 'https://www.facebook.com/arbortasktreeservice/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/contact-us/> (referer: http://www.lewistreeserviceinc.com/)
DEBUG: Scraped from <200 http://www.lewistreeserviceinc.com/contact-us/>
{'emails': ['admin@lewistreeserviceinc.com', 'Admin@lewistreeserviceinc.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Scraped from <200 https://www.a1treeredding.com/contact/>
{'emails': ['Office@a1treeredding.com', 'office@a1treeredding.com'],
 'facebook': 'https://www.facebook.com/A1treeredding/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Crawled 163 pages (at 163 pages/min), scraped 64 items (at 64 items/min)
ERROR: Gave up retrying <GET http://www.alliancetrees.com/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Error downloading <GET http://www.alliancetrees.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 63368,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 5290733,
 'downloader/response_count': 212,
 'downloader/response_status_count/200': 142,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/302': 2,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/308': 1,
 'downloader/response_status_count/403': 21,
 'elapsed_time_seconds': 68.287951,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 10, 16, 35, 59, 895474),
 'httpcompression/response_bytes': 22330493,
 'httpcompression/response_count': 144,
 'httperror/response_ignored_count': 21,
 'httperror/response_ignored_status_count/403': 21,
 'item_scraped_count': 64,
 'log_count/DEBUG': 285,
 'log_count/ERROR': 3,
 'log_count/INFO': 32,
 'request_depth_max': 1,
 'response_received_count': 163,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2022, 12, 10, 16, 34, 51, 607523)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 2cc5c3d2dc2937b5
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1420004631184 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1420004631184 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1420004631184 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1420004631184 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Redirecting (302) to <GET http://www.sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/contact> (referer: https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/contact.html> (referer: http://www.blackbeartrees.com/)
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/contact/privacy/> (referer: https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite)
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (403) <GET https://www.adolphstreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.adolphstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Redirecting (301) to <GET https://www.affordabletreeservicesorangecounty.com/> from <GET http://www.affordabletreeservicesorangecounty.com/>
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> from <GET https://www.gomezlandscapeandtreecare.com/contact.php>
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.eastbaytreeservice.com/> from <GET http://www.eastbaytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> (referer: https://www.gomezlandscapeandtreecare.com/)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.eastbaytreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/contact-us/> (referer: https://www.affordabletreeservicesorangecounty.com/)
DEBUG: Crawled (200) <GET http://acutabovetreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/index.html#contact> (referer: http://www.abotreeservice.com/)
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Redirecting (301) to <GET https://stocktontreeservices.com/> from <GET https://www.stocktontreeservices.com/>
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://navastree.wixsite.com/my-site> (referer: None)
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.stevestreeservice.net/> from <GET http://www.stevestreeservice.net/>
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (403) <GET http://www.buenavistatree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
INFO: Ignoring response <403 http://www.buenavistatree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://www.runyonstree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 44, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
INFO: Ignoring response <403 https://www.runyonstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (403) <GET https://www.petestreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.lunatreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
INFO: Ignoring response <403 https://www.petestreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.lunatreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/contact-2/> (referer: https://stocktontreeservices.com/)
DEBUG: Redirecting (301) to <GET https://arbortask.com/> from <GET http://www.arbortask.com/>
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/contact/> (referer: https://www.stevestreeservice.net/)
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
DEBUG: Crawled (200) <GET https://arbortask.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Redirecting (301) to <GET https://arbortask.com/contact/> from <GET https://arbortask.com/contact>
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/contact-us/> (referer: http://www.lewistreeserviceinc.com/)
DEBUG: Crawled (200) <GET https://arbortask.com/contact/> (referer: https://arbortask.com/)
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Received SIGINT, shutting down gracefully. Send again to force 
INFO: Closing spider (shutdown)
INFO: Received SIGINT twice, forcing unclean shutdown
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 2,
 'downloader/exception_type_count/twisted.internet.error.ConnectError': 1,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 1,
 'downloader/request_bytes': 61836,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 5290684,
 'downloader/response_count': 213,
 'downloader/response_status_count/200': 142,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/302': 3,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/308': 1,
 'downloader/response_status_count/403': 21,
 'elapsed_time_seconds': 31.677011,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2022, 12, 10, 16, 52, 32, 624693),
 'httpcompression/response_bytes': 22331970,
 'httpcompression/response_count': 144,
 'httperror/response_ignored_count': 21,
 'httperror/response_ignored_status_count/403': 21,
 'log_count/DEBUG': 222,
 'log_count/ERROR': 1,
 'log_count/INFO': 33,
 'request_depth_max': 1,
 'response_received_count': 163,
 'retry/count': 2,
 'retry/reason_count/twisted.internet.error.ConnectError': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 1,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 216,
 'scheduler/enqueued/memory': 216,
 'start_time': datetime.datetime(2022, 12, 10, 16, 52, 0, 947682)}
INFO: Spider closed (shutdown)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 20b2e20ff2db7503
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2853021599488 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2853021599488 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2853021599488 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2853021599488 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'index': 7,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'index': 8,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
DEBUG: Scraped from <200 https://www.caltreeservice.com/contact-us>
{'emails': ['office@caltreeservice.com'],
 'facebook': 'https://www.facebook.com/samcolemanluxury',
 'index': 9,
 'instagram': 'https://www.instagram.com/samcolemanluxury/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/coast/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsteroftheCoast/',
 'index': 13,
 'instagram': 'https://www.instagram.com/monsterofthecoast/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Scraped from <200 https://octreeservices.com/contact-us/>
{'emails': ['octreeservices1@gmail.com'],
 'facebook': 'N/A',
 'index': 1,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/contact> (referer: https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/west-valley/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/Monster-Tree-Service-of-West-Valley-1287919078019258/',
 'index': 24,
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/'}
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.bigtstrees.com/contact>
{'emails': ['bigtstrees@yahoo.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'igtstrees@yahoo.com'],
 'facebook': 'http://www.facebook.com/BigTsTrees',
 'index': 22,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
DEBUG: Scraped from <200 https://www.tomdaytreeservice.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/TomDayTreeService/reviews/',
 'index': 11,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://westcoastarborists.com/>
{'emails': ['wcahiring@wcainc.com', 'corporate@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'index': 17,
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.specializedtreeworks.com/contact.html>
{'emails': ['ContactUs@specializedtreeworks.com'],
 'facebook': 'N/A',
 'index': 28,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.monstertreeservice.com/south-bay/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Monster-Tree-Service-of-South-Bay-1088163361240866/',
 'index': 12,
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://rndtreeservices.com/contact-us>
{'emails': ['filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/106157038650413',
 'index': 25,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 16,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Scraped from <200 https://www.modestotreeservicecompany.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'index': 20,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Scraped from <200 https://arborworksinc.com/contact/>
{'emails': ['information@arborworksinc.com'],
 'facebook': 'https://www.facebook.com/arborworks1/',
 'index': 4,
 'instagram': 'https://www.instagram.com/arborworksllc/',
 'linkedin': 'https://www.linkedin.com/company/arborworksinc',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.aearborists.com/contact-us/>
{'emails': ['aearborists@gmail.com'],
 'facebook': 'https://www.facebook.com/AE-Arborists-Tree-Care-428707717460988/ ',
 'index': 2,
 'instagram': 'https://www.instagram.com/aearborists/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/aearborists'}
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
DEBUG: Scraped from <200 https://losangelesca-treeservice.com/contact>
{'emails': ['losangelescatreeservice@gmail.com',
            'u003Elosangelescatreeservice@gmail.com'],
 'facebook': 'https://www.facebook.com/losangelescatreeservice/',
 'index': 27,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/contact/privacy/> (referer: https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite)
DEBUG: Scraped from <200 https://www.traversotree.com/contacts/>
{'emails': ['office@traversotree.com', 'Office@traversotree.com'],
 'facebook': 'https://www.facebook.com/traversotree',
 'index': 19,
 'instagram': 'https://www.instagram.com/traversotree/?hl=en',
 'linkedin': 'https://www.linkedin.com/pub/traverso-tree-service/38/6a3/a40',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.vetreeservice.com/contactus.html>
{'emails': ['John@vetreeservice.com',
            'Ed@vetreeservice.com',
            'patti@vetreeservice.com',
            'Vic@vetreeservice.com',
            'Patti@vetreeservice.com',
            'Ashleigh@vetreeservice.com',
            'Eric@vetreeservice.com',
            'dns@technologydimensions.com'],
 'facebook': 'N/A',
 'index': 35,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.tiptoparborists.com/contact/privacy/>
{'emails': ['privacy@reachlocal.com.'],
 'facebook': 'https://www.facebook.com/pg/Tip-Top-Arborists-Inc-608355719230396/reviews/',
 'index': 3,
 'instagram': 'https://www.instagram.com/tip_top_arborists/',
 'linkedin': 'https://www.linkedin.com/company/tip-top-arborists',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/contact.html> (referer: http://www.blackbeartrees.com/)
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Scraped from <200 https://fallenleaftree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/fallenleaftreemanagement',
 'index': 18,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FallenLeafTree'}
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Scraped from <200 https://bayareatreespecialists.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Bay-Area-Tree-Specialists-658134177581480/?timeline_context_item_type=intro_card_work&timeline_context_item_source=100007956785104',
 'index': 32,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/TreesSpecialist'}
DEBUG: Scraped from <200 http://www.blackbeartrees.com/contact.html>
{'emails': ['blackbeartreeservice559@gmail.com'],
 'facebook': 'N/A',
 'index': 33,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 23,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Scraped from <200 https://californiagreentreecare.com/contact.php>
{'emails': ['info@californiagreentreecare.com'],
 'facebook': 'N/A',
 'index': 34,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET https://www.adolphstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
INFO: Ignoring response <403 https://www.adolphstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.affordabletreeservicesorangecounty.com/> from <GET http://www.affordabletreeservicesorangecounty.com/>
DEBUG: Scraped from <200 https://www.herculestreeservice.com/contact/>
{'emails': ['info@herculestreeservice.com'],
 'facebook': 'https://www.facebook.com/510799tree/',
 'index': 6,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'index': 38,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://foresttreeservices.com/contact-us/>
{'emails': ['info@foresttreeservices.com'],
 'facebook': 'https://www.facebook.com/foresttreeservices',
 'index': 37,
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/company/forest-tree-services/about/',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Scraped from <200 https://www.commercialtreeservices.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/commercialtreeservices',
 'index': 51,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 39,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 50,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/contact-us/> (referer: https://www.affordabletreeservicesorangecounty.com/)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Scraped from <200 https://www.affordabletreeservicesorangecounty.com/contact-us/>
{'emails': ['20treeremovaloc@gmail.com', 'treeremovaloc@gmail.com'],
 'facebook': 'N/A',
 'index': 52,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.atlas-tree.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/AtlasTreeSurgery',
 'index': 64,
 'instagram': 'https://www.instagram.com/atlas.tree/',
 'linkedin': 'https://www.linkedin.com/company/atlas-tree-landscape-inc/about/',
 'twitter': 'https://twitter.com/atlas_and'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Redirecting (301) to <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> from <GET https://www.gomezlandscapeandtreecare.com/contact.php>
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['dillanmcather@gmail.com', 'sales@shipmantree.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'index': 44,
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.a1treeredding.com/contact/>
{'emails': ['office@a1treeredding.com', 'Office@a1treeredding.com'],
 'facebook': 'https://www.facebook.com/A1treeredding/',
 'index': 60,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'index': 48,
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> (referer: https://www.gomezlandscapeandtreecare.com/)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Redirecting (301) to <GET https://www.eastbaytreeservice.com/> from <GET http://www.eastbaytreeservice.com/>
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 41,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'index': 49,
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.theneckofthewoods.com/contact-us.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/eddie.farquharson',
 'index': 56,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php>
{'emails': ['sales@gomezltc.com'],
 'facebook': '//www.facebook.com/Gomez-Landscape-Tree-Care-Inc-885181728164027/',
 'index': 58,
 'instagram': '//www.instagram.com/gomezlandscapetreecare/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://cutitrighttreeservicefresno.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'index': 45,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['fred@richardstree.com', 'info@richardstree.com'],
 'facebook': 'N/A',
 'index': 61,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['fred@richardstree.com', 'info@richardstree.com'],
 'facebook': 'N/A',
 'index': 62,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.sequoiastreeservice.com/>
{'emails': ['evencio.martinez@yahoo.com'],
 'facebook': 'https://www.facebook.com/Sequoias-Tree-Service-104264014496885/',
 'index': 26,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://stocktontreeservices.com/> from <GET https://www.stocktontreeservices.com/>
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
DEBUG: Scraped from <200 https://www.treeserviceroseville.com/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'index': 59,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/index.html#contact> (referer: http://www.abotreeservice.com/)
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Crawled (200) <GET https://www.eastbaytreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['info@mowbrays.com', 'customerservice@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'index': 47,
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.abotreeservice.com/index.html>
{'emails': ['krasimira.stoyanova@deluxe.com',
            'operation@abotreeservice.com',
            'info@abotreeservice.com'],
 'facebook': 'https://www.facebook.com/abotreeservice',
 'index': 67,
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/abotreeservice',
 'twitter': 'https://twitter.com/abotreeservice'}
DEBUG: Crawled (200) <GET http://acutabovetreesvc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/> (referer: None)
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://navastree.wixsite.com/my-site> (referer: None)
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://dprotreeservice.com/contact-us/>
{'emails': ['d.protreeservice@gmail.com'],
 'facebook': 'N/A',
 'index': 63,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://www.stevestreeservice.net/> from <GET http://www.stevestreeservice.net/>
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Scraped from <200 https://ranchotreeservice.com/contact/>
{'emails': ['info@ranchotreeservice.com'],
 'facebook': 'https://www.facebook.com/Rancho-Tree-Service-109046575024387',
 'index': 74,
 'instagram': 'https://www.instagram.com/ranchotreeservice/',
 'linkedin': 'https://www.linkedin.com/company/rancho-inc-california/',
 'twitter': 'https://twitter.com/RanchoTree'}
DEBUG: Crawled (403) <GET http://www.buenavistatree.com/> (referer: None)
DEBUG: Scraped from <200 https://jtstree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/category/Shopping---Retail/Jts-Inc-510518789043998/',
 'index': 77,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.buenavistatree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
DEBUG: Crawled (403) <GET https://www.runyonstree.com/> (referer: None)
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'index': 78,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/contact-2/> (referer: https://stocktontreeservices.com/)
DEBUG: Crawled (403) <GET http://www.lunatreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 44, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
INFO: Ignoring response <403 https://www.runyonstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://stocktontreeservices.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'index': 69,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET https://www.petestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
INFO: Ignoring response <403 http://www.lunatreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
INFO: Ignoring response <403 https://www.petestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'index': 79,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://jesustreeserviceandlandscaping.com/contact/>
{'emails': ['jesusjgr1987@gmail.com'],
 'facebook': 'https://www.facebook.com/Jesus-Tree-Services-Landscaping-104850001236628',
 'index': 36,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 89,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 91,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Redirecting (301) to <GET https://arbortask.com/> from <GET http://www.arbortask.com/>
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/> (referer: None)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 90,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
DEBUG: Scraped from <200 https://greenzwaytreeservice.com/contact/>
{'emails': ['Greenzway@hotmail.com', 'greenzway@hotmail.com'],
 'facebook': 'https://www.facebook.com/pg/greenzway',
 'index': 93,
 'instagram': 'https://www.instagram.com/greenzway_official',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/contact/> (referer: https://www.stevestreeservice.net/)
DEBUG: Scraped from <200 https://www.stevestreeservice.net/contact/>
{'emails': ['steves8733@gmail.com'],
 'facebook': 'N/A',
 'index': 94,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/> (referer: None)
DEBUG: Scraped from <200 https://bunyonbros.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/bunyonbrostreeserviceSLO',
 'index': 100,
 'instagram': 'https://www.instagram.com/bunyonbrostreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.lctrees.com/contact/>
{'emails': ['info@lctrees.com'],
 'facebook': 'https://www.facebook.com/LC-Tree-Service-162733330551792/',
 'index': 81,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Crawled (200) <GET https://arbortask.com/> (referer: None)
DEBUG: Scraped from <200 https://treeservicemantecaca.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'index': 84,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://arbortask.com/contact/> from <GET https://arbortask.com/contact>
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/contact-us/> (referer: http://www.lewistreeserviceinc.com/)
DEBUG: Scraped from <200 http://www.lewistreeserviceinc.com/contact-us/>
{'emails': ['Admin@lewistreeserviceinc.com', 'admin@lewistreeserviceinc.com'],
 'facebook': 'N/A',
 'index': 92,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arbortask.com/contact/> (referer: https://arbortask.com/)
DEBUG: Scraped from <200 https://arbortask.com/contact/>
{'emails': ['almangrant@yahoo.com'],
 'facebook': 'https://www.facebook.com/arbortasktreeservice/',
 'index': 99,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Crawled 163 pages (at 163 pages/min), scraped 64 items (at 64 items/min)
ERROR: Gave up retrying <GET http://www.alliancetrees.com/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Error downloading <GET http://www.alliancetrees.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 64391,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 5292068,
 'downloader/response_count': 212,
 'downloader/response_status_count/200': 142,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/302': 2,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/308': 1,
 'downloader/response_status_count/403': 21,
 'elapsed_time_seconds': 67.634808,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 10, 16, 53, 48, 988852),
 'httpcompression/response_bytes': 22331969,
 'httpcompression/response_count': 144,
 'httperror/response_ignored_count': 21,
 'httperror/response_ignored_status_count/403': 21,
 'item_scraped_count': 64,
 'log_count/DEBUG': 285,
 'log_count/ERROR': 3,
 'log_count/INFO': 32,
 'request_depth_max': 1,
 'response_received_count': 163,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2022, 12, 10, 16, 52, 41, 354044)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 8744cbb984ea85d0
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2282137913904 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2282137913904 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2282137913904 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2282137913904 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'index': 7,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'index': 8,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/coast/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsteroftheCoast/',
 'index': 13,
 'instagram': 'https://www.instagram.com/monsterofthecoast/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/south-bay/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Monster-Tree-Service-of-South-Bay-1088163361240866/',
 'index': 12,
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Scraped from <200 https://octreeservices.com/contact-us/>
{'emails': ['octreeservices1@gmail.com'],
 'facebook': 'N/A',
 'index': 1,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.caltreeservice.com/contact-us>
{'emails': ['office@caltreeservice.com'],
 'facebook': 'https://www.facebook.com/samcolemanluxury',
 'index': 9,
 'instagram': 'https://www.instagram.com/samcolemanluxury/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://westcoastarborists.com/>
{'emails': ['corporate@wcainc.com', 'wcahiring@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'index': 17,
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/contact> (referer: https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Scraped from <200 https://rndtreeservices.com/contact-us>
{'emails': ['filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/106157038650413',
 'index': 25,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.bigtstrees.com/contact>
{'emails': ['605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            'igtstrees@yahoo.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'bigtstrees@yahoo.com'],
 'facebook': 'http://www.facebook.com/BigTsTrees',
 'index': 22,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.monstertreeservice.com/west-valley/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/Monster-Tree-Service-of-West-Valley-1287919078019258/',
 'index': 24,
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/'}
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite> (referer: None)
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
DEBUG: Scraped from <200 https://www.modestotreeservicecompany.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'index': 20,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.specializedtreeworks.com/contact.html>
{'emails': ['ContactUs@specializedtreeworks.com'],
 'facebook': 'N/A',
 'index': 28,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.tomdaytreeservice.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/TomDayTreeService/reviews/',
 'index': 11,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 16,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Scraped from <200 https://arborworksinc.com/contact/>
{'emails': ['information@arborworksinc.com'],
 'facebook': 'https://www.facebook.com/arborworks1/',
 'index': 4,
 'instagram': 'https://www.instagram.com/arborworksllc/',
 'linkedin': 'https://www.linkedin.com/company/arborworksinc',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/contact.html> (referer: http://www.blackbeartrees.com/)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
DEBUG: Scraped from <200 https://bayareatreespecialists.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Bay-Area-Tree-Specialists-658134177581480/?timeline_context_item_type=intro_card_work&timeline_context_item_source=100007956785104',
 'index': 32,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/TreesSpecialist'}
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
DEBUG: Scraped from <200 http://www.blackbeartrees.com/contact.html>
{'emails': ['blackbeartreeservice559@gmail.com'],
 'facebook': 'N/A',
 'index': 33,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://losangelesca-treeservice.com/contact>
{'emails': ['losangelescatreeservice@gmail.com',
            'u003Elosangelescatreeservice@gmail.com'],
 'facebook': 'https://www.facebook.com/losangelescatreeservice/',
 'index': 27,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.vetreeservice.com/contactus.html>
{'emails': ['Vic@vetreeservice.com',
            'Eric@vetreeservice.com',
            'Ed@vetreeservice.com',
            'Patti@vetreeservice.com',
            'dns@technologydimensions.com',
            'Ashleigh@vetreeservice.com',
            'patti@vetreeservice.com',
            'John@vetreeservice.com'],
 'facebook': 'N/A',
 'index': 35,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 23,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
DEBUG: Scraped from <200 https://fallenleaftree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/fallenleaftreemanagement',
 'index': 18,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FallenLeafTree'}
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/contact/privacy/> (referer: https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite)
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Scraped from <200 http://www.aearborists.com/contact-us/>
{'emails': ['aearborists@gmail.com'],
 'facebook': 'https://www.facebook.com/AE-Arborists-Tree-Care-428707717460988/ ',
 'index': 2,
 'instagram': 'https://www.instagram.com/aearborists/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/aearborists'}
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Scraped from <200 https://www.traversotree.com/contacts/>
{'emails': ['Office@traversotree.com', 'office@traversotree.com'],
 'facebook': 'https://www.facebook.com/traversotree',
 'index': 19,
 'instagram': 'https://www.instagram.com/traversotree/?hl=en',
 'linkedin': 'https://www.linkedin.com/pub/traverso-tree-service/38/6a3/a40',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://californiagreentreecare.com/contact.php>
{'emails': ['info@californiagreentreecare.com'],
 'facebook': 'N/A',
 'index': 34,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.tiptoparborists.com/contact/privacy/>
{'emails': ['privacy@reachlocal.com.'],
 'facebook': 'https://www.facebook.com/pg/Tip-Top-Arborists-Inc-608355719230396/reviews/',
 'index': 3,
 'instagram': 'https://www.instagram.com/tip_top_arborists/',
 'linkedin': 'https://www.linkedin.com/company/tip-top-arborists',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
DEBUG: Crawled (403) <GET https://www.adolphstreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.adolphstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 39,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://www.herculestreeservice.com/contact/>
{'emails': ['info@herculestreeservice.com'],
 'facebook': 'https://www.facebook.com/510799tree/',
 'index': 6,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'index': 38,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.commercialtreeservices.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/commercialtreeservices',
 'index': 51,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Redirecting (301) to <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> from <GET https://www.gomezlandscapeandtreecare.com/contact.php>
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Scraped from <200 https://www.a1treeredding.com/contact/>
{'emails': ['Office@a1treeredding.com', 'office@a1treeredding.com'],
 'facebook': 'https://www.facebook.com/A1treeredding/',
 'index': 60,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['sales@shipmantree.com', 'dillanmcather@gmail.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'index': 44,
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.affordabletreeservicesorangecounty.com/> from <GET http://www.affordabletreeservicesorangecounty.com/>
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> (referer: https://www.gomezlandscapeandtreecare.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 41,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Scraped from <200 https://www.theneckofthewoods.com/contact-us.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/eddie.farquharson',
 'index': 56,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Scraped from <200 https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php>
{'emails': ['sales@gomezltc.com'],
 'facebook': '//www.facebook.com/Gomez-Landscape-Tree-Care-Inc-885181728164027/',
 'index': 58,
 'instagram': '//www.instagram.com/gomezlandscapetreecare/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 50,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'index': 48,
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'index': 49,
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Redirecting (301) to <GET https://www.eastbaytreeservice.com/> from <GET http://www.eastbaytreeservice.com/>
DEBUG: Scraped from <200 https://cutitrighttreeservicefresno.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'index': 45,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'index': 61,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://www.atlas-tree.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/AtlasTreeSurgery',
 'index': 64,
 'instagram': 'https://www.instagram.com/atlas.tree/',
 'linkedin': 'https://www.linkedin.com/company/atlas-tree-landscape-inc/about/',
 'twitter': 'https://twitter.com/atlas_and'}
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
DEBUG: Scraped from <200 https://foresttreeservices.com/contact-us/>
{'emails': ['info@foresttreeservices.com'],
 'facebook': 'https://www.facebook.com/foresttreeservices',
 'index': 37,
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/company/forest-tree-services/about/',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
DEBUG: Scraped from <200 https://www.treeserviceroseville.com/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'index': 59,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'index': 62,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.eastbaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/contact-us/> (referer: https://www.affordabletreeservicesorangecounty.com/)
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.affordabletreeservicesorangecounty.com/contact-us/>
{'emails': ['treeremovaloc@gmail.com', '20treeremovaloc@gmail.com'],
 'facebook': 'N/A',
 'index': 52,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://stocktontreeservices.com/> from <GET https://www.stocktontreeservices.com/>
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Scraped from <200 https://www.sequoiastreeservice.com/>
{'emails': ['evencio.martinez@yahoo.com'],
 'facebook': 'https://www.facebook.com/Sequoias-Tree-Service-104264014496885/',
 'index': 26,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://acutabovetreesvc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/index.html#contact> (referer: http://www.abotreeservice.com/)
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
DEBUG: Scraped from <200 http://www.abotreeservice.com/index.html>
{'emails': ['info@abotreeservice.com',
            'operation@abotreeservice.com',
            'krasimira.stoyanova@deluxe.com'],
 'facebook': 'https://www.facebook.com/abotreeservice',
 'index': 67,
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/abotreeservice',
 'twitter': 'https://twitter.com/abotreeservice'}
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
DEBUG: Crawled (200) <GET https://navastree.wixsite.com/my-site> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Scraped from <200 https://ranchotreeservice.com/contact/>
{'emails': ['info@ranchotreeservice.com'],
 'facebook': 'https://www.facebook.com/Rancho-Tree-Service-109046575024387',
 'index': 74,
 'instagram': 'https://www.instagram.com/ranchotreeservice/',
 'linkedin': 'https://www.linkedin.com/company/rancho-inc-california/',
 'twitter': 'https://twitter.com/RanchoTree'}
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['info@mowbrays.com', 'customerservice@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'index': 47,
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Redirecting (301) to <GET https://www.stevestreeservice.net/> from <GET http://www.stevestreeservice.net/>
DEBUG: Scraped from <200 https://jtstree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/category/Shopping---Retail/Jts-Inc-510518789043998/',
 'index': 77,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/contact-2/> (referer: https://stocktontreeservices.com/)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (403) <GET https://www.petestreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://stocktontreeservices.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'index': 69,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
INFO: Ignoring response <403 https://www.petestreeservice.com/>: HTTP status code is not handled or not allowed
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 44, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'index': 79,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 89,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.buenavistatree.com/> (referer: None)
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'index': 78,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 90,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.lunatreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
INFO: Ignoring response <403 http://www.buenavistatree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (403) <GET https://www.runyonstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Redirecting (301) to <GET https://arbortask.com/> from <GET http://www.arbortask.com/>
INFO: Ignoring response <403 http://www.lunatreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://greenzwaytreeservice.com/contact/>
{'emails': ['Greenzway@hotmail.com', 'greenzway@hotmail.com'],
 'facebook': 'https://www.facebook.com/pg/greenzway',
 'index': 93,
 'instagram': 'https://www.instagram.com/greenzway_official',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 91,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 https://www.runyonstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://dprotreeservice.com/contact-us/>
{'emails': ['d.protreeservice@gmail.com'],
 'facebook': 'N/A',
 'index': 63,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
DEBUG: Scraped from <200 https://jesustreeserviceandlandscaping.com/contact/>
{'emails': ['jesusjgr1987@gmail.com'],
 'facebook': 'https://www.facebook.com/Jesus-Tree-Services-Landscaping-104850001236628',
 'index': 36,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/contact/> (referer: https://www.stevestreeservice.net/)
DEBUG: Scraped from <200 https://www.stevestreeservice.net/contact/>
{'emails': ['steves8733@gmail.com'],
 'facebook': 'N/A',
 'index': 94,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
DEBUG: Scraped from <200 https://bunyonbros.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/bunyonbrostreeserviceSLO',
 'index': 100,
 'instagram': 'https://www.instagram.com/bunyonbrostreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Scraped from <200 https://treeservicemantecaca.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'index': 84,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Crawled (200) <GET https://arbortask.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Scraped from <200 https://www.lctrees.com/contact/>
{'emails': ['info@lctrees.com'],
 'facebook': 'https://www.facebook.com/LC-Tree-Service-162733330551792/',
 'index': 81,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://arbortask.com/contact/> from <GET https://arbortask.com/contact>
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/contact-us/> (referer: http://www.lewistreeserviceinc.com/)
DEBUG: Scraped from <200 http://www.lewistreeserviceinc.com/contact-us/>
{'emails': ['Admin@lewistreeserviceinc.com', 'admin@lewistreeserviceinc.com'],
 'facebook': 'N/A',
 'index': 92,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arbortask.com/contact/> (referer: https://arbortask.com/)
DEBUG: Scraped from <200 https://arbortask.com/contact/>
{'emails': ['almangrant@yahoo.com'],
 'facebook': 'https://www.facebook.com/arbortasktreeservice/',
 'index': 99,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Crawled 163 pages (at 163 pages/min), scraped 64 items (at 64 items/min)
ERROR: Gave up retrying <GET http://www.alliancetrees.com/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Error downloading <GET http://www.alliancetrees.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 64391,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 5291276,
 'downloader/response_count': 212,
 'downloader/response_status_count/200': 142,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/302': 2,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/308': 1,
 'downloader/response_status_count/403': 21,
 'elapsed_time_seconds': 68.125075,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 10, 16, 56, 22, 353231),
 'httpcompression/response_bytes': 22329717,
 'httpcompression/response_count': 144,
 'httperror/response_ignored_count': 21,
 'httperror/response_ignored_status_count/403': 21,
 'item_scraped_count': 64,
 'log_count/DEBUG': 285,
 'log_count/ERROR': 3,
 'log_count/INFO': 32,
 'request_depth_max': 1,
 'response_received_count': 163,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2022, 12, 10, 16, 55, 14, 228156)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: e67f45dd49388d0c
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1990596158288 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1990596158288 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1990596158288 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1990596158288 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'index': 8,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'index': 7,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Scraped from <200 https://www.caltreeservice.com/contact-us>
{'emails': ['office@caltreeservice.com'],
 'facebook': 'https://www.facebook.com/samcolemanluxury',
 'index': 9,
 'instagram': 'https://www.instagram.com/samcolemanluxury/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/south-bay/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Monster-Tree-Service-of-South-Bay-1088163361240866/',
 'index': 12,
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Scraped from <200 https://octreeservices.com/contact-us/>
{'emails': ['octreeservices1@gmail.com'],
 'facebook': 'N/A',
 'index': 1,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/contact> (referer: https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/west-valley/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/Monster-Tree-Service-of-West-Valley-1287919078019258/',
 'index': 24,
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/'}
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Scraped from <200 https://www.bigtstrees.com/contact>
{'emails': ['831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'bigtstrees@yahoo.com',
            'igtstrees@yahoo.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'http://www.facebook.com/BigTsTrees',
 'index': 22,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite> (referer: None)
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://westcoastarborists.com/>
{'emails': ['wcahiring@wcainc.com', 'corporate@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'index': 17,
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
DEBUG: Scraped from <200 https://rndtreeservices.com/contact-us>
{'emails': ['filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/106157038650413',
 'index': 25,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.monstertreeservice.com/coast/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsteroftheCoast/',
 'index': 13,
 'instagram': 'https://www.instagram.com/monsterofthecoast/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Scraped from <200 https://www.modestotreeservicecompany.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'index': 20,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Scraped from <200 http://www.specializedtreeworks.com/contact.html>
{'emails': ['ContactUs@specializedtreeworks.com'],
 'facebook': 'N/A',
 'index': 28,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 16,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Scraped from <200 https://arborworksinc.com/contact/>
{'emails': ['information@arborworksinc.com'],
 'facebook': 'https://www.facebook.com/arborworks1/',
 'index': 4,
 'instagram': 'https://www.instagram.com/arborworksllc/',
 'linkedin': 'https://www.linkedin.com/company/arborworksinc',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.tomdaytreeservice.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/TomDayTreeService/reviews/',
 'index': 11,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/contact.html> (referer: http://www.blackbeartrees.com/)
DEBUG: Scraped from <200 https://losangelesca-treeservice.com/contact>
{'emails': ['u003Elosangelescatreeservice@gmail.com',
            'losangelescatreeservice@gmail.com'],
 'facebook': 'https://www.facebook.com/losangelescatreeservice/',
 'index': 27,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
DEBUG: Scraped from <200 http://www.blackbeartrees.com/contact.html>
{'emails': ['blackbeartreeservice559@gmail.com'],
 'facebook': 'N/A',
 'index': 33,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/contact/privacy/> (referer: https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite)
DEBUG: Scraped from <200 https://www.traversotree.com/contacts/>
{'emails': ['Office@traversotree.com', 'office@traversotree.com'],
 'facebook': 'https://www.facebook.com/traversotree',
 'index': 19,
 'instagram': 'https://www.instagram.com/traversotree/?hl=en',
 'linkedin': 'https://www.linkedin.com/pub/traverso-tree-service/38/6a3/a40',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
DEBUG: Scraped from <200 http://www.vetreeservice.com/contactus.html>
{'emails': ['Ed@vetreeservice.com',
            'Ashleigh@vetreeservice.com',
            'John@vetreeservice.com',
            'dns@technologydimensions.com',
            'Vic@vetreeservice.com',
            'Eric@vetreeservice.com',
            'Patti@vetreeservice.com',
            'patti@vetreeservice.com'],
 'facebook': 'N/A',
 'index': 35,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.tiptoparborists.com/contact/privacy/>
{'emails': ['privacy@reachlocal.com.'],
 'facebook': 'https://www.facebook.com/pg/Tip-Top-Arborists-Inc-608355719230396/reviews/',
 'index': 3,
 'instagram': 'https://www.instagram.com/tip_top_arborists/',
 'linkedin': 'https://www.linkedin.com/company/tip-top-arborists',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://bayareatreespecialists.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Bay-Area-Tree-Specialists-658134177581480/?timeline_context_item_type=intro_card_work&timeline_context_item_source=100007956785104',
 'index': 32,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/TreesSpecialist'}
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Scraped from <200 https://fallenleaftree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/fallenleaftreemanagement',
 'index': 18,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FallenLeafTree'}
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 23,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://californiagreentreecare.com/contact.php>
{'emails': ['info@californiagreentreecare.com'],
 'facebook': 'N/A',
 'index': 34,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'index': 38,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Scraped from <200 https://www.herculestreeservice.com/contact/>
{'emails': ['info@herculestreeservice.com'],
 'facebook': 'https://www.facebook.com/510799tree/',
 'index': 6,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 39,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.adolphstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
INFO: Ignoring response <403 https://www.adolphstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.aearborists.com/contact-us/>
{'emails': ['aearborists@gmail.com'],
 'facebook': 'https://www.facebook.com/AE-Arborists-Tree-Care-428707717460988/ ',
 'index': 2,
 'instagram': 'https://www.instagram.com/aearborists/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/aearborists'}
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['sales@shipmantree.com', 'dillanmcather@gmail.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'index': 44,
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 50,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Scraped from <200 https://www.commercialtreeservices.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/commercialtreeservices',
 'index': 51,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> from <GET https://www.gomezlandscapeandtreecare.com/contact.php>
DEBUG: Redirecting (301) to <GET https://www.affordabletreeservicesorangecounty.com/> from <GET http://www.affordabletreeservicesorangecounty.com/>
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 41,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> (referer: https://www.gomezlandscapeandtreecare.com/)
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Scraped from <200 https://www.theneckofthewoods.com/contact-us.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/eddie.farquharson',
 'index': 56,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Scraped from <200 https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php>
{'emails': ['sales@gomezltc.com'],
 'facebook': '//www.facebook.com/Gomez-Landscape-Tree-Care-Inc-885181728164027/',
 'index': 58,
 'instagram': '//www.instagram.com/gomezlandscapetreecare/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Scraped from <200 https://www.a1treeredding.com/contact/>
{'emails': ['office@a1treeredding.com', 'Office@a1treeredding.com'],
 'facebook': 'https://www.facebook.com/A1treeredding/',
 'index': 60,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'index': 49,
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'index': 48,
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Scraped from <200 https://www.atlas-tree.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/AtlasTreeSurgery',
 'index': 64,
 'instagram': 'https://www.instagram.com/atlas.tree/',
 'linkedin': 'https://www.linkedin.com/company/atlas-tree-landscape-inc/about/',
 'twitter': 'https://twitter.com/atlas_and'}
DEBUG: Scraped from <200 https://cutitrighttreeservicefresno.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'index': 45,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.eastbaytreeservice.com/> from <GET http://www.eastbaytreeservice.com/>
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'index': 61,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
DEBUG: Scraped from <200 https://foresttreeservices.com/contact-us/>
{'emails': ['info@foresttreeservices.com'],
 'facebook': 'https://www.facebook.com/foresttreeservices',
 'index': 37,
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/company/forest-tree-services/about/',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'index': 62,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/> (referer: None)
DEBUG: Scraped from <200 https://www.sequoiastreeservice.com/>
{'emails': ['evencio.martinez@yahoo.com'],
 'facebook': 'https://www.facebook.com/Sequoias-Tree-Service-104264014496885/',
 'index': 26,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/contact-us/> (referer: https://www.affordabletreeservicesorangecounty.com/)
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.treeserviceroseville.com/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'index': 59,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['customerservice@mowbrays.com', 'info@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'index': 47,
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.eastbaytreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.affordabletreeservicesorangecounty.com/contact-us/>
{'emails': ['20treeremovaloc@gmail.com', 'treeremovaloc@gmail.com'],
 'facebook': 'N/A',
 'index': 52,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (200) <GET http://acutabovetreesvc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
DEBUG: Redirecting (301) to <GET https://stocktontreeservices.com/> from <GET https://www.stocktontreeservices.com/>
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/index.html#contact> (referer: http://www.abotreeservice.com/)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Scraped from <200 http://www.abotreeservice.com/index.html>
{'emails': ['operation@abotreeservice.com',
            'info@abotreeservice.com',
            'krasimira.stoyanova@deluxe.com'],
 'facebook': 'https://www.facebook.com/abotreeservice',
 'index': 67,
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/abotreeservice',
 'twitter': 'https://twitter.com/abotreeservice'}
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://navastree.wixsite.com/my-site> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Scraped from <200 https://ranchotreeservice.com/contact/>
{'emails': ['info@ranchotreeservice.com'],
 'facebook': 'https://www.facebook.com/Rancho-Tree-Service-109046575024387',
 'index': 74,
 'instagram': 'https://www.instagram.com/ranchotreeservice/',
 'linkedin': 'https://www.linkedin.com/company/rancho-inc-california/',
 'twitter': 'https://twitter.com/RanchoTree'}
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.stevestreeservice.net/> from <GET http://www.stevestreeservice.net/>
DEBUG: Crawled (403) <GET http://www.buenavistatree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
INFO: Ignoring response <403 http://www.buenavistatree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://www.petestreeservice.com/> (referer: None)
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'index': 79,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
INFO: Ignoring response <403 https://www.petestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'index': 78,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://jesustreeserviceandlandscaping.com/contact/>
{'emails': ['jesusjgr1987@gmail.com'],
 'facebook': 'https://www.facebook.com/Jesus-Tree-Services-Landscaping-104850001236628',
 'index': 36,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 44, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (403) <GET http://www.lunatreetrimming.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.runyonstree.com/> (referer: None)
DEBUG: Scraped from <200 https://jtstree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/category/Shopping---Retail/Jts-Inc-510518789043998/',
 'index': 77,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
INFO: Ignoring response <403 http://www.lunatreetrimming.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 https://www.runyonstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 89,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/contact-2/> (referer: https://stocktontreeservices.com/)
DEBUG: Redirecting (301) to <GET https://arbortask.com/> from <GET http://www.arbortask.com/>
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 90,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Scraped from <200 https://stocktontreeservices.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'index': 69,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/> (referer: None)
DEBUG: Scraped from <200 https://dprotreeservice.com/contact-us/>
{'emails': ['d.protreeservice@gmail.com'],
 'facebook': 'N/A',
 'index': 63,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 91,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://greenzwaytreeservice.com/contact/>
{'emails': ['greenzway@hotmail.com', 'Greenzway@hotmail.com'],
 'facebook': 'https://www.facebook.com/pg/greenzway',
 'index': 93,
 'instagram': 'https://www.instagram.com/greenzway_official',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/contact/> (referer: https://www.stevestreeservice.net/)
DEBUG: Scraped from <200 https://www.stevestreeservice.net/contact/>
{'emails': ['steves8733@gmail.com'],
 'facebook': 'N/A',
 'index': 94,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Scraped from <200 https://www.lctrees.com/contact/>
{'emails': ['info@lctrees.com'],
 'facebook': 'https://www.facebook.com/LC-Tree-Service-162733330551792/',
 'index': 81,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
DEBUG: Scraped from <200 https://bunyonbros.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/bunyonbrostreeserviceSLO',
 'index': 100,
 'instagram': 'https://www.instagram.com/bunyonbrostreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arbortask.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Scraped from <200 https://treeservicemantecaca.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'index': 84,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://arbortask.com/contact/> from <GET https://arbortask.com/contact>
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arbortask.com/contact/> (referer: https://arbortask.com/)
DEBUG: Scraped from <200 https://arbortask.com/contact/>
{'emails': ['almangrant@yahoo.com'],
 'facebook': 'https://www.facebook.com/arbortasktreeservice/',
 'index': 99,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/contact-us/> (referer: http://www.lewistreeserviceinc.com/)
DEBUG: Scraped from <200 http://www.lewistreeserviceinc.com/contact-us/>
{'emails': ['Admin@lewistreeserviceinc.com', 'admin@lewistreeserviceinc.com'],
 'facebook': 'N/A',
 'index': 92,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Crawled 163 pages (at 163 pages/min), scraped 64 items (at 64 items/min)
ERROR: Gave up retrying <GET http://www.alliancetrees.com/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Error downloading <GET http://www.alliancetrees.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 64904,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 5291914,
 'downloader/response_count': 212,
 'downloader/response_status_count/200': 142,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/302': 2,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/308': 1,
 'downloader/response_status_count/403': 21,
 'elapsed_time_seconds': 68.415592,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 10, 16, 58, 38, 646801),
 'httpcompression/response_bytes': 22331198,
 'httpcompression/response_count': 144,
 'httperror/response_ignored_count': 21,
 'httperror/response_ignored_status_count/403': 21,
 'item_scraped_count': 64,
 'log_count/DEBUG': 285,
 'log_count/ERROR': 3,
 'log_count/INFO': 32,
 'request_depth_max': 1,
 'response_received_count': 163,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2022, 12, 10, 16, 57, 30, 231209)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 284724e8f6bf93eb
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 3032599904896 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 3032599904896 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 3032599904896 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 3032599904896 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'index': 8,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'index': 7,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/coast/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsteroftheCoast/',
 'index': 13,
 'instagram': 'https://www.instagram.com/monsterofthecoast/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.monstertreeservice.com/south-bay/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Monster-Tree-Service-of-South-Bay-1088163361240866/',
 'index': 12,
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Scraped from <200 https://www.caltreeservice.com/contact-us>
{'emails': ['office@caltreeservice.com'],
 'facebook': 'https://www.facebook.com/samcolemanluxury',
 'index': 9,
 'instagram': 'https://www.instagram.com/samcolemanluxury/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Scraped from <200 https://octreeservices.com/contact-us/>
{'emails': ['octreeservices1@gmail.com'],
 'facebook': 'N/A',
 'index': 1,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Scraped from <200 https://www.tomdaytreeservice.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/TomDayTreeService/reviews/',
 'index': 11,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/contact> (referer: https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
DEBUG: Scraped from <200 https://www.bigtstrees.com/contact>
{'emails': ['831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'igtstrees@yahoo.com',
            'bigtstrees@yahoo.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'http://www.facebook.com/BigTsTrees',
 'index': 22,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.specializedtreeworks.com/contact.html>
{'emails': ['ContactUs@specializedtreeworks.com'],
 'facebook': 'N/A',
 'index': 28,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://rndtreeservices.com/contact-us>
{'emails': ['filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/106157038650413',
 'index': 25,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://westcoastarborists.com/>
{'emails': ['wcahiring@wcainc.com', 'corporate@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'index': 17,
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/> (referer: None)
DEBUG: Scraped from <200 https://arborworksinc.com/contact/>
{'emails': ['information@arborworksinc.com'],
 'facebook': 'https://www.facebook.com/arborworks1/',
 'index': 4,
 'instagram': 'https://www.instagram.com/arborworksllc/',
 'linkedin': 'https://www.linkedin.com/company/arborworksinc',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 16,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Scraped from <200 https://www.modestotreeservicecompany.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'index': 20,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/west-valley/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/Monster-Tree-Service-of-West-Valley-1287919078019258/',
 'index': 24,
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/'}
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Scraped from <200 https://bayareatreespecialists.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Bay-Area-Tree-Specialists-658134177581480/?timeline_context_item_type=intro_card_work&timeline_context_item_source=100007956785104',
 'index': 32,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/TreesSpecialist'}
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/contact.html> (referer: http://www.blackbeartrees.com/)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/contact/privacy/> (referer: https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite)
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
DEBUG: Scraped from <200 http://www.vetreeservice.com/contactus.html>
{'emails': ['Ashleigh@vetreeservice.com',
            'dns@technologydimensions.com',
            'John@vetreeservice.com',
            'Patti@vetreeservice.com',
            'Ed@vetreeservice.com',
            'Eric@vetreeservice.com',
            'patti@vetreeservice.com',
            'Vic@vetreeservice.com'],
 'facebook': 'N/A',
 'index': 35,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.blackbeartrees.com/contact.html>
{'emails': ['blackbeartreeservice559@gmail.com'],
 'facebook': 'N/A',
 'index': 33,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://losangelesca-treeservice.com/contact>
{'emails': ['losangelescatreeservice@gmail.com',
            'u003Elosangelescatreeservice@gmail.com'],
 'facebook': 'https://www.facebook.com/losangelescatreeservice/',
 'index': 27,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.tiptoparborists.com/contact/privacy/>
{'emails': ['privacy@reachlocal.com.'],
 'facebook': 'https://www.facebook.com/pg/Tip-Top-Arborists-Inc-608355719230396/reviews/',
 'index': 3,
 'instagram': 'https://www.instagram.com/tip_top_arborists/',
 'linkedin': 'https://www.linkedin.com/company/tip-top-arborists',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.traversotree.com/contacts/>
{'emails': ['Office@traversotree.com', 'office@traversotree.com'],
 'facebook': 'https://www.facebook.com/traversotree',
 'index': 19,
 'instagram': 'https://www.instagram.com/traversotree/?hl=en',
 'linkedin': 'https://www.linkedin.com/pub/traverso-tree-service/38/6a3/a40',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 23,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Scraped from <200 https://fallenleaftree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/fallenleaftreemanagement',
 'index': 18,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FallenLeafTree'}
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Scraped from <200 https://californiagreentreecare.com/contact.php>
{'emails': ['info@californiagreentreecare.com'],
 'facebook': 'N/A',
 'index': 34,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 39,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Scraped from <200 http://www.aearborists.com/contact-us/>
{'emails': ['aearborists@gmail.com'],
 'facebook': 'https://www.facebook.com/AE-Arborists-Tree-Care-428707717460988/ ',
 'index': 2,
 'instagram': 'https://www.instagram.com/aearborists/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/aearborists'}
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'index': 38,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (403) <GET https://www.adolphstreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.herculestreeservice.com/contact/>
{'emails': ['info@herculestreeservice.com'],
 'facebook': 'https://www.facebook.com/510799tree/',
 'index': 6,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
INFO: Ignoring response <403 https://www.adolphstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
DEBUG: Scraped from <200 https://foresttreeservices.com/contact-us/>
{'emails': ['info@foresttreeservices.com'],
 'facebook': 'https://www.facebook.com/foresttreeservices',
 'index': 37,
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/company/forest-tree-services/about/',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Scraped from <200 https://www.commercialtreeservices.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/commercialtreeservices',
 'index': 51,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['dillanmcather@gmail.com', 'sales@shipmantree.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'index': 44,
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Scraped from <200 https://www.a1treeredding.com/contact/>
{'emails': ['office@a1treeredding.com', 'Office@a1treeredding.com'],
 'facebook': 'https://www.facebook.com/A1treeredding/',
 'index': 60,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Scraped from <200 https://www.theneckofthewoods.com/contact-us.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/eddie.farquharson',
 'index': 56,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 50,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> from <GET https://www.gomezlandscapeandtreecare.com/contact.php>
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 41,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Redirecting (301) to <GET https://www.affordabletreeservicesorangecounty.com/> from <GET http://www.affordabletreeservicesorangecounty.com/>
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'index': 48,
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.atlas-tree.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/AtlasTreeSurgery',
 'index': 64,
 'instagram': 'https://www.instagram.com/atlas.tree/',
 'linkedin': 'https://www.linkedin.com/company/atlas-tree-landscape-inc/about/',
 'twitter': 'https://twitter.com/atlas_and'}
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> (referer: https://www.gomezlandscapeandtreecare.com/)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'index': 49,
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'index': 61,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Scraped from <200 https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php>
{'emails': ['sales@gomezltc.com'],
 'facebook': '//www.facebook.com/Gomez-Landscape-Tree-Care-Inc-885181728164027/',
 'index': 58,
 'instagram': '//www.instagram.com/gomezlandscapetreecare/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'index': 62,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Scraped from <200 https://cutitrighttreeservicefresno.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'index': 45,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.eastbaytreeservice.com/> from <GET http://www.eastbaytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
DEBUG: Scraped from <200 https://www.treeserviceroseville.com/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'index': 59,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/> (referer: None)
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.eastbaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
DEBUG: Crawled (200) <GET http://acutabovetreesvc.com/> (referer: None)
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['customerservice@mowbrays.com', 'info@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'index': 47,
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/contact-us/> (referer: https://www.affordabletreeservicesorangecounty.com/)
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Redirecting (301) to <GET https://stocktontreeservices.com/> from <GET https://www.stocktontreeservices.com/>
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
DEBUG: Scraped from <200 https://www.affordabletreeservicesorangecounty.com/contact-us/>
{'emails': ['treeremovaloc@gmail.com', '20treeremovaloc@gmail.com'],
 'facebook': 'N/A',
 'index': 52,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/index.html#contact> (referer: http://www.abotreeservice.com/)
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.abotreeservice.com/index.html>
{'emails': ['operation@abotreeservice.com',
            'info@abotreeservice.com',
            'krasimira.stoyanova@deluxe.com'],
 'facebook': 'https://www.facebook.com/abotreeservice',
 'index': 67,
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/abotreeservice',
 'twitter': 'https://twitter.com/abotreeservice'}
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://dprotreeservice.com/contact-us/>
{'emails': ['d.protreeservice@gmail.com'],
 'facebook': 'N/A',
 'index': 63,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://navastree.wixsite.com/my-site> (referer: None)
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://ranchotreeservice.com/contact/>
{'emails': ['info@ranchotreeservice.com'],
 'facebook': 'https://www.facebook.com/Rancho-Tree-Service-109046575024387',
 'index': 74,
 'instagram': 'https://www.instagram.com/ranchotreeservice/',
 'linkedin': 'https://www.linkedin.com/company/rancho-inc-california/',
 'twitter': 'https://twitter.com/RanchoTree'}
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
DEBUG: Scraped from <200 https://jtstree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/category/Shopping---Retail/Jts-Inc-510518789043998/',
 'index': 77,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.buenavistatree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.stevestreeservice.net/> from <GET http://www.stevestreeservice.net/>
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
INFO: Ignoring response <403 http://www.buenavistatree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Scraped from <200 https://www.sequoiastreeservice.com/>
{'emails': ['evencio.martinez@yahoo.com'],
 'facebook': 'https://www.facebook.com/Sequoias-Tree-Service-104264014496885/',
 'index': 26,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'index': 79,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET https://www.petestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.runyonstree.com/> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 44, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
INFO: Ignoring response <403 https://www.petestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.lunatreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
INFO: Ignoring response <403 https://www.runyonstree.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.lunatreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/contact-2/> (referer: https://stocktontreeservices.com/)
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'index': 78,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 89,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Scraped from <200 https://stocktontreeservices.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'index': 69,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://arbortask.com/> from <GET http://www.arbortask.com/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 91,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 90,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://greenzwaytreeservice.com/contact/>
{'emails': ['Greenzway@hotmail.com', 'greenzway@hotmail.com'],
 'facebook': 'https://www.facebook.com/pg/greenzway',
 'index': 93,
 'instagram': 'https://www.instagram.com/greenzway_official',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
DEBUG: Scraped from <200 https://jesustreeserviceandlandscaping.com/contact/>
{'emails': ['jesusjgr1987@gmail.com'],
 'facebook': 'https://www.facebook.com/Jesus-Tree-Services-Landscaping-104850001236628',
 'index': 36,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/contact/> (referer: https://www.stevestreeservice.net/)
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Scraped from <200 https://www.stevestreeservice.net/contact/>
{'emails': ['steves8733@gmail.com'],
 'facebook': 'N/A',
 'index': 94,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Scraped from <200 https://www.lctrees.com/contact/>
{'emails': ['info@lctrees.com'],
 'facebook': 'https://www.facebook.com/LC-Tree-Service-162733330551792/',
 'index': 81,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
DEBUG: Scraped from <200 https://bunyonbros.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/bunyonbrostreeserviceSLO',
 'index': 100,
 'instagram': 'https://www.instagram.com/bunyonbrostreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arbortask.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Scraped from <200 https://treeservicemantecaca.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'index': 84,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://arbortask.com/contact/> from <GET https://arbortask.com/contact>
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/contact-us/> (referer: http://www.lewistreeserviceinc.com/)
DEBUG: Scraped from <200 http://www.lewistreeserviceinc.com/contact-us/>
{'emails': ['Admin@lewistreeserviceinc.com', 'admin@lewistreeserviceinc.com'],
 'facebook': 'N/A',
 'index': 92,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arbortask.com/contact/> (referer: https://arbortask.com/)
DEBUG: Scraped from <200 https://arbortask.com/contact/>
{'emails': ['almangrant@yahoo.com'],
 'facebook': 'https://www.facebook.com/arbortasktreeservice/',
 'index': 99,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Crawled 163 pages (at 163 pages/min), scraped 64 items (at 64 items/min)
ERROR: Gave up retrying <GET http://www.alliancetrees.com/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Error downloading <GET http://www.alliancetrees.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 64391,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 5291671,
 'downloader/response_count': 212,
 'downloader/response_status_count/200': 142,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/302': 2,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/308': 1,
 'downloader/response_status_count/403': 21,
 'elapsed_time_seconds': 68.126351,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 10, 17, 0, 32, 469128),
 'httpcompression/response_bytes': 22329711,
 'httpcompression/response_count': 144,
 'httperror/response_ignored_count': 21,
 'httperror/response_ignored_status_count/403': 21,
 'item_scraped_count': 64,
 'log_count/DEBUG': 285,
 'log_count/ERROR': 3,
 'log_count/INFO': 32,
 'request_depth_max': 1,
 'response_received_count': 163,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2022, 12, 10, 16, 59, 24, 342777)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 8be4c5985868cfdf
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1812227901760 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1812227901760 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1812227901760 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1812227901760 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'index': 8,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'index': 7,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.caltreeservice.com/contact-us>
{'emails': ['office@caltreeservice.com'],
 'facebook': 'https://www.facebook.com/samcolemanluxury',
 'index': 9,
 'instagram': 'https://www.instagram.com/samcolemanluxury/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/coast/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsteroftheCoast/',
 'index': 13,
 'instagram': 'https://www.instagram.com/monsterofthecoast/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/south-bay/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Monster-Tree-Service-of-South-Bay-1088163361240866/',
 'index': 12,
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/west-valley/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/Monster-Tree-Service-of-West-Valley-1287919078019258/',
 'index': 24,
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/'}
DEBUG: Scraped from <200 https://octreeservices.com/contact-us/>
{'emails': ['octreeservices1@gmail.com'],
 'facebook': 'N/A',
 'index': 1,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/contact> (referer: https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Scraped from <200 https://rndtreeservices.com/contact-us>
{'emails': ['filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/106157038650413',
 'index': 25,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.bigtstrees.com/contact>
{'emails': ['igtstrees@yahoo.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'bigtstrees@yahoo.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'http://www.facebook.com/BigTsTrees',
 'index': 22,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://westcoastarborists.com/>
{'emails': ['wcahiring@wcainc.com', 'corporate@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'index': 17,
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.specializedtreeworks.com/contact.html>
{'emails': ['ContactUs@specializedtreeworks.com'],
 'facebook': 'N/A',
 'index': 28,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
DEBUG: Scraped from <200 https://www.modestotreeservicecompany.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'index': 20,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Scraped from <200 https://www.tomdaytreeservice.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/TomDayTreeService/reviews/',
 'index': 11,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 16,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Scraped from <200 https://bayareatreespecialists.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Bay-Area-Tree-Specialists-658134177581480/?timeline_context_item_type=intro_card_work&timeline_context_item_source=100007956785104',
 'index': 32,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/TreesSpecialist'}
DEBUG: Scraped from <200 https://arborworksinc.com/contact/>
{'emails': ['information@arborworksinc.com'],
 'facebook': 'https://www.facebook.com/arborworks1/',
 'index': 4,
 'instagram': 'https://www.instagram.com/arborworksllc/',
 'linkedin': 'https://www.linkedin.com/company/arborworksinc',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/contact.html> (referer: http://www.blackbeartrees.com/)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
DEBUG: Scraped from <200 https://losangelesca-treeservice.com/contact>
{'emails': ['u003Elosangelescatreeservice@gmail.com',
            'losangelescatreeservice@gmail.com'],
 'facebook': 'https://www.facebook.com/losangelescatreeservice/',
 'index': 27,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Scraped from <200 http://www.blackbeartrees.com/contact.html>
{'emails': ['blackbeartreeservice559@gmail.com'],
 'facebook': 'N/A',
 'index': 33,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Scraped from <200 http://www.vetreeservice.com/contactus.html>
{'emails': ['patti@vetreeservice.com',
            'Ed@vetreeservice.com',
            'Vic@vetreeservice.com',
            'Ashleigh@vetreeservice.com',
            'John@vetreeservice.com',
            'Patti@vetreeservice.com',
            'dns@technologydimensions.com',
            'Eric@vetreeservice.com'],
 'facebook': 'N/A',
 'index': 35,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Scraped from <200 https://fallenleaftree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/fallenleaftreemanagement',
 'index': 18,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FallenLeafTree'}
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/contact/privacy/> (referer: https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 23,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://californiagreentreecare.com/contact.php>
{'emails': ['info@californiagreentreecare.com'],
 'facebook': 'N/A',
 'index': 34,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.tiptoparborists.com/contact/privacy/>
{'emails': ['privacy@reachlocal.com.'],
 'facebook': 'https://www.facebook.com/pg/Tip-Top-Arborists-Inc-608355719230396/reviews/',
 'index': 3,
 'instagram': 'https://www.instagram.com/tip_top_arborists/',
 'linkedin': 'https://www.linkedin.com/company/tip-top-arborists',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
DEBUG: Scraped from <200 https://www.traversotree.com/contacts/>
{'emails': ['Office@traversotree.com', 'office@traversotree.com'],
 'facebook': 'https://www.facebook.com/traversotree',
 'index': 19,
 'instagram': 'https://www.instagram.com/traversotree/?hl=en',
 'linkedin': 'https://www.linkedin.com/pub/traverso-tree-service/38/6a3/a40',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 39,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Scraped from <200 http://www.aearborists.com/contact-us/>
{'emails': ['aearborists@gmail.com'],
 'facebook': 'https://www.facebook.com/AE-Arborists-Tree-Care-428707717460988/ ',
 'index': 2,
 'instagram': 'https://www.instagram.com/aearborists/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/aearborists'}
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Crawled (403) <GET https://www.adolphstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
INFO: Ignoring response <403 https://www.adolphstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.herculestreeservice.com/contact/>
{'emails': ['info@herculestreeservice.com'],
 'facebook': 'https://www.facebook.com/510799tree/',
 'index': 6,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'index': 38,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://foresttreeservices.com/contact-us/>
{'emails': ['info@foresttreeservices.com'],
 'facebook': 'https://www.facebook.com/foresttreeservices',
 'index': 37,
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/company/forest-tree-services/about/',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
DEBUG: Scraped from <200 https://www.commercialtreeservices.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/commercialtreeservices',
 'index': 51,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['sales@shipmantree.com', 'dillanmcather@gmail.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'index': 44,
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.a1treeredding.com/contact/>
{'emails': ['office@a1treeredding.com', 'Office@a1treeredding.com'],
 'facebook': 'https://www.facebook.com/A1treeredding/',
 'index': 60,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.affordabletreeservicesorangecounty.com/> from <GET http://www.affordabletreeservicesorangecounty.com/>
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 50,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (301) to <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> from <GET https://www.gomezlandscapeandtreecare.com/contact.php>
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Scraped from <200 https://cutitrighttreeservicefresno.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'index': 45,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'index': 49,
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'index': 48,
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Scraped from <200 https://www.atlas-tree.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/AtlasTreeSurgery',
 'index': 64,
 'instagram': 'https://www.instagram.com/atlas.tree/',
 'linkedin': 'https://www.linkedin.com/company/atlas-tree-landscape-inc/about/',
 'twitter': 'https://twitter.com/atlas_and'}
DEBUG: Scraped from <200 https://www.theneckofthewoods.com/contact-us.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/eddie.farquharson',
 'index': 56,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> (referer: https://www.gomezlandscapeandtreecare.com/)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Scraped from <200 https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php>
{'emails': ['sales@gomezltc.com'],
 'facebook': '//www.facebook.com/Gomez-Landscape-Tree-Care-Inc-885181728164027/',
 'index': 58,
 'instagram': '//www.instagram.com/gomezlandscapetreecare/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['fred@richardstree.com', 'info@richardstree.com'],
 'facebook': 'N/A',
 'index': 61,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.eastbaytreeservice.com/> from <GET http://www.eastbaytreeservice.com/>
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 41,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['fred@richardstree.com', 'info@richardstree.com'],
 'facebook': 'N/A',
 'index': 62,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/> (referer: None)
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.sequoiastreeservice.com/>
{'emails': ['evencio.martinez@yahoo.com'],
 'facebook': 'https://www.facebook.com/Sequoias-Tree-Service-104264014496885/',
 'index': 26,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.eastbaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/contact-us/> (referer: https://www.affordabletreeservicesorangecounty.com/)
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
DEBUG: Crawled (200) <GET http://acutabovetreesvc.com/> (referer: None)
DEBUG: Scraped from <200 https://www.affordabletreeservicesorangecounty.com/contact-us/>
{'emails': ['treeremovaloc@gmail.com', '20treeremovaloc@gmail.com'],
 'facebook': 'N/A',
 'index': 52,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Redirecting (301) to <GET https://stocktontreeservices.com/> from <GET https://www.stocktontreeservices.com/>
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Scraped from <200 https://www.treeserviceroseville.com/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'index': 59,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/index.html#contact> (referer: http://www.abotreeservice.com/)
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
DEBUG: Scraped from <200 http://www.abotreeservice.com/index.html>
{'emails': ['operation@abotreeservice.com',
            'krasimira.stoyanova@deluxe.com',
            'info@abotreeservice.com'],
 'facebook': 'https://www.facebook.com/abotreeservice',
 'index': 67,
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/abotreeservice',
 'twitter': 'https://twitter.com/abotreeservice'}
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['customerservice@mowbrays.com', 'info@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'index': 47,
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://dprotreeservice.com/contact-us/>
{'emails': ['d.protreeservice@gmail.com'],
 'facebook': 'N/A',
 'index': 63,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://navastree.wixsite.com/my-site> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
DEBUG: Scraped from <200 https://jtstree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/category/Shopping---Retail/Jts-Inc-510518789043998/',
 'index': 77,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://ranchotreeservice.com/contact/>
{'emails': ['info@ranchotreeservice.com'],
 'facebook': 'https://www.facebook.com/Rancho-Tree-Service-109046575024387',
 'index': 74,
 'instagram': 'https://www.instagram.com/ranchotreeservice/',
 'linkedin': 'https://www.linkedin.com/company/rancho-inc-california/',
 'twitter': 'https://twitter.com/RanchoTree'}
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.stevestreeservice.net/> from <GET http://www.stevestreeservice.net/>
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.buenavistatree.com/> (referer: None)
INFO: Ignoring response <403 http://www.buenavistatree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://www.runyonstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.runyonstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 44, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (403) <GET http://www.lunatreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.petestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
INFO: Ignoring response <403 http://www.lunatreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
INFO: Ignoring response <403 https://www.petestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://jesustreeserviceandlandscaping.com/contact/>
{'emails': ['jesusjgr1987@gmail.com'],
 'facebook': 'https://www.facebook.com/Jesus-Tree-Services-Landscaping-104850001236628',
 'index': 36,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/contact-2/> (referer: https://stocktontreeservices.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Scraped from <200 https://stocktontreeservices.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'index': 69,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Redirecting (301) to <GET https://arbortask.com/> from <GET http://www.arbortask.com/>
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 91,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'index': 78,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 90,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 89,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'index': 79,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://greenzwaytreeservice.com/contact/>
{'emails': ['Greenzway@hotmail.com', 'greenzway@hotmail.com'],
 'facebook': 'https://www.facebook.com/pg/greenzway',
 'index': 93,
 'instagram': 'https://www.instagram.com/greenzway_official',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/contact/> (referer: https://www.stevestreeservice.net/)
DEBUG: Scraped from <200 https://www.stevestreeservice.net/contact/>
{'emails': ['steves8733@gmail.com'],
 'facebook': 'N/A',
 'index': 94,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
DEBUG: Scraped from <200 https://bunyonbros.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/bunyonbrostreeserviceSLO',
 'index': 100,
 'instagram': 'https://www.instagram.com/bunyonbrostreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arbortask.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Redirecting (301) to <GET https://arbortask.com/contact/> from <GET https://arbortask.com/contact>
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Scraped from <200 https://treeservicemantecaca.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'index': 84,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Scraped from <200 https://www.lctrees.com/contact/>
{'emails': ['info@lctrees.com'],
 'facebook': 'https://www.facebook.com/LC-Tree-Service-162733330551792/',
 'index': 81,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/contact-us/> (referer: http://www.lewistreeserviceinc.com/)
DEBUG: Crawled (200) <GET https://arbortask.com/contact/> (referer: https://arbortask.com/)
DEBUG: Scraped from <200 http://www.lewistreeserviceinc.com/contact-us/>
{'emails': ['Admin@lewistreeserviceinc.com', 'admin@lewistreeserviceinc.com'],
 'facebook': 'N/A',
 'index': 92,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://arbortask.com/contact/>
{'emails': ['almangrant@yahoo.com'],
 'facebook': 'https://www.facebook.com/arbortasktreeservice/',
 'index': 99,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Crawled 163 pages (at 163 pages/min), scraped 64 items (at 64 items/min)
ERROR: Gave up retrying <GET http://www.alliancetrees.com/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Error downloading <GET http://www.alliancetrees.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 63879,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 5291125,
 'downloader/response_count': 212,
 'downloader/response_status_count/200': 142,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/302': 2,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/308': 1,
 'downloader/response_status_count/403': 21,
 'elapsed_time_seconds': 68.413475,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 10, 17, 2, 29, 510666),
 'httpcompression/response_bytes': 22329715,
 'httpcompression/response_count': 144,
 'httperror/response_ignored_count': 21,
 'httperror/response_ignored_status_count/403': 21,
 'item_scraped_count': 64,
 'log_count/DEBUG': 285,
 'log_count/ERROR': 3,
 'log_count/INFO': 32,
 'request_depth_max': 1,
 'response_received_count': 163,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2022, 12, 10, 17, 1, 21, 97191)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 704d1a2dd3405e2a
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 1864667424624 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1864667424624 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1864667424624 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1864667424624 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'index': 8,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'index': 7,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Scraped from <200 https://www.caltreeservice.com/contact-us>
{'emails': ['office@caltreeservice.com'],
 'facebook': 'https://www.facebook.com/samcolemanluxury',
 'index': 9,
 'instagram': 'https://www.instagram.com/samcolemanluxury/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.monstertreeservice.com/west-valley/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/Monster-Tree-Service-of-West-Valley-1287919078019258/',
 'index': 24,
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/'}
DEBUG: Scraped from <200 https://octreeservices.com/contact-us/>
{'emails': ['octreeservices1@gmail.com'],
 'facebook': 'N/A',
 'index': 1,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/contact> (referer: https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/coast/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsteroftheCoast/',
 'index': 13,
 'instagram': 'https://www.instagram.com/monsterofthecoast/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Scraped from <200 https://www.bigtstrees.com/contact>
{'emails': ['831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'bigtstrees@yahoo.com',
            'igtstrees@yahoo.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com'],
 'facebook': 'http://www.facebook.com/BigTsTrees',
 'index': 22,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Scraped from <200 https://rndtreeservices.com/contact-us>
{'emails': ['filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/106157038650413',
 'index': 25,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://westcoastarborists.com/>
{'emails': ['wcahiring@wcainc.com', 'corporate@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'index': 17,
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.monstertreeservice.com/south-bay/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Monster-Tree-Service-of-South-Bay-1088163361240866/',
 'index': 12,
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Scraped from <200 https://www.tomdaytreeservice.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/TomDayTreeService/reviews/',
 'index': 11,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://arborworksinc.com/contact/>
{'emails': ['information@arborworksinc.com'],
 'facebook': 'https://www.facebook.com/arborworks1/',
 'index': 4,
 'instagram': 'https://www.instagram.com/arborworksllc/',
 'linkedin': 'https://www.linkedin.com/company/arborworksinc',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite> (referer: None)
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Scraped from <200 http://www.specializedtreeworks.com/contact.html>
{'emails': ['ContactUs@specializedtreeworks.com'],
 'facebook': 'N/A',
 'index': 28,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.modestotreeservicecompany.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'index': 20,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://losangelesca-treeservice.com/contact>
{'emails': ['losangelescatreeservice@gmail.com',
            'u003Elosangelescatreeservice@gmail.com'],
 'facebook': 'https://www.facebook.com/losangelescatreeservice/',
 'index': 27,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 16,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Scraped from <200 https://bayareatreespecialists.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Bay-Area-Tree-Specialists-658134177581480/?timeline_context_item_type=intro_card_work&timeline_context_item_source=100007956785104',
 'index': 32,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/TreesSpecialist'}
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/contact.html> (referer: http://www.blackbeartrees.com/)
DEBUG: Scraped from <200 https://fallenleaftree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/fallenleaftreemanagement',
 'index': 18,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FallenLeafTree'}
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.blackbeartrees.com/contact.html>
{'emails': ['blackbeartreeservice559@gmail.com'],
 'facebook': 'N/A',
 'index': 33,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
DEBUG: Scraped from <200 http://www.vetreeservice.com/contactus.html>
{'emails': ['patti@vetreeservice.com',
            'John@vetreeservice.com',
            'Patti@vetreeservice.com',
            'Vic@vetreeservice.com',
            'dns@technologydimensions.com',
            'Ashleigh@vetreeservice.com',
            'Eric@vetreeservice.com',
            'Ed@vetreeservice.com'],
 'facebook': 'N/A',
 'index': 35,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/contact/privacy/> (referer: https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite)
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.tiptoparborists.com/contact/privacy/>
{'emails': ['privacy@reachlocal.com.'],
 'facebook': 'https://www.facebook.com/pg/Tip-Top-Arborists-Inc-608355719230396/reviews/',
 'index': 3,
 'instagram': 'https://www.instagram.com/tip_top_arborists/',
 'linkedin': 'https://www.linkedin.com/company/tip-top-arborists',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Scraped from <200 https://www.traversotree.com/contacts/>
{'emails': ['Office@traversotree.com', 'office@traversotree.com'],
 'facebook': 'https://www.facebook.com/traversotree',
 'index': 19,
 'instagram': 'https://www.instagram.com/traversotree/?hl=en',
 'linkedin': 'https://www.linkedin.com/pub/traverso-tree-service/38/6a3/a40',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 23,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'index': 38,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
DEBUG: Scraped from <200 https://www.herculestreeservice.com/contact/>
{'emails': ['info@herculestreeservice.com'],
 'facebook': 'https://www.facebook.com/510799tree/',
 'index': 6,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 39,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.adolphstreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.adolphstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
DEBUG: Scraped from <200 https://californiagreentreecare.com/contact.php>
{'emails': ['info@californiagreentreecare.com'],
 'facebook': 'N/A',
 'index': 34,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['sales@shipmantree.com', 'dillanmcather@gmail.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'index': 44,
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Scraped from <200 https://jesustreeserviceandlandscaping.com/contact/>
{'emails': ['jesusjgr1987@gmail.com'],
 'facebook': 'https://www.facebook.com/Jesus-Tree-Services-Landscaping-104850001236628',
 'index': 36,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 50,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 41,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Scraped from <200 https://foresttreeservices.com/contact-us/>
{'emails': ['info@foresttreeservices.com'],
 'facebook': 'https://www.facebook.com/foresttreeservices',
 'index': 37,
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/company/forest-tree-services/about/',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'index': 48,
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://cutitrighttreeservicefresno.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'index': 45,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.commercialtreeservices.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/commercialtreeservices',
 'index': 51,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'index': 49,
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/> (referer: None)
DEBUG: Scraped from <200 https://www.theneckofthewoods.com/contact-us.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/eddie.farquharson',
 'index': 56,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.affordabletreeservicesorangecounty.com/> from <GET http://www.affordabletreeservicesorangecounty.com/>
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Scraped from <200 https://www.sequoiastreeservice.com/>
{'emails': ['evencio.martinez@yahoo.com'],
 'facebook': 'https://www.facebook.com/Sequoias-Tree-Service-104264014496885/',
 'index': 26,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> from <GET https://www.gomezlandscapeandtreecare.com/contact.php>
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Redirecting (301) to <GET https://www.eastbaytreeservice.com/> from <GET http://www.eastbaytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Scraped from <200 https://www.atlas-tree.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/AtlasTreeSurgery',
 'index': 64,
 'instagram': 'https://www.instagram.com/atlas.tree/',
 'linkedin': 'https://www.linkedin.com/company/atlas-tree-landscape-inc/about/',
 'twitter': 'https://twitter.com/atlas_and'}
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> (referer: https://www.gomezlandscapeandtreecare.com/)
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
DEBUG: Scraped from <200 https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php>
{'emails': ['sales@gomezltc.com'],
 'facebook': '//www.facebook.com/Gomez-Landscape-Tree-Care-Inc-885181728164027/',
 'index': 58,
 'instagram': '//www.instagram.com/gomezlandscapetreecare/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['customerservice@mowbrays.com', 'info@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'index': 47,
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'index': 61,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/> (referer: None)
DEBUG: Scraped from <200 https://www.treeserviceroseville.com/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'index': 59,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.eastbaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'index': 62,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.a1treeredding.com/contact/>
{'emails': ['Office@a1treeredding.com', 'office@a1treeredding.com'],
 'facebook': 'https://www.facebook.com/A1treeredding/',
 'index': 60,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Redirecting (301) to <GET https://stocktontreeservices.com/> from <GET https://www.stocktontreeservices.com/>
DEBUG: Crawled (200) <GET http://acutabovetreesvc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/index.html#contact> (referer: http://www.abotreeservice.com/)
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/contact-us/> (referer: https://www.affordabletreeservicesorangecounty.com/)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 http://www.abotreeservice.com/index.html>
{'emails': ['krasimira.stoyanova@deluxe.com',
            'info@abotreeservice.com',
            'operation@abotreeservice.com'],
 'facebook': 'https://www.facebook.com/abotreeservice',
 'index': 67,
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/abotreeservice',
 'twitter': 'https://twitter.com/abotreeservice'}
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.affordabletreeservicesorangecounty.com/contact-us/>
{'emails': ['treeremovaloc@gmail.com', '20treeremovaloc@gmail.com'],
 'facebook': 'N/A',
 'index': 52,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://navastree.wixsite.com/my-site> (referer: None)
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Scraped from <200 https://ranchotreeservice.com/contact/>
{'emails': ['info@ranchotreeservice.com'],
 'facebook': 'https://www.facebook.com/Rancho-Tree-Service-109046575024387',
 'index': 74,
 'instagram': 'https://www.instagram.com/ranchotreeservice/',
 'linkedin': 'https://www.linkedin.com/company/rancho-inc-california/',
 'twitter': 'https://twitter.com/RanchoTree'}
DEBUG: Scraped from <200 http://www.aearborists.com/contact-us/>
{'emails': ['aearborists@gmail.com'],
 'facebook': 'https://www.facebook.com/AE-Arborists-Tree-Care-428707717460988/ ',
 'index': 2,
 'instagram': 'https://www.instagram.com/aearborists/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/aearborists'}
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Crawled (403) <GET http://www.buenavistatree.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.runyonstree.com/> (referer: None)
DEBUG: Scraped from <200 https://jtstree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/category/Shopping---Retail/Jts-Inc-510518789043998/',
 'index': 77,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.stevestreeservice.net/> from <GET http://www.stevestreeservice.net/>
INFO: Ignoring response <403 http://www.buenavistatree.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
INFO: Ignoring response <403 https://www.runyonstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.lunatreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
INFO: Ignoring response <403 http://www.lunatreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://www.petestreeservice.com/> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 44, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
INFO: Ignoring response <403 https://www.petestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/contact-2/> (referer: https://stocktontreeservices.com/)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Scraped from <200 https://stocktontreeservices.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'index': 69,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Redirecting (301) to <GET https://arbortask.com/> from <GET http://www.arbortask.com/>
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'index': 78,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'index': 79,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 90,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 89,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://dprotreeservice.com/contact-us/>
{'emails': ['d.protreeservice@gmail.com'],
 'facebook': 'N/A',
 'index': 63,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 91,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
DEBUG: Scraped from <200 https://greenzwaytreeservice.com/contact/>
{'emails': ['greenzway@hotmail.com', 'Greenzway@hotmail.com'],
 'facebook': 'https://www.facebook.com/pg/greenzway',
 'index': 93,
 'instagram': 'https://www.instagram.com/greenzway_official',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/contact/> (referer: https://www.stevestreeservice.net/)
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
DEBUG: Scraped from <200 https://www.stevestreeservice.net/contact/>
{'emails': ['steves8733@gmail.com'],
 'facebook': 'N/A',
 'index': 94,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/> (referer: None)
DEBUG: Scraped from <200 https://www.lctrees.com/contact/>
{'emails': ['info@lctrees.com'],
 'facebook': 'https://www.facebook.com/LC-Tree-Service-162733330551792/',
 'index': 81,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
DEBUG: Scraped from <200 https://bunyonbros.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/bunyonbrostreeserviceSLO',
 'index': 100,
 'instagram': 'https://www.instagram.com/bunyonbrostreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arbortask.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://arbortask.com/contact/> from <GET https://arbortask.com/contact>
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Scraped from <200 https://treeservicemantecaca.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'index': 84,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arbortask.com/contact/> (referer: https://arbortask.com/)
DEBUG: Scraped from <200 https://arbortask.com/contact/>
{'emails': ['almangrant@yahoo.com'],
 'facebook': 'https://www.facebook.com/arbortasktreeservice/',
 'index': 99,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/contact-us/> (referer: http://www.lewistreeserviceinc.com/)
DEBUG: Scraped from <200 http://www.lewistreeserviceinc.com/contact-us/>
{'emails': ['admin@lewistreeserviceinc.com', 'Admin@lewistreeserviceinc.com'],
 'facebook': 'N/A',
 'index': 92,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Crawled 163 pages (at 163 pages/min), scraped 64 items (at 64 items/min)
ERROR: Gave up retrying <GET http://www.alliancetrees.com/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Error downloading <GET http://www.alliancetrees.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 62343,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 5290605,
 'downloader/response_count': 212,
 'downloader/response_status_count/200': 142,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/302': 2,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/308': 1,
 'downloader/response_status_count/403': 21,
 'elapsed_time_seconds': 68.959757,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 10, 17, 7, 15, 364651),
 'httpcompression/response_bytes': 22331205,
 'httpcompression/response_count': 144,
 'httperror/response_ignored_count': 21,
 'httperror/response_ignored_status_count/403': 21,
 'item_scraped_count': 64,
 'log_count/DEBUG': 285,
 'log_count/ERROR': 3,
 'log_count/INFO': 32,
 'request_depth_max': 1,
 'response_received_count': 163,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2022, 12, 10, 17, 6, 6, 404894)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: 7d9ec5781b650fbd
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 2603084367616 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2603084367616 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2603084367616 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2603084367616 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'index': 8,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'index': 7,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
DEBUG: Scraped from <200 https://www.caltreeservice.com/contact-us>
{'emails': ['office@caltreeservice.com'],
 'facebook': 'https://www.facebook.com/samcolemanluxury',
 'index': 9,
 'instagram': 'https://www.instagram.com/samcolemanluxury/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/coast/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsteroftheCoast/',
 'index': 13,
 'instagram': 'https://www.instagram.com/monsterofthecoast/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/contact> (referer: https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/south-bay/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Monster-Tree-Service-of-South-Bay-1088163361240866/',
 'index': 12,
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://octreeservices.com/contact-us/>
{'emails': ['octreeservices1@gmail.com'],
 'facebook': 'N/A',
 'index': 1,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Scraped from <200 https://www.bigtstrees.com/contact>
{'emails': ['igtstrees@yahoo.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'bigtstrees@yahoo.com'],
 'facebook': 'http://www.facebook.com/BigTsTrees',
 'index': 22,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/west-valley/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/Monster-Tree-Service-of-West-Valley-1287919078019258/',
 'index': 24,
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/'}
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://rndtreeservices.com/contact-us>
{'emails': ['filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/106157038650413',
 'index': 25,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite> (referer: None)
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://westcoastarborists.com/>
{'emails': ['wcahiring@wcainc.com', 'corporate@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'index': 17,
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
DEBUG: Scraped from <200 http://www.specializedtreeworks.com/contact.html>
{'emails': ['ContactUs@specializedtreeworks.com'],
 'facebook': 'N/A',
 'index': 28,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/> (referer: None)
DEBUG: Scraped from <200 https://www.tomdaytreeservice.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/TomDayTreeService/reviews/',
 'index': 11,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://arborworksinc.com/contact/>
{'emails': ['information@arborworksinc.com'],
 'facebook': 'https://www.facebook.com/arborworks1/',
 'index': 4,
 'instagram': 'https://www.instagram.com/arborworksllc/',
 'linkedin': 'https://www.linkedin.com/company/arborworksinc',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Scraped from <200 https://www.modestotreeservicecompany.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'index': 20,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Scraped from <200 https://fallenleaftree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/fallenleaftreemanagement',
 'index': 18,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FallenLeafTree'}
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Scraped from <200 https://losangelesca-treeservice.com/contact>
{'emails': ['u003Elosangelescatreeservice@gmail.com',
            'losangelescatreeservice@gmail.com'],
 'facebook': 'https://www.facebook.com/losangelescatreeservice/',
 'index': 27,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/contact.html> (referer: http://www.blackbeartrees.com/)
DEBUG: Scraped from <200 http://www.vetreeservice.com/contactus.html>
{'emails': ['Patti@vetreeservice.com',
            'patti@vetreeservice.com',
            'Ed@vetreeservice.com',
            'Ashleigh@vetreeservice.com',
            'Eric@vetreeservice.com',
            'John@vetreeservice.com',
            'dns@technologydimensions.com',
            'Vic@vetreeservice.com'],
 'facebook': 'N/A',
 'index': 35,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://bayareatreespecialists.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Bay-Area-Tree-Specialists-658134177581480/?timeline_context_item_type=intro_card_work&timeline_context_item_source=100007956785104',
 'index': 32,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/TreesSpecialist'}
DEBUG: Scraped from <200 http://www.blackbeartrees.com/contact.html>
{'emails': ['blackbeartreeservice559@gmail.com'],
 'facebook': 'N/A',
 'index': 33,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 16,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/contact/privacy/> (referer: https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.traversotree.com/contacts/>
{'emails': ['Office@traversotree.com', 'office@traversotree.com'],
 'facebook': 'https://www.facebook.com/traversotree',
 'index': 19,
 'instagram': 'https://www.instagram.com/traversotree/?hl=en',
 'linkedin': 'https://www.linkedin.com/pub/traverso-tree-service/38/6a3/a40',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
DEBUG: Scraped from <200 https://www.tiptoparborists.com/contact/privacy/>
{'emails': ['privacy@reachlocal.com.'],
 'facebook': 'https://www.facebook.com/pg/Tip-Top-Arborists-Inc-608355719230396/reviews/',
 'index': 3,
 'instagram': 'https://www.instagram.com/tip_top_arborists/',
 'linkedin': 'https://www.linkedin.com/company/tip-top-arborists',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 23,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Scraped from <200 http://www.aearborists.com/contact-us/>
{'emails': ['aearborists@gmail.com'],
 'facebook': 'https://www.facebook.com/AE-Arborists-Tree-Care-428707717460988/ ',
 'index': 2,
 'instagram': 'https://www.instagram.com/aearborists/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/aearborists'}
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Scraped from <200 https://californiagreentreecare.com/contact.php>
{'emails': ['info@californiagreentreecare.com'],
 'facebook': 'N/A',
 'index': 34,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
DEBUG: Crawled (403) <GET https://www.adolphstreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
INFO: Ignoring response <403 https://www.adolphstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Scraped from <200 https://www.herculestreeservice.com/contact/>
{'emails': ['info@herculestreeservice.com'],
 'facebook': 'https://www.facebook.com/510799tree/',
 'index': 6,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'index': 38,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Scraped from <200 https://jesustreeserviceandlandscaping.com/contact/>
{'emails': ['jesusjgr1987@gmail.com'],
 'facebook': 'https://www.facebook.com/Jesus-Tree-Services-Landscaping-104850001236628',
 'index': 36,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://cutitrighttreeservicefresno.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'index': 45,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['sales@shipmantree.com', 'dillanmcather@gmail.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'index': 44,
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 39,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Scraped from <200 https://www.a1treeredding.com/contact/>
{'emails': ['Office@a1treeredding.com', 'office@a1treeredding.com'],
 'facebook': 'https://www.facebook.com/A1treeredding/',
 'index': 60,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Scraped from <200 https://www.commercialtreeservices.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/commercialtreeservices',
 'index': 51,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'index': 48,
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.affordabletreeservicesorangecounty.com/> from <GET http://www.affordabletreeservicesorangecounty.com/>
DEBUG: Scraped from <200 https://www.theneckofthewoods.com/contact-us.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/eddie.farquharson',
 'index': 56,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'index': 49,
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.eastbaytreeservice.com/> from <GET http://www.eastbaytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> from <GET https://www.gomezlandscapeandtreecare.com/contact.php>
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 50,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> (referer: https://www.gomezlandscapeandtreecare.com/)
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'index': 61,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.atlas-tree.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/AtlasTreeSurgery',
 'index': 64,
 'instagram': 'https://www.instagram.com/atlas.tree/',
 'linkedin': 'https://www.linkedin.com/company/atlas-tree-landscape-inc/about/',
 'twitter': 'https://twitter.com/atlas_and'}
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'index': 62,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
DEBUG: Scraped from <200 https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php>
{'emails': ['sales@gomezltc.com'],
 'facebook': '//www.facebook.com/Gomez-Landscape-Tree-Care-Inc-885181728164027/',
 'index': 58,
 'instagram': '//www.instagram.com/gomezlandscapetreecare/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://www.treeserviceroseville.com/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'index': 59,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
DEBUG: Scraped from <200 https://foresttreeservices.com/contact-us/>
{'emails': ['info@foresttreeservices.com'],
 'facebook': 'https://www.facebook.com/foresttreeservices',
 'index': 37,
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/company/forest-tree-services/about/',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'index': 41,
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
DEBUG: Crawled (200) <GET https://www.eastbaytreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/> (referer: None)
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
DEBUG: Scraped from <200 https://www.sequoiastreeservice.com/>
{'emails': ['evencio.martinez@yahoo.com'],
 'facebook': 'https://www.facebook.com/Sequoias-Tree-Service-104264014496885/',
 'index': 26,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['info@mowbrays.com', 'customerservice@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'index': 47,
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://stocktontreeservices.com/> from <GET https://www.stocktontreeservices.com/>
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (200) <GET http://acutabovetreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/contact-us/> (referer: https://www.affordabletreeservicesorangecounty.com/)
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
DEBUG: Scraped from <200 https://www.affordabletreeservicesorangecounty.com/contact-us/>
{'emails': ['20treeremovaloc@gmail.com', 'treeremovaloc@gmail.com'],
 'facebook': 'N/A',
 'index': 52,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://navastree.wixsite.com/my-site> (referer: None)
DEBUG: Scraped from <200 https://dprotreeservice.com/contact-us/>
{'emails': ['d.protreeservice@gmail.com'],
 'facebook': 'N/A',
 'index': 63,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/index.html#contact> (referer: http://www.abotreeservice.com/)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/> (referer: None)
DEBUG: Scraped from <200 http://www.abotreeservice.com/index.html>
{'emails': ['krasimira.stoyanova@deluxe.com',
            'info@abotreeservice.com',
            'operation@abotreeservice.com'],
 'facebook': 'https://www.facebook.com/abotreeservice',
 'index': 67,
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/abotreeservice',
 'twitter': 'https://twitter.com/abotreeservice'}
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Scraped from <200 https://ranchotreeservice.com/contact/>
{'emails': ['info@ranchotreeservice.com'],
 'facebook': 'https://www.facebook.com/Rancho-Tree-Service-109046575024387',
 'index': 74,
 'instagram': 'https://www.instagram.com/ranchotreeservice/',
 'linkedin': 'https://www.linkedin.com/company/rancho-inc-california/',
 'twitter': 'https://twitter.com/RanchoTree'}
DEBUG: Scraped from <200 https://jtstree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/category/Shopping---Retail/Jts-Inc-510518789043998/',
 'index': 77,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.stevestreeservice.net/> from <GET http://www.stevestreeservice.net/>
DEBUG: Crawled (403) <GET http://www.buenavistatree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Crawled (403) <GET https://www.petestreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.buenavistatree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 45, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
INFO: Ignoring response <403 https://www.petestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://www.runyonstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
INFO: Ignoring response <403 https://www.runyonstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.lunatreetrimming.com/> (referer: None)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
INFO: Ignoring response <403 http://www.lunatreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 89,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/contact-2/> (referer: https://stocktontreeservices.com/)
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 90,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://arbortask.com/> from <GET http://www.arbortask.com/>
DEBUG: Scraped from <200 https://stocktontreeservices.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'index': 69,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Scraped from <200 https://greenzwaytreeservice.com/contact/>
{'emails': ['greenzway@hotmail.com', 'Greenzway@hotmail.com'],
 'facebook': 'https://www.facebook.com/pg/greenzway',
 'index': 93,
 'instagram': 'https://www.instagram.com/greenzway_official',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'index': 91,
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/> (referer: None)
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'index': 78,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'index': 79,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/contact/> (referer: https://www.stevestreeservice.net/)
DEBUG: Scraped from <200 https://www.stevestreeservice.net/contact/>
{'emails': ['steves8733@gmail.com'],
 'facebook': 'N/A',
 'index': 94,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
DEBUG: Crawled (200) <GET https://arbortask.com/> (referer: None)
DEBUG: Scraped from <200 https://bunyonbros.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/bunyonbrostreeserviceSLO',
 'index': 100,
 'instagram': 'https://www.instagram.com/bunyonbrostreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://arbortask.com/contact/> from <GET https://arbortask.com/contact>
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Scraped from <200 https://treeservicemantecaca.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'index': 84,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://arbortask.com/contact/> (referer: https://arbortask.com/)
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Scraped from <200 https://arbortask.com/contact/>
{'emails': ['almangrant@yahoo.com'],
 'facebook': 'https://www.facebook.com/arbortasktreeservice/',
 'index': 99,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Scraped from <200 https://www.lctrees.com/contact/>
{'emails': ['info@lctrees.com'],
 'facebook': 'https://www.facebook.com/LC-Tree-Service-162733330551792/',
 'index': 81,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/contact-us/> (referer: http://www.lewistreeserviceinc.com/)
DEBUG: Scraped from <200 http://www.lewistreeserviceinc.com/contact-us/>
{'emails': ['Admin@lewistreeserviceinc.com', 'admin@lewistreeserviceinc.com'],
 'facebook': 'N/A',
 'index': 92,
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Crawled 163 pages (at 163 pages/min), scraped 64 items (at 64 items/min)
ERROR: Gave up retrying <GET http://www.alliancetrees.com/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Error downloading <GET http://www.alliancetrees.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 62343,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 5289934,
 'downloader/response_count': 212,
 'downloader/response_status_count/200': 142,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/302': 2,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/308': 1,
 'downloader/response_status_count/403': 21,
 'elapsed_time_seconds': 68.020817,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 10, 17, 9, 42, 202833),
 'httpcompression/response_bytes': 22330502,
 'httpcompression/response_count': 144,
 'httperror/response_ignored_count': 21,
 'httperror/response_ignored_status_count/403': 21,
 'item_scraped_count': 64,
 'log_count/DEBUG': 285,
 'log_count/ERROR': 3,
 'log_count/INFO': 32,
 'request_depth_max': 1,
 'response_received_count': 163,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2022, 12, 10, 17, 8, 34, 182016)}
INFO: Spider closed (finished)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'CONCURRENT_REQUESTS': 1,
 'DEPTH_PRIORITY': 1,
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SCHEDULER_DISK_QUEUE': 'scrapy.squeues.PickleFifoDiskQueue',
 'SCHEDULER_MEMORY_QUEUE': 'scrapy.squeues.FifoMemoryQueue',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: b4f23511903cbbf6
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Scraped from <200 https://octreeservices.com/contact-us/>
{'emails': ['octreeservices1@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
DEBUG: Scraped from <200 http://www.aearborists.com/contact-us/>
{'emails': ['aearborists@gmail.com'],
 'facebook': 'https://www.facebook.com/AE-Arborists-Tree-Care-428707717460988/ ',
 'instagram': 'https://www.instagram.com/aearborists/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/aearborists'}
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite> (referer: None)
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/contact/privacy/> (referer: https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite)
DEBUG: Scraped from <200 https://www.tiptoparborists.com/contact/privacy/>
{'emails': ['privacy@reachlocal.com.'],
 'facebook': 'https://www.facebook.com/pg/Tip-Top-Arborists-Inc-608355719230396/reviews/',
 'instagram': 'https://www.instagram.com/tip_top_arborists/',
 'linkedin': 'https://www.linkedin.com/company/tip-top-arborists',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Scraped from <200 https://arborworksinc.com/contact/>
{'emails': ['information@arborworksinc.com'],
 'facebook': 'https://www.facebook.com/arborworks1/',
 'instagram': 'https://www.instagram.com/arborworksllc/',
 'linkedin': 'https://www.linkedin.com/company/arborworksinc',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Attempting to acquire lock 1757924441824 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1757924441824 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 1757924441824 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 1757924441824 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Scraped from <200 https://www.herculestreeservice.com/contact/>
{'emails': ['info@herculestreeservice.com'],
 'facebook': 'https://www.facebook.com/510799tree/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.caltreeservice.com/contact-us>
{'emails': ['office@caltreeservice.com'],
 'facebook': 'https://www.facebook.com/samcolemanluxury',
 'instagram': 'https://www.instagram.com/samcolemanluxury/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Scraped from <200 https://www.tomdaytreeservice.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/TomDayTreeService/reviews/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/south-bay/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Monster-Tree-Service-of-South-Bay-1088163361240866/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/coast/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsteroftheCoast/',
 'instagram': 'https://www.instagram.com/monsterofthecoast/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
DEBUG: Scraped from <200 https://westcoastarborists.com/>
{'emails': ['corporate@wcainc.com', 'wcahiring@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Scraped from <200 https://fallenleaftree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/fallenleaftreemanagement',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FallenLeafTree'}
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
DEBUG: Scraped from <200 https://www.traversotree.com/contacts/>
{'emails': ['office@traversotree.com', 'Office@traversotree.com'],
 'facebook': 'https://www.facebook.com/traversotree',
 'instagram': 'https://www.instagram.com/traversotree/?hl=en',
 'linkedin': 'https://www.linkedin.com/pub/traverso-tree-service/38/6a3/a40',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
DEBUG: Scraped from <200 https://www.modestotreeservicecompany.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/contact> (referer: https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Scraped from <200 https://www.bigtstrees.com/contact>
{'emails': ['831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            'igtstrees@yahoo.com',
            'bigtstrees@yahoo.com'],
 'facebook': 'http://www.facebook.com/BigTsTrees',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/west-valley/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/Monster-Tree-Service-of-West-Valley-1287919078019258/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/'}
DEBUG: Scraped from <200 https://rndtreeservices.com/contact-us>
{'emails': ['filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/106157038650413',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
DEBUG: Scraped from <200 https://www.sequoiastreeservice.com/>
{'emails': ['evencio.martinez@yahoo.com'],
 'facebook': 'https://www.facebook.com/Sequoias-Tree-Service-104264014496885/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Scraped from <200 https://losangelesca-treeservice.com/contact>
{'emails': ['losangelescatreeservice@gmail.com',
            'u003Elosangelescatreeservice@gmail.com'],
 'facebook': 'https://www.facebook.com/losangelescatreeservice/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
DEBUG: Scraped from <200 http://www.specializedtreeworks.com/contact.html>
{'emails': ['ContactUs@specializedtreeworks.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
DEBUG: Scraped from <200 https://bayareatreespecialists.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Bay-Area-Tree-Specialists-658134177581480/?timeline_context_item_type=intro_card_work&timeline_context_item_source=100007956785104',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/TreesSpecialist'}
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/contact.html> (referer: http://www.blackbeartrees.com/)
DEBUG: Scraped from <200 http://www.blackbeartrees.com/contact.html>
{'emails': ['blackbeartreeservice559@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
DEBUG: Scraped from <200 https://californiagreentreecare.com/contact.php>
{'emails': ['info@californiagreentreecare.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
DEBUG: Scraped from <200 https://californiagreentreecare.com/contact.php>
{'emails': ['info@californiagreentreecare.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
DEBUG: Scraped from <200 http://www.vetreeservice.com/contactus.html>
{'emails': ['Patti@vetreeservice.com',
            'Eric@vetreeservice.com',
            'Vic@vetreeservice.com',
            'dns@technologydimensions.com',
            'John@vetreeservice.com',
            'Ashleigh@vetreeservice.com',
            'patti@vetreeservice.com',
            'Ed@vetreeservice.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
DEBUG: Scraped from <200 https://jesustreeserviceandlandscaping.com/contact/>
{'emails': ['jesusjgr1987@gmail.com'],
 'facebook': 'https://www.facebook.com/Jesus-Tree-Services-Landscaping-104850001236628',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
INFO: Crawled 68 pages (at 68 pages/min), scraped 29 items (at 29 items/min)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://foresttreeservices.com/contact-us/>
{'emails': ['info@foresttreeservices.com'],
 'facebook': 'https://www.facebook.com/foresttreeservices',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/company/forest-tree-services/about/',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['sales@shipmantree.com', 'dillanmcather@gmail.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Scraped from <200 https://cutitrighttreeservicefresno.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['customerservice@mowbrays.com', 'info@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.affordabletreeservicesorangecounty.com/> from <GET http://www.affordabletreeservicesorangecounty.com/>
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Scraped from <200 https://www.commercialtreeservices.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/commercialtreeservices',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/contact-us/> (referer: https://www.affordabletreeservicesorangecounty.com/)
DEBUG: Scraped from <200 https://www.affordabletreeservicesorangecounty.com/contact-us/>
{'emails': ['20treeremovaloc@gmail.com', 'treeremovaloc@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://www.adolphstreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.adolphstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Crawled 96 pages (at 28 pages/min), scraped 41 items (at 12 items/min)
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Gave up retrying <GET http://www.alliancetrees.com/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Error downloading <GET http://www.alliancetrees.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> from <GET https://www.gomezlandscapeandtreecare.com/contact.php>
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> (referer: https://www.gomezlandscapeandtreecare.com/)
DEBUG: Scraped from <200 https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php>
{'emails': ['sales@gomezltc.com'],
 'facebook': '//www.facebook.com/Gomez-Landscape-Tree-Care-Inc-885181728164027/',
 'instagram': '//www.instagram.com/gomezlandscapetreecare/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
DEBUG: Scraped from <200 https://www.treeserviceroseville.com/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Scraped from <200 https://www.a1treeredding.com/contact/>
{'emails': ['office@a1treeredding.com', 'Office@a1treeredding.com'],
 'facebook': 'https://www.facebook.com/A1treeredding/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['fred@richardstree.com', 'info@richardstree.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['fred@richardstree.com', 'info@richardstree.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
DEBUG: Scraped from <200 https://dprotreeservice.com/contact-us/>
{'emails': ['d.protreeservice@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Scraped from <200 https://www.atlas-tree.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/AtlasTreeSurgery',
 'instagram': 'https://www.instagram.com/atlas.tree/',
 'linkedin': 'https://www.linkedin.com/company/atlas-tree-landscape-inc/about/',
 'twitter': 'https://twitter.com/atlas_and'}
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://www.bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
INFO: Received SIGINT, shutting down gracefully. Send again to force 
INFO: Closing spider (shutdown)
INFO: Received SIGINT twice, forcing unclean shutdown
WARNING: Got data loss in http://www.abotreeservice.com/. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
DEBUG: Retrying <GET http://www.abotreeservice.com/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>, <twisted.python.failure.Failure twisted.web.http._DataLoss: Chunked decoder in 'BODY' state, still expecting more data to get to 'FINISHED' state.>]
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 4,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 1,
 'downloader/request_bytes': 51271,
 'downloader/request_count': 152,
 'downloader/request_method_count/GET': 152,
 'downloader/response_bytes': 3945000,
 'downloader/response_count': 148,
 'downloader/response_status_count/200': 107,
 'downloader/response_status_count/301': 27,
 'downloader/response_status_count/302': 3,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/308': 1,
 'downloader/response_status_count/403': 9,
 'elapsed_time_seconds': 169.75113,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2022, 12, 10, 17, 20, 33, 537892),
 'httpcompression/response_bytes': 15705109,
 'httpcompression/response_count': 98,
 'httperror/response_ignored_count': 9,
 'httperror/response_ignored_status_count/403': 9,
 'item_scraped_count': 48,
 'log_count/DEBUG': 206,
 'log_count/ERROR': 2,
 'log_count/INFO': 23,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 116,
 'retry/count': 3,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 1,
 'scheduler/dequeued': 152,
 'scheduler/dequeued/memory': 152,
 'scheduler/enqueued': 153,
 'scheduler/enqueued/memory': 153,
 'start_time': datetime.datetime(2022, 12, 10, 17, 17, 43, 786762)}
INFO: Spider closed (shutdown)
INFO: Scrapy 2.7.1 started (bot: scraper)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0
INFO: Overridden settings:
{'BOT_NAME': 'scraper',
 'CONCURRENT_REQUESTS': 1,
 'DEPTH_PRIORITY': 1,
 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SCHEDULER_DISK_QUEUE': 'scrapy.squeues.PickleFifoDiskQueue',
 'SCHEDULER_MEMORY_QUEUE': 'scrapy.squeues.FifoMemoryQueue',
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
DEBUG: Using selector: SelectSelector
DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
INFO: Telnet Password: a96eac6a73cb5456
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Crawled (200) <GET https://octreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.aearborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://octreeservices.com/contact-us/> (referer: https://octreeservices.com/)
DEBUG: Scraped from <200 https://octreeservices.com/contact-us/>
{'emails': ['octreeservices1@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.aearborists.com/contact-us/> (referer: None)
DEBUG: Scraped from <200 http://www.aearborists.com/contact-us/>
{'emails': ['aearborists@gmail.com'],
 'facebook': 'https://www.facebook.com/AE-Arborists-Tree-Care-428707717460988/ ',
 'instagram': 'https://www.instagram.com/aearborists/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/aearborists'}
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite> (referer: None)
DEBUG: Crawled (200) <GET https://arborworksinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.tiptoparborists.com/contact/privacy/> (referer: https://www.tiptoparborists.com/?utm_source=google&utm_medium=organic&utm_campaign=gmbavwebsite)
DEBUG: Scraped from <200 https://www.tiptoparborists.com/contact/privacy/>
{'emails': ['privacy@reachlocal.com.'],
 'facebook': 'https://www.facebook.com/pg/Tip-Top-Arborists-Inc-608355719230396/reviews/',
 'instagram': 'https://www.instagram.com/tip_top_arborists/',
 'linkedin': 'https://www.linkedin.com/company/tip-top-arborists',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://arborworksinc.com/contact/> (referer: https://arborworksinc.com/)
DEBUG: Scraped from <200 https://arborworksinc.com/contact/>
{'emails': ['information@arborworksinc.com'],
 'facebook': 'https://www.facebook.com/arborworks1/',
 'instagram': 'https://www.instagram.com/arborworksllc/',
 'linkedin': 'https://www.linkedin.com/company/arborworksinc',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET https://www.modestotreetrimming.com/> (referer: None)
INFO: Ignoring response <403 https://www.modestotreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Attempting to acquire lock 2286772531216 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2286772531216 acquired on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 2286772531216 on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 2286772531216 released on C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Redirecting (301) to <GET https://www.herculestreeservice.com/> from <GET http://www.herculestreeservice.com/>
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.herculestreeservice.com/contact/> (referer: https://www.herculestreeservice.com/)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Crawled (200) <GET http://www.petersonstreeworks.com/contact-us.html> (referer: http://www.petersonstreeworks.com/)
DEBUG: Scraped from <200 https://www.herculestreeservice.com/contact/>
{'emails': ['info@herculestreeservice.com'],
 'facebook': 'https://www.facebook.com/510799tree/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 http://www.petersonstreeworks.com/contact-us.html>
{'emails': ['petersonstrees@icloud.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://caltreeservice.com/> from <GET http://caltreeservice.com/>
DEBUG: Redirecting (301) to <GET https://www.caltreeservice.com/> from <GET https://caltreeservice.com/>
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.davidstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.caltreeservice.com/contact-us> (referer: https://www.caltreeservice.com/)
INFO: Ignoring response <403 http://www.davidstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Scraped from <200 https://www.caltreeservice.com/contact-us>
{'emails': ['office@caltreeservice.com'],
 'facebook': 'https://www.facebook.com/samcolemanluxury',
 'instagram': 'https://www.instagram.com/samcolemanluxury/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.tomdaytreeservice.com/> from <GET http://www.tomdaytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes> (referer: None)
DEBUG: Crawled (200) <GET https://www.tomdaytreeservice.com/contact-us> (referer: https://www.tomdaytreeservice.com/)
DEBUG: Scraped from <200 https://www.tomdaytreeservice.com/contact-us>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/TomDayTreeService/reviews/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/south-bay/contact-us/> (referer: https://www.monstertreeservice.com/south-bay/?utm_source=GMB&utm_medium=organic&utm_campaign=RanchoPalosVerdes)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/south-bay/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Monster-Tree-Service-of-South-Bay-1088163361240866/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont> (referer: None)
DEBUG: Crawled (200) <GET https://www.twainhartetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/coast/contact-us/> (referer: https://www.monstertreeservice.com/coast/?utm_source=GMB&utm_medium=organic&utm_campaign=Belmont)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/coast/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/MonsteroftheCoast/',
 'instagram': 'https://www.instagram.com/monsterofthecoast/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://sequoiatreeservice.us/> from <GET http://www.sequoiatreeservice.us/>
DEBUG: Crawled (200) <GET https://sequoiatreeservice.us/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay> (referer: None)
DEBUG: Redirecting (307) to <GET https://westcoastarborists.com/> from <GET http://westcoastarborists.com/>
DEBUG: Crawled (200) <GET https://westcoastarborists.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/east-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_East%20Bay)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://westcoastarborists.com/#contact> (referer: https://westcoastarborists.com/)
DEBUG: Scraped from <200 https://westcoastarborists.com/>
{'emails': ['corporate@wcainc.com', 'wcahiring@wcainc.com'],
 'facebook': 'https://www.facebook.com/WestCoastArborists/',
 'instagram': 'https://www.instagram.com/wcainc/',
 'linkedin': 'https://www.linkedin.com/company/west-coast-arborists-inc-',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://fallenleaftree.com/> from <GET https://www.fallenleaftree.com/>
DEBUG: Crawled (200) <GET https://fallenleaftree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.traversotree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://fallenleaftree.com/contact-us/> (referer: https://fallenleaftree.com/)
DEBUG: Scraped from <200 https://fallenleaftree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/fallenleaftreemanagement',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/FallenLeafTree'}
DEBUG: Crawled (200) <GET https://www.traversotree.com/contacts/> (referer: https://www.traversotree.com/)
DEBUG: Scraped from <200 https://www.traversotree.com/contacts/>
{'emails': ['Office@traversotree.com', 'office@traversotree.com'],
 'facebook': 'https://www.facebook.com/traversotree',
 'instagram': 'https://www.instagram.com/traversotree/?hl=en',
 'linkedin': 'https://www.linkedin.com/pub/traverso-tree-service/38/6a3/a40',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://californiatreedesign.com/> from <GET http://www.californiatreedesign.com/>
DEBUG: Crawled (200) <GET https://californiatreedesign.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.modestotreeservicecompany.com/contact/> from <GET https://www.modestotreeservicecompany.com/contact>
DEBUG: Redirecting (301) to <GET https://www.modestotreeservicecompany.com/contact/> from <GET http://www.modestotreeservicecompany.com/contact/>
DEBUG: Crawled (200) <GET https://www.modestotreeservicecompany.com/contact/> (referer: None)
DEBUG: Scraped from <200 https://www.modestotreeservicecompany.com/contact/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco> (referer: None)
DEBUG: Crawled (200) <GET https://www.bigtstrees.com/contact> (referer: https://www.bigtstrees.com/?y_source=1_MjA0NTc2NzYtNzE1LWxvY2F0aW9uLndlYnNpdGU%3D)
DEBUG: Scraped from <200 https://www.bigtstrees.com/contact>
{'emails': ['bigtstrees@yahoo.com',
            '605a7baede844d278b89dc95ae0a9123@sentry-next.wixpress.com',
            '831126cb46b74583bf6f72c5061cba9d@sentry-viewer.wixpress.com',
            'igtstrees@yahoo.com'],
 'facebook': 'http://www.facebook.com/BigTsTrees',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/san-francisco-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_San%20Francisco)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose> (referer: None)
DEBUG: Redirecting (301) to <GET https://rndtreeservices.com/> from <GET http://rndtreeservices.com/>
DEBUG: Crawled (200) <GET https://rndtreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.monstertreeservice.com/west-valley/contact-us/> (referer: https://www.monstertreeservice.com/west-valley/?utm_source=GMB&utm_medium=organic&utm_campaign=SanJose)
DEBUG: Crawled (200) <GET https://rndtreeservices.com/contact-us> (referer: https://rndtreeservices.com/)
DEBUG: Scraped from <200 https://www.monstertreeservice.com/west-valley/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pg/Monster-Tree-Service-of-West-Valley-1287919078019258/',
 'instagram': 'https://www.instagram.com/monstertreeservices/',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/'}
DEBUG: Scraped from <200 https://rndtreeservices.com/contact-us>
{'emails': ['filler@godaddy.com'],
 'facebook': 'https://www.facebook.com/106157038650413',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.sequoiastreeservice.com/> from <GET https://sequoiastreeservice.com/>
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.sequoiastreeservice.com/#contact> (referer: https://www.sequoiastreeservice.com/)
DEBUG: Scraped from <200 https://www.sequoiastreeservice.com/>
{'emails': ['evencio.martinez@yahoo.com'],
 'facebook': 'https://www.facebook.com/Sequoias-Tree-Service-104264014496885/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://losangelesca-treeservice.com/contact> (referer: https://losangelesca-treeservice.com/)
DEBUG: Scraped from <200 https://losangelesca-treeservice.com/contact>
{'emails': ['u003Elosangelescatreeservice@gmail.com',
            'losangelescatreeservice@gmail.com'],
 'facebook': 'https://www.facebook.com/losangelescatreeservice/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.bptreeservices.com/> from <GET http://bptreeservices.com/>
DEBUG: Crawled (200) <GET https://www.bptreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.specializedtreeworks.com/contact.html> (referer: http://www.specializedtreeworks.com/)
DEBUG: Scraped from <200 http://www.specializedtreeworks.com/contact.html>
{'emails': ['ContactUs@specializedtreeworks.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://topestreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://topestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.forresttreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.forresttreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/> (referer: None)
DEBUG: Crawled (200) <GET https://bayareatreespecialists.com/contact/> (referer: https://bayareatreespecialists.com/)
DEBUG: Scraped from <200 https://bayareatreespecialists.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/Bay-Area-Tree-Specialists-658134177581480/?timeline_context_item_type=intro_card_work&timeline_context_item_source=100007956785104',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'https://twitter.com/TreesSpecialist'}
DEBUG: Crawled (200) <GET http://www.blackbeartrees.com/contact.html> (referer: http://www.blackbeartrees.com/)
DEBUG: Scraped from <200 http://www.blackbeartrees.com/contact.html>
{'emails': ['blackbeartreeservice559@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://californiagreentreecare.com/> from <GET http://californiagreentreecare.com/>
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://californiagreentreecare.com/contact.php> (referer: None)
DEBUG: Scraped from <200 https://californiagreentreecare.com/contact.php>
{'emails': ['info@californiagreentreecare.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.vetreeservice.com/contactus.html> (referer: http://www.vetreeservice.com/)
DEBUG: Scraped from <200 http://www.vetreeservice.com/contactus.html>
{'emails': ['Eric@vetreeservice.com',
            'Patti@vetreeservice.com',
            'John@vetreeservice.com',
            'patti@vetreeservice.com',
            'Vic@vetreeservice.com',
            'Ashleigh@vetreeservice.com',
            'Ed@vetreeservice.com',
            'dns@technologydimensions.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://jesustreeserviceandlandscaping.com/> from <GET http://jesustreeserviceandlandscaping.com/>
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/> (referer: None)
DEBUG: Crawled (200) <GET https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb> (referer: None)
DEBUG: Crawled (200) <GET https://jesustreeserviceandlandscaping.com/contact/> (referer: https://jesustreeserviceandlandscaping.com/)
DEBUG: Scraped from <200 https://jesustreeserviceandlandscaping.com/contact/>
{'emails': ['jesusjgr1987@gmail.com'],
 'facebook': 'https://www.facebook.com/Jesus-Tree-Services-Landscaping-104850001236628',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://foresttreeservices.com/contact-us/> (referer: https://foresttreeservices.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb)
DEBUG: Scraped from <200 https://foresttreeservices.com/contact-us/>
{'emails': ['info@foresttreeservices.com'],
 'facebook': 'https://www.facebook.com/foresttreeservices',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/company/forest-tree-services/about/',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.artstreeservice.com/> from <GET http://www.artstreeservice.com/>
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz> (referer: None)
DEBUG: Crawled (200) <GET https://www.artstreeservice.com/contact.html> (referer: https://www.artstreeservice.com/)
DEBUG: Scraped from <200 https://www.artstreeservice.com/contact.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Crawled 69 pages (at 69 pages/min), scraped 30 items (at 30 items/min)
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/santa-cruz-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Santa%20Cruz)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Redirecting (301) to <GET https://www.hamiltontree.com/> from <GET http://www.hamiltontree.com/>
DEBUG: Redirecting (301) to <GET https://hamiltontree.com/> from <GET https://www.hamiltontree.com/>
DEBUG: Crawled (200) <GET https://hamiltontree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay> (referer: None)
DEBUG: Crawled (403) <GET http://www.cwtreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.cwtreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/south-bay-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_South%20Bay)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (403) <GET http://www.travistreeserviceinc.com/> (referer: None)
INFO: Ignoring response <403 http://www.travistreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (308) to <GET https://www.shipmantree.com/> from <GET http://www.shipmantree.com/>
DEBUG: Redirecting (301) to <GET https://shipmantree.com/> from <GET https://www.shipmantree.com/>
DEBUG: Crawled (200) <GET https://shipmantree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.cutitrighttreeservicefresno.com/> from <GET http://www.cutitrighttreeservicefresno.com/>
DEBUG: Redirecting (301) to <GET https://cutitrighttreeservicefresno.com/> from <GET https://www.cutitrighttreeservicefresno.com/>
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/> (referer: None)
DEBUG: Crawled (200) <GET https://shipmantree.com/contact/> (referer: https://shipmantree.com/)
DEBUG: Scraped from <200 https://shipmantree.com/contact/>
{'emails': ['dillanmcather@gmail.com', 'sales@shipmantree.com'],
 'facebook': 'https://www.facebook.com/profile.php?id=100071969492853',
 'instagram': 'https://www.instagram.com/shipmantreeservice559/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://cutitrighttreeservicefresno.com/contact-us/> (referer: https://cutitrighttreeservicefresno.com/)
DEBUG: Scraped from <200 https://cutitrighttreeservicefresno.com/contact-us/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://www.jmtreeserviceca.com/> (referer: None)
INFO: Ignoring response <403 http://www.jmtreeserviceca.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.mowbrays.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.mowbrays.com/contact-us/> (referer: https://www.mowbrays.com/)
DEBUG: Scraped from <200 https://www.mowbrays.com/contact-us/>
{'emails': ['customerservice@mowbrays.com', 'info@mowbrays.com'],
 'facebook': 'https://www.facebook.com/mowbraystree',
 'instagram': 'https://www.instagram.com/mowbrays/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://imagetreeservice.com/> from <GET https://www.imagetreeservice.com/>
DEBUG: Crawled (200) <GET https://imagetreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento> (referer: None)
DEBUG: Crawled (200) <GET https://imagetreeservice.com/contact-us/> (referer: https://imagetreeservice.com/)
DEBUG: Scraped from <200 https://imagetreeservice.com/contact-us/>
{'emails': ['info@imagetreeservice.com'],
 'facebook': 'https://www.facebook.com/ImageTreeService/',
 'instagram': 'https://www.instagram.com/imagetreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.davey.com/about/contact-us/> (referer: https://www.davey.com/residential-tree-services/local-offices/sacramento-roseville-tree-service/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=RC_Sacramento)
DEBUG: Scraped from <200 https://www.davey.com/about/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/DaveyTree',
 'instagram': 'https://instagram.com/DaveyTree/',
 'linkedin': 'http://www.linkedin.com/company/the-davey-tree-expert-company',
 'twitter': 'https://twitter.com/DaveyTree'}
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.affordabletreeservicesorangecounty.com/> from <GET http://www.affordabletreeservicesorangecounty.com/>
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.commercialtreeservices.com/contact/> (referer: https://www.commercialtreeservices.com/)
DEBUG: Scraped from <200 https://www.commercialtreeservices.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/commercialtreeservices',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.affordabletreeservicesorangecounty.com/contact-us/> (referer: https://www.affordabletreeservicesorangecounty.com/)
DEBUG: Scraped from <200 https://www.affordabletreeservicesorangecounty.com/contact-us/>
{'emails': ['20treeremovaloc@gmail.com', 'treeremovaloc@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.acleancuttree.com/> from <GET http://acleancuttree.com/>
DEBUG: Crawled (403) <GET http://www.acleancuttree.com/> (referer: None)
INFO: Ignoring response <403 http://www.acleancuttree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://www.adolphstreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.adolphstreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
INFO: Crawled 94 pages (at 25 pages/min), scraped 40 items (at 10 items/min)
DEBUG: Retrying <GET http://www.alliancetrees.com/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Gave up retrying <GET http://www.alliancetrees.com/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
ERROR: Error downloading <GET http://www.alliancetrees.com/>
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic> (referer: None)
DEBUG: Crawled (200) <GET http://www.familytree-service.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.theneckofthewoods.com/contact-us.html> (referer: https://www.theneckofthewoods.com/?utm_source=GMB&utm_medium=organic)
DEBUG: Scraped from <200 https://www.theneckofthewoods.com/contact-us.html>
{'emails': [],
 'facebook': 'https://www.facebook.com/eddie.farquharson',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> from <GET https://www.gomezlandscapeandtreecare.com/contact.php>
DEBUG: Crawled (200) <GET https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php> (referer: https://www.gomezlandscapeandtreecare.com/)
DEBUG: Scraped from <200 https://www.gomezlandscapeandtreecare.com/contact/request-an-estimate.php>
{'emails': ['sales@gomezltc.com'],
 'facebook': '//www.facebook.com/Gomez-Landscape-Tree-Care-Inc-885181728164027/',
 'instagram': '//www.instagram.com/gomezlandscapetreecare/?hl=en',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.treeserviceroseville.com/contact-us.html> (referer: https://www.treeserviceroseville.com/)
DEBUG: Scraped from <200 https://www.treeserviceroseville.com/contact-us.html>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.a1treeredding.com/contact/> (referer: https://www.a1treeredding.com/)
DEBUG: Scraped from <200 https://www.a1treeredding.com/contact/>
{'emails': ['office@a1treeredding.com', 'Office@a1treeredding.com'],
 'facebook': 'https://www.facebook.com/A1treeredding/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.richardstree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.richardstree.com/contact.html> (referer: http://www.richardstree.com/)
DEBUG: Scraped from <200 http://www.richardstree.com/contact.html>
{'emails': ['info@richardstree.com', 'fred@richardstree.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://dprotreeservice.com/> from <GET http://dprotreeservice.com/>
DEBUG: Crawled (200) <GET https://dprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website> (referer: None)
DEBUG: Crawled (200) <GET https://dprotreeservice.com/contact-us/> (referer: https://dprotreeservice.com/)
DEBUG: Crawled (200) <GET https://www.atlas-tree.com/contact/> (referer: https://www.atlas-tree.com/?utm_source=google&utm_medium=organic&utm_campaign=gmb&utm_content=gmb_website)
DEBUG: Scraped from <200 https://dprotreeservice.com/contact-us/>
{'emails': ['d.protreeservice@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Scraped from <200 https://www.atlas-tree.com/contact/>
{'emails': [],
 'facebook': 'https://www.facebook.com/AtlasTreeSurgery',
 'instagram': 'https://www.instagram.com/atlas.tree/',
 'linkedin': 'https://www.linkedin.com/company/atlas-tree-landscape-inc/about/',
 'twitter': 'https://twitter.com/atlas_and'}
DEBUG: Redirecting (301) to <GET https://www.atlastree.com/> from <GET https://atlastree.com/>
DEBUG: Crawled (200) <GET https://www.atlastree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.eastbaytreeservice.com/> from <GET http://www.eastbaytreeservice.com/>
DEBUG: Crawled (200) <GET https://www.eastbaytreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.abotreeservice.com/index.html#contact> (referer: http://www.abotreeservice.com/)
DEBUG: Scraped from <200 http://www.abotreeservice.com/index.html>
{'emails': ['operation@abotreeservice.com',
            'krasimira.stoyanova@deluxe.com',
            'info@abotreeservice.com'],
 'facebook': 'https://www.facebook.com/abotreeservice',
 'instagram': 'N/A',
 'linkedin': 'https://www.linkedin.com/in/abotreeservice',
 'twitter': 'https://twitter.com/abotreeservice'}
DEBUG: Redirecting (301) to <GET https://stocktontreeservices.com/> from <GET https://www.stocktontreeservices.com/>
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.williamstreeservices.net/> (referer: None)
INFO: Ignoring response <403 http://www.williamstreeservices.net/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://stocktontreeservices.com/contact-2/> (referer: https://stocktontreeservices.com/)
DEBUG: Scraped from <200 https://stocktontreeservices.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET http://williamstreeserviceinc.com/> (referer: None)
INFO: Ignoring response <403 http://williamstreeserviceinc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://treeservicesandiegoca.com/> (referer: None)
DEBUG: Crawled (403) <GET http://twincitiestreeservice.net/> (referer: None)
INFO: Ignoring response <403 http://twincitiestreeservice.net/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://ranchotreeservice.com/> from <GET http://www.ranchotreeservice.com/>
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/> (referer: None)
DEBUG: Crawled (403) <GET http://higueratreecare.com/> (referer: None)
INFO: Ignoring response <403 http://higueratreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://ranchotreeservice.com/contact/> (referer: https://ranchotreeservice.com/)
DEBUG: Scraped from <200 https://ranchotreeservice.com/contact/>
{'emails': ['info@ranchotreeservice.com'],
 'facebook': 'https://www.facebook.com/Rancho-Tree-Service-109046575024387',
 'instagram': 'https://www.instagram.com/ranchotreeservice/',
 'linkedin': 'https://www.linkedin.com/company/rancho-inc-california/',
 'twitter': 'https://twitter.com/RanchoTree'}
DEBUG: Crawled (200) <GET http://acutabovetreesvc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jtstree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Crawled (200) <GET https://jtstree.com/contact-us/> (referer: https://jtstree.com/)
DEBUG: Scraped from <200 https://jtstree.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/pages/category/Shopping---Retail/Jts-Inc-510518789043998/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.delacruztreesvc.com/> from <GET http://delacruztreesvc.com/>
DEBUG: Crawled (403) <GET http://www.delacruztreesvc.com/> (referer: None)
INFO: Crawled 131 pages (at 37 pages/min), scraped 53 items (at 13 items/min)
INFO: Ignoring response <403 http://www.delacruztreesvc.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET http://treeprotreeservice.com/contact-us/> (referer: http://treeprotreeservice.com/)
DEBUG: Scraped from <200 http://treeprotreeservice.com/contact-us/>
{'emails': ['treepro.office@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/> from <GET http://www.lctrees.com/>
DEBUG: Crawled (200) <GET https://www.lctrees.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://www.lctrees.com/contact/> from <GET https://www.lctrees.com/contact>
DEBUG: Crawled (200) <GET https://www.lctrees.com/contact/> (referer: https://www.lctrees.com/)
DEBUG: Scraped from <200 https://www.lctrees.com/contact/>
{'emails': ['info@lctrees.com'],
 'facebook': 'https://www.facebook.com/LC-Tree-Service-162733330551792/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET http://www.larrystreecare.com/> from <GET http://larrystreecare.com/>
DEBUG: Crawled (403) <GET http://www.larrystreecare.com/> (referer: None)
INFO: Ignoring response <403 http://www.larrystreecare.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://treeservicemantecaca.com/> from <GET https://www.treeservicemantecaca.com/>
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/> (referer: None)
DEBUG: Crawled (403) <GET http://www.atlastreeservice.com/> (referer: None)
INFO: Ignoring response <403 http://www.atlastreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://treeservicemantecaca.com/contact-2/> (referer: https://treeservicemantecaca.com/)
DEBUG: Scraped from <200 https://treeservicemantecaca.com/contact-2/>
{'emails': [],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.treebiz.org/> (referer: None)
DEBUG: Redirecting (301) to <GET https://joelstreeservices.com/> from <GET http://joelstreeservices.com/>
DEBUG: Crawled (200) <GET https://joelstreeservices.com/> (referer: None)
DEBUG: Crawled (200) <GET https://navastree.wixsite.com/my-site> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://www.alpentree.com/> from <GET http://alpentree.com/>
DEBUG: Crawled (200) <GET https://www.alpentree.com/> (referer: None)
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/> (referer: None)
DEBUG: Crawled (200) <GET https://www.alpentree.com/contact> (referer: https://www.alpentree.com/)
DEBUG: Scraped from <200 https://www.alpentree.com/contact>
{'emails': ['alpentree@gmail.com'],
 'facebook': 'https://www.facebook.com/Alpen-Tree-Experts-296764412428/',
 'instagram': 'http://www.instagram.com/alpentreeexperts',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET http://www.lewistreeserviceinc.com/contact-us/> (referer: http://www.lewistreeserviceinc.com/)
DEBUG: Scraped from <200 http://www.lewistreeserviceinc.com/contact-us/>
{'emails': ['Admin@lewistreeserviceinc.com', 'admin@lewistreeserviceinc.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Redirecting (301) to <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> from <GET http://greenzwaytreeservice.com/>
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html> (referer: None)
DEBUG: Redirecting (301) to <GET https://www.stevestreeservice.net/> from <GET http://www.stevestreeservice.net/>
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/> (referer: None)
DEBUG: Crawled (200) <GET https://greenzwaytreeservice.com/contact/> (referer: https://greenzwaytreeservice.com/wp-content/endurance-page-cache/_index.html)
DEBUG: Scraped from <200 https://greenzwaytreeservice.com/contact/>
{'emails': ['Greenzway@hotmail.com', 'greenzway@hotmail.com'],
 'facebook': 'https://www.facebook.com/pg/greenzway',
 'instagram': 'https://www.instagram.com/greenzway_official',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://www.stevestreeservice.net/contact/> (referer: https://www.stevestreeservice.net/)
DEBUG: Scraped from <200 https://www.stevestreeservice.net/contact/>
{'emails': ['steves8733@gmail.com'],
 'facebook': 'N/A',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (403) <GET https://www.petestreeservice.com/> (referer: None)
INFO: Ignoring response <403 https://www.petestreeservice.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.buenavistatree.com/> (referer: None)
INFO: Ignoring response <403 http://www.buenavistatree.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET http://www.lunatreetrimming.com/> (referer: None)
INFO: Ignoring response <403 http://www.lunatreetrimming.com/>: HTTP status code is not handled or not allowed
DEBUG: Crawled (403) <GET https://www.runyonstree.com/> (referer: None)
INFO: Ignoring response <403 https://www.runyonstree.com/>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (301) to <GET https://arbortask.com/> from <GET http://www.arbortask.com/>
DEBUG: Crawled (200) <GET https://arbortask.com/> (referer: None)
DEBUG: Redirecting (301) to <GET http://bunyonbros.com/> from <GET http://www.bunyonbros.com/>
DEBUG: Redirecting (301) to <GET https://bunyonbros.com/> from <GET http://bunyonbros.com/>
DEBUG: Crawled (200) <GET https://bunyonbros.com/> (referer: None)
DEBUG: Redirecting (301) to <GET https://arbortask.com/contact/> from <GET https://arbortask.com/contact>
DEBUG: Crawled (200) <GET https://arbortask.com/contact/> (referer: https://arbortask.com/)
DEBUG: Scraped from <200 https://arbortask.com/contact/>
{'emails': ['almangrant@yahoo.com'],
 'facebook': 'https://www.facebook.com/arbortasktreeservice/',
 'instagram': 'N/A',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
DEBUG: Crawled (200) <GET https://bunyonbros.com/contact-us/> (referer: https://bunyonbros.com/)
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\moffi\PycharmProjects\scraping_web\scraper\scraper\spiders\website_spider.py", line 45, in start_requests
    yield scrapy.Request(url=url, callback=self.parse_website,meta={'test_number':test_number})
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\moffi\PycharmProjects\scraping_web\venv\lib\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: 
DEBUG: Scraped from <200 https://bunyonbros.com/contact-us/>
{'emails': [],
 'facebook': 'https://www.facebook.com/bunyonbrostreeserviceSLO',
 'instagram': 'https://www.instagram.com/bunyonbrostreeservice/',
 'linkedin': 'N/A',
 'twitter': 'N/A'}
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 66056,
 'downloader/request_count': 213,
 'downloader/request_method_count/GET': 213,
 'downloader/response_bytes': 5264694,
 'downloader/response_count': 210,
 'downloader/response_status_count/200': 141,
 'downloader/response_status_count/301': 45,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/308': 1,
 'downloader/response_status_count/403': 21,
 'elapsed_time_seconds': 215.370152,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 12, 10, 17, 25, 5, 425600),
 'httpcompression/response_bytes': 22331214,
 'httpcompression/response_count': 144,
 'httperror/response_ignored_count': 21,
 'httperror/response_ignored_status_count/403': 21,
 'item_scraped_count': 64,
 'log_count/DEBUG': 283,
 'log_count/ERROR': 3,
 'log_count/INFO': 34,
 'request_depth_max': 1,
 'response_received_count': 162,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'scheduler/dequeued': 213,
 'scheduler/dequeued/memory': 213,
 'scheduler/enqueued': 213,
 'scheduler/enqueued/memory': 213,
 'start_time': datetime.datetime(2022, 12, 10, 17, 21, 30, 55448)}
INFO: Spider closed (finished)
